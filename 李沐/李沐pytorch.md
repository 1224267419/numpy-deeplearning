 ä½¿ç”¨.ipynbæ–‡ä»¶ï¼šcmd è¾“å…¥ipython notebook 

http://localhost:8888/notebooks/d2l-zh%20(1)/pytorch/index.ipynb

åœ°å€å¦‚ä¸Š 

## ä¸€èˆ¬è€Œè¨€,å¤æ‚ä¸€ç‚¹çš„æ¨¡å‹æ¯”è¿‡äºç®€å•çš„æ¨¡å‹æ›´å¥½,èµ·ç å¤æ‚æ¨¡å‹å¯ä»¥é€šè¿‡æ­£åˆ™åŒ–è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜,å¤ªç®€å•å°±éº»çƒ¦äº†

### æ•°æ®æ“ä½œï¼š

ä¸€äº›ç®€å•çš„åˆ‡ç‰‡

![image-20211112161214878](image-20211112161214878.png)



```
X = torch.arange(12, dtype=torch.float32).reshape((3,4))
Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])torch.cat((X, Y), dim=0)
torch.cat((X, Y), dim=1)
```

è¾“å‡º

```python
(tensor([[ 0.,  1.,  2.,  3.],
         [ 4.,  5.,  6.,  7.],
         [ 8.,  9., 10., 11.],
         [ 2.,  1.,  4.,  3.],
         [ 1.,  2.,  3.,  4.],
         [ 4.,  3.,  2.,  1.]]),#ç¬¬0ç»´(è¡Œåˆå¹¶)(dim=0)
 tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],
         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],
         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))#ç¬¬1ç»´(åˆ—åˆå¹¶)(dim=1)
```

torch.zeros()å’Œtorch.ones()	å…¨0å’Œå…¨ä¸€çš„tensorå˜é‡

ä¸¤ä¸ªtensorç›´æ¥+-*/ä»¥åŠ**,æ˜¯åœ¨åšå¯¹åº”å…ƒç´ çš„è¿ç®—(å…è®¸å¹¿æ’­)

torch.exp()	eçš„å¯¹åº”æ¬¡æ–¹

torch.sum()	ç”Ÿæˆåªæœ‰ä¸€ä¸ªå…ƒç´ çš„å¼ é‡(å¯¹æ‰€æœ‰å…ƒç´ æ±‚å’Œ )

å¹¿æ’­ï¼šä»…æœ‰ä¸€ä¸ªå€¼çš„ç»´åº¦è‡ªåŠ¨(å¹¿æ’­)æ‰©å±•



### æ•°æ®é¢„å¤„ç†

ä¸‹é¢æˆ‘ä»¬å°†æ•°æ®é›†æŒ‰è¡Œå†™å…¥CSVæ–‡ä»¶ä¸­ã€‚

```python
import os

os.makedirs(os.path.join('..', 'data'), exist_ok=True) #åˆ›å»ºæ–‡ä»¶å¤¹
data_file = os.path.join('..', 'data', 'house_tiny.csv')
#åˆ›å»ºhouse_tiny.csvæ–‡ä»¶
with open(data_file, 'w') as f:
    f.write('NumRooms,Alley,Price\n')  # åˆ—å
    f.write('NA,Pave,127500\n')  # æ¯è¡Œè¡¨ç¤ºä¸€ä¸ªæ•°æ®æ ·æœ¬
    f.write('2,NA,106000\n')
    f.write('4,NA,178100\n')
    f.write('NA,NA,140000\n')
```

åˆ›å»ºä¸€ä¸ªäººå·¥æ•°æ®é›†ï¼Œå¹¶å­˜å‚¨åœ¨csvï¼ˆé€—å·åˆ†éš”å€¼ï¼‰æ–‡ä»¶`../data/house_tiny.csv`ä¸­

NAä»£è¡¨æœªçŸ¥æ•°

###  è¯»å–æ•°æ®é›†

```python
import pandas as pd
os.makedirs(os.path.join('..', 'data'), exist_ok=True)
data_file = os.path.join('..', 'data', 'house_tiny.csv')



data = pd.read_csv(data_file)
print(data)
```

ä½¿ç”¨pandasåº“è¯»å– ä¸Šé¢å†™å…¥çš„æ–‡ä»¶æ•°æ®

### 2.2.2. å¤„ç†ç¼ºå¤±å€¼

æ³¨æ„ï¼Œâ€œNaNâ€é¡¹ä»£è¡¨ç¼ºå¤±å€¼ã€‚ä¸ºäº†å¤„ç†ç¼ºå¤±çš„æ•°æ®ï¼Œå…¸å‹çš„æ–¹æ³•åŒ…æ‹¬*æ’å€¼*å’Œ*åˆ é™¤*ï¼Œå…¶ä¸­æ’å€¼ç”¨æ›¿ä»£å€¼ä»£æ›¿ç¼ºå¤±å€¼ã€‚è€Œåˆ é™¤åˆ™å¿½ç•¥ç¼ºå¤±å€¼ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†è€ƒè™‘æ’å€¼ã€‚

é€šè¿‡ä½ç½®ç´¢å¼•`iloc`ï¼Œæˆ‘ä»¬å°†`data`åˆ†æˆ`inputs`å’Œ`outputs`ï¼Œå…¶ä¸­å‰è€…ä¸º`data`çš„å‰ä¸¤åˆ—ï¼Œè€Œåè€…ä¸º`data`çš„æœ€åä¸€åˆ—ã€‚å¯¹äº`inputs`ä¸­ç¼ºå°‘çš„æ•°å€¼ï¼Œæˆ‘ä»¬ç”¨åŒä¸€åˆ—çš„å‡å€¼æ›¿æ¢â€œNaNâ€é¡¹ã€‚

```python
inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]
inputs = inputs.fillna(inputs.mean()) #å‡å€¼æ›¿æ¢NAN
print(inputs)
```

ä»¥ä¸Šå°†æ•°æ®æŒ‰åˆ—åˆ†å¼€,å¹¶ç”¨å‡å€¼æ›¿æ¢NAN(å¦‚æœå¯ä»¥çš„è¯)

```
   NumRooms Alley
0       3.0  Pave
1       2.0   NaN
2       4.0   NaN
3       3.0   NaN
```

å¯¹äº`inputs`ä¸­çš„ç±»åˆ«å€¼æˆ–ç¦»æ•£å€¼ï¼Œæˆ‘ä»¬å°†â€œNaNâ€è§†ä¸ºä¸€ä¸ªç±»åˆ«ã€‚ç”±äºâ€œå··å­â€ï¼ˆâ€œAlleyâ€ï¼‰åˆ—åªæ¥å—ä¸¤ç§ç±»å‹çš„ç±»åˆ«å€¼â€œPaveâ€å’Œâ€œNaNâ€ï¼Œ`pandas`å¯ä»¥è‡ªåŠ¨å°†æ­¤åˆ—è½¬æ¢ä¸ºä¸¤åˆ—â€œAlley_Paveâ€å’Œâ€œAlley_nanâ€ã€‚å··å­ç±»å‹ä¸ºâ€œPaveâ€çš„è¡Œä¼šå°†â€œAlley_Paveâ€çš„å€¼è®¾ç½®ä¸º1ï¼Œâ€œAlley_nanâ€çš„å€¼è®¾ç½®ä¸º0ã€‚ç¼ºå°‘å··å­ç±»å‹çš„è¡Œä¼šå°†â€œAlley_Paveâ€å’Œâ€œAlley_nanâ€åˆ†åˆ«è®¾ç½®ä¸º0å’Œ1ã€‚

```
inputs = pd.get_dummies(inputs, dummy_na=True)
#dummy_na=True,ä¿ç•™åˆ†ç±»å˜é‡ä¸­çš„ç¼ºå¤±å€¼ï¼Œå°†å…¶å•ç‹¬ä½œä¸ºä¸€åˆ—,å»æ‰åˆ™ä¸ä¿ç•™
print(inputs)
```

å°†æ‰€æœ‰è¾“å‡ºç±»å‹ä½œä¸ºç‰¹å¾ï¼Œç„¶åç”¨**ç±»hot-one**ç¼–ç è¾“å‡º

è¾“å‡ºï¼š

```
   NumRooms  Alley_Pave  Alley_nan
0       3.0           1          0
1       2.0           0          1
2       4.0           0          1
3       3.0           0          1
```

ä¿ç•™åˆ†ç±»å˜é‡ä¸­çš„ç¼ºå¤±å€¼ï¼Œå°†å…¶å•ç‹¬ä½œä¸ºä¸€åˆ—ï¼Œ åŠ dummy_na = Trueï¼Œä¸ä¿ç•™ç›´æ¥å»æ‰å°±è¡Œ

```python
x, y = torch.tensor(inputs.values), torch.tensor(outputs.values)
print('3.è½¬æ¢ä¸ºå¼ é‡ï¼š')
print(x)
print(y)

```



```python
3.è½¬æ¢ä¸ºå¼ é‡ï¼š
tensor([[3., 1., 0.],
        [2., 0., 1.],
        [4., 0., 1.],
        [3., 0., 1.]], dtype=torch.float64)
tensor([[       nan, 1.2750e+05],
        [2.0000e+00, 1.0600e+05],
        [4.0000e+00, 1.7810e+05],
        [       nan, 1.4000e+05]], dtype=torch.float64)
```

å¦‚ä¸Š,å°†ä»csvä¸­è¯»å–åˆ°çš„æ•°ç»„è½¬åŒ–ä¸ºäº†tensorç±»å‹çš„æ•°



```python
print('4.çŸ©é˜µçš„è®¡ç®—')
A = torch.arange(20, dtype=torch.float32).reshape(5, 4)
B = A.clone()  # é€šè¿‡åˆ†é…æ–°å†…å­˜ï¼Œå°†Açš„ä¸€ä¸ªå‰¯æœ¬åˆ†é…ç»™B

A+=1
print('A:', A)
print('B:', B)
print('A + B:', A + B)  # çŸ©é˜µç›¸åŠ 
print('A * B:', A * B)  # çŸ©é˜µç›¸ä¹˜
```

è¾“å‡º:

```
4.çŸ©é˜µçš„è®¡ç®—
A: tensor([[ 1.,  2.,  3.,  4.],
        [ 5.,  6.,  7.,  8.],
        [ 9., 10., 11., 12.],
        [13., 14., 15., 16.],
        [17., 18., 19., 20.]])
B: tensor([[ 0.,  1.,  2.,  3.],
        [ 4.,  5.,  6.,  7.],
        [ 8.,  9., 10., 11.],
        [12., 13., 14., 15.],
        [16., 17., 18., 19.]])
```

A.clone()å¾—åˆ°çš„å‰¯æœ¬ä¸ä¼šéšç€Açš„åç»­æ”¹å˜è€Œæ”¹å˜

B=A.sum(axis=0,keepdims=True)	ä»…æ²¿ç€ç¬¬0ç»´æ±‚å’Œ,keepdims=Trueç”¨æ¥ä½¿å¾—ç»´åº¦ä¸å˜,ä»è€Œå¯ä»¥è®©A/B,è¿™ä¸ªåœ¨æ±‚å‡å€¼æ—¶ä¹Ÿæ˜¯å¯è¡Œçš„

torch.dot(x, y) å‘é‡ç‚¹ä¹˜(å¯¹åº”ä½ç½®ç›¸ä¹˜å†æ±‚å’Œ)	torch.mv(A, x)å‘é‡ç›¸ä¹˜	(ä»…ä¸€ç»´å¼ é‡)

torch.mul()  çŸ©é˜µçš„ç‚¹ä¹˜											torch.mm()æ˜¯çŸ©é˜µä¹˜æ³•

torch.sum(x * y)é€šè¿‡è¿™æ ·çš„æ–¹å¼ä¹Ÿå¯ä»¥è¡¨è¾¾å‘é‡ç‚¹ä¹˜(å½“ç„¶è€è€å®å®ç”¨å‡½æ•°æœ€å¥½)

torch.norm(u) å‘é‡çš„ğ¿2èŒƒæ•°:	å¹³æ–¹å’Œå†å¼€æ ¹

torch.abs(u).sum() å‘é‡çš„ğ¿1èŒƒæ•°	ç»å¯¹å€¼å’Œ

å‰©ä½™è¯¦è§03-linerâ€¦â€¦



æ³¨æ„:reshapeå¤„ç†çš„tensorå¦‚æœæ˜¯è¿ç»­çš„ï¼Œåˆ™äºviewç›¸åŒï¼Œåœ¨åŸåœ°å€æ”¹å˜ï¼›å¦‚æœä¸è¿ç»­ï¼Œreshapeä¼šç”Ÿæˆä¸€ä¸ªæ–°çš„tensor

å¹¸è¿çš„æ˜¯ï¼Œ(**æ‰§è¡ŒåŸåœ°æ“ä½œ**)éå¸¸ç®€å•ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨åˆ‡ç‰‡è¡¨ç¤ºæ³•å°†æ“ä½œçš„ç»“æœåˆ†é…ç»™å…ˆå‰åˆ†é…çš„æ•°ç»„ï¼Œä¾‹å¦‚`Y[:] = <expression>`ã€‚ä¸ºäº†è¯´æ˜è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªæ–°çš„çŸ©é˜µ`Z`ï¼Œå…¶å½¢çŠ¶ä¸å¦ä¸€ä¸ª`Y`ç›¸åŒï¼Œä½¿ç”¨`zeros_like`æ¥åˆ†é…ä¸€ä¸ªå…¨0çš„å—ã€‚

````python
Z = torch.zeros_like(Y)
print('id(Z):', id(Z))
Z[:] = X + Y
print('id(Z):', id(Z))
````

è¾“å‡ºï¼š

```python
id(Z): 140272150341696
id(Z): 140272150341696
```

ä½¿ç”¨æ­¤æ–¹æ³•ä»¥è¦†ç›–ä»¥å‰çš„å†…å­˜ï¼ŒèŠ‚çœç©ºé—´



#### çŸ©é˜µè®¡ç®—

![image-20220227154649321](ææ²pytorch.assets/image-20220227154649321-16459480115231.png)

å¯¹äºä¸å¯å¾®çš„å‡½æ•°,æœ‰å¦‚ä¸Šäºšå¯¼æ•°



æ ‡é‡yå¯¹äºå‘é‡xçš„æ±‚å¯¼,æœ‰![image-20220227154902887](ææ²pytorch.assets/image-20220227154902887.png)

ä¸¾ä¸ªä¾‹å­,y=(x1)^2+2(x2)^2,![image-20220227154955408](ææ²pytorch.assets/image-20220227154955408.png)

æ±‚å¯¼å¾—åˆ°ä¸€ä¸ªå‘é‡



![image-20220227155214304](ææ²pytorch.assets/image-20220227155214304-16459483359572.png)

![image-20220227155226839](ææ²pytorch.assets/image-20220227155226839-16459483490163.png)

å¦‚ä¸Šæ˜¯ä¸€äº›çŸ©é˜µçš„æ±‚å¯¼(ä¹Ÿæ²¡å¿…è¦æ­»è®°,ä¸äº†è§£å°±ç®—äº†)

![image-20220227155514831](ææ²pytorch.assets/image-20220227155514831-16459485165164.png)

å› ä¸ºå‘é‡æ‰€åœ¨ä½ç½®ä¸åŒè€Œå¯¼è‡´çŸ©é˜µçš„æ–¹å‘ä¸åŒ

![image-20220227155613992](ææ²pytorch.assets/image-20220227155613992.png)

å¦‚ä¸Šåˆ™æ˜¯ä¸€ä¸ªå‘é‡é™¤ä»¥å‘é‡çš„ä¾‹å­

### è‡ªåŠ¨æ±‚å¯¼(ä»æ ‡é‡åˆ°å‘é‡)

åŸç†ï¼šé“¾å¼æ³•åˆ™

![image-20211112194359024](image-20211112194359024.png)

æ ‡é‡*å‘é‡=å‘é‡ï¼Œå‘é‡ *å‘é‡=å‘é‡

éšå¼æ„é€ ï¼šç³»ç»Ÿå°†ä½ æ¯ä¸€æ­¥çš„è®¡ç®—è®°å½•ä¸‹æ¥ï¼Œä¸ç”¨è‡ªå·±æ‰‹åŠ¨è®¡ç®—

pytorchæ˜¯åå‘æ±‚å¯¼back propagation  

åå‘ä¼ æ’­ï¼šè®¡ç®—å¤æ‚åº¦O(n),å†…å­˜å¤æ‚åº¦O(n)

æ­£å‘ç§¯ç´¯ï¼šè®¡ç®—å¤æ‚åº¦O(n),å†…å­˜å¤æ‚åº¦O(1)ï¼Œä½†æ˜¯éœ€è¦æ‰«ææ¯ä¸€å±‚çš„æ‰€æœ‰å‚æ•°ï¼Œæ‰€ä»¥ä¸å¦‚åå‘ä¼ æ’­(ä¸€èˆ¬è€Œè¨€)

ä»£ç å‚è€ƒ05-autograd

```python
print('1.è‡ªåŠ¨æ¢¯åº¦è®¡ç®—')
x = torch.arange(4.0, requires_grad=True)  # 1.å°†æ¢¯åº¦é™„åŠ åˆ°æƒ³è¦å¯¹å…¶è®¡ç®—åå¯¼æ•°çš„å˜é‡
print('x:', x)
print('x.grad:', x.grad)
y = 2 * torch.dot(x, x)  # 2.è®°å½•ç›®æ ‡å€¼çš„è®¡ç®—
print('y:', y)
y.backward()  # 3.æ‰§è¡Œå®ƒçš„åå‘ä¼ æ’­å‡½æ•°
print('x.grad:', x.grad)  # 4.è®¿é—®å¾—åˆ°çš„æ¢¯åº¦
print('x.grad == 4*x:', x.grad == 4 * x)

```

è¾“å‡ºå¦‚ä¸‹:

```python
1.è‡ªåŠ¨æ¢¯åº¦è®¡ç®—
x: tensor([0., 1., 2., 3.], requires_grad=True)
x.grad: None
y: tensor(28., grad_fn=<MulBackward0>)
x.grad: tensor([ 0.,  4.,  8., 12.])
x.grad == 4*x: tensor([True, True, True, True])
y: tensor(6., grad_fn=<SumBackward0>)
x.grad: tensor([1., 1., 1., 1.])
x: tensor([0., 1., 2., 3.], requires_grad=True)
x.grad: tensor([0., 2., 4., 6.])
```

æ‰§è¡Œy.backwardä»¥å,å³å¯è¾“å‡ºx.grad(å³xå¯¹äºyçš„æ¢¯åº¦)

 requires_grad=Trueç”¨äºä¿ç•™æ¢¯åº¦ä¿¡æ¯,è¦ç•™ç€

```python
x.grad.zero_()
```

ç”¨äºæ¢¯åº¦æ¸…é›¶,ä¸æ¸…é›¶ä¼šä½¿å¾—ä¹‹å‰è®¡ç®—çš„æ¢¯åº¦å’Œä»¥åè®¡ç®—çš„æ¢¯åº¦å åŠ 



éƒ¨åˆ†æ²¡åšç¬”è®°çš„éƒ¨åˆ†è¯¦è§ä»£ç 

## D:\numpy+deep learning\ææ²è¯¾ä»¶\dive_into_deep_learning-main\ch02



batchsizeè¶Šå°æ”¶æ•›åè€Œè¶Šå¥½,è¿‡å¤§çš„batchåè€Œä¸å¥½,å› ä¸ºå™ªéŸ³å¯¹ç¥ç»ç½‘ç»œå¹¶ä¸æ˜¯åäº‹,å°batchåˆ©äºæ·±åº¦ç¥ç»ç½‘ç»œä¸è¿‡æ‹Ÿåˆ

æ­£åˆ™é¡¹ä¸æ”¾åœ¨æŸå¤±å‡½æ•°å†…,æ­£åˆ™åŒ–æ–¹æ³•éå¸¸å¤š

##### All models are wrong, some are useful. æœºå™¨å­¦ä¹ å¾ˆå¤šæ˜¯ç¡¬å»æŠ“è§„å¾‹çš„ã€‚æ‰€ä»¥å³ä½¿æ‰¾åˆ°äº†å…¨å±€æœ€ä¼˜è§£,ä¹Ÿä¸ä¸€å®šçœŸçš„å°±æœ‰è‰¯å¥½çš„æ³›åŒ–æ€§.è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆSGDçœ‹èµ·æ¥æ…¢è€Œä¸”æ•ˆæœä¸ä¸€å®šç†æƒ³,ä½†å´æ˜¯æœ€å¸¸è§æœ€é€šç”¨çš„ä¼˜åŒ–å™¨ä¹‹ä¸€

ç°åœ¨çš„ä¼˜åŒ–æ–¹æ³•ï¼Œä¸»è¦æ˜¯å‡¸ä¼˜åŒ–çš„ï¼Œéå‡¸é—®é¢˜è§£å†³çš„ä¸å¾ˆå¥½ã€‚(å‡¸ä¼˜åŒ–éƒ½å¥½ä¹…æ²¡çœ‹è¿‡äº†,æœ‰ç©ºå»æ¸©ä¹ ä¸€ä¸‹)



detach()å‡½æ•°	æ‰€æœ‰çš„è¿ç®—å­ä¼šè‡ªåŠ¨åŠ å…¥è®¡ç®—å›¾æ±‚æ¢¯åº¦ï¼Œdetachå¯ä»¥æŠŠä¸éœ€è¦æ±‚æ¢¯åº¦çš„è¿ç®—åˆ†ç¦»å¼€



da ta-iterå†™æ³•æœ‰å¯èƒ½å¯¼è‡´å†…å­˜è¿‡å¤§(å¾ˆå°å¯èƒ½)



indicesä¸ä¸€å®šè¦è½¬åŒ–æˆtensor,å› ä¸ºtensorå¯èƒ½æ˜¯åˆ—è¡¨æˆ–è€…å…ƒç»„å®ç°çš„ï¼Œå°±åƒåˆ—è¡¨åº•å±‚æ˜¯å…ƒç»„å®ç°çš„ï¼Œåªè¦èƒ½è¾¾åˆ°ç›®çš„å·¥å…·æ˜¯ä»€ä¹ˆæ ·ä¸é‚£ä¹ˆé‡è¦



*Adaptive* Boostingè‡ªé€‚åº”å¢å¼º,Adamç­‰éƒ½å¯ä»¥ç”¨äºåˆ¤æ–­æ”¶æ•›



ä¸€èˆ¬è€Œè¨€æ·±åº¦å­¦ä¹ çš„é—®é¢˜éƒ½æ˜¯æ²¡æœ‰æ˜¾å¼è§£çš„,æœ‰æ˜¾å¼è§£çš„é—®é¢˜ä¹Ÿä¸éœ€è¦æ·±åº¦å­¦ä¹ æ¥è§£å†³



#### åˆ†ç±»ä¸å›å½’

å›å½’ï¼šé¢„æµ‹ä¸€ä¸ªè¿ç»­å€¼		åˆ†ç±»ï¼šé¢„æµ‹ä¸€ä¸ªç¦»æ•£å€¼(ç±»)



å¯¹äºåˆ†ç±»é—®é¢˜,æˆ‘ä»¬å¹¶ä¸éœ€è¦é¢„æµ‹å€¼çš„ç½®ä¿¡åº¦ç‰¹åˆ«é«˜,é‡ç‚¹æ˜¯**çœŸç±»çš„ç½®ä¿¡åº¦è¿œå¤§äºå…¶ä»–ç±»**,æ»¡è¶³æ­¤æ¡ä»¶çš„æƒ…å†µä¸‹å³ä½¿ç½®ä¿¡åº¦ä¸é«˜ä¹Ÿæ— å¦¨



![img](ææ²pytorch.assets/v2-39eca1f41fe487983f5111f5e5073396_720w.jpg)

softmaxå‡½æ•°å¦‚ä¸Š

![image-20220228130056379](ææ²pytorch.assets/image-20220228130056379-16460244573112.png)

ä½¿ç”¨æŒ‡æ•°å‡½æ•°,æ›´èƒ½çªå‡ºç½®ä¿¡åº¦é«˜çš„å€¼



![image-20220228130353099](ææ²pytorch.assets/image-20220228130353099-16460246349833.png)

å› ä¸ºæˆ‘çš„çœŸå®æ ‡ç­¾æ˜¯one-hotå˜é‡ï¼Œåªæœ‰ä¸€ä¸ªä¸º1ï¼Œæ‰€ä»¥åªéœ€è¦æ±‚çœŸå®æ ‡ç­¾ä¸º1å¯¹åº”çš„é‚£ä¸ªé¢„æµ‹å€¼,å³å¯æ±‚å‡ºloss'



ä¸€äº›ç®€å•çš„LossæŸå¤±å‡½æ•°

L2 Loss	![image-20220228130722539](ææ²pytorch.assets/image-20220228130722539-16460248451034.png)

å¸¸ç”¨,æ•ˆæœä¹Ÿä¸å·®



L1 Loss![image-20220228131158787](ææ²pytorch.assets/image-20220228131158787-16460251199495.png)

ä¸å¤§å¸¸ç”¨,å› ä¸º0ç‚¹å¤„ä¸å¯å¯¼,è¦å€ŸåŠ©äºšå¯¼æ•°,ä¸åˆ’ç®—



Huber's Robust Loss![image-20220228131448643](ææ²pytorch.assets/image-20220228131448643-16460252898406.png)

ç»“åˆäº†ä»¥ä¸ŠL1 L2	losså‡½æ•°



### ä»¥midistä¸ºä¾‹,ä¸‹è½½å¹¶è½½å…¥æ•°æ®é›†

```python
def load_data_fashion_mnist(batch_size, resize=None):  #@save
    """ä¸‹è½½Fashion-MNISTæ•°æ®é›†ï¼Œç„¶åå°†å…¶åŠ è½½åˆ°å†…å­˜ä¸­"""
    trans = [transforms.ToTensor()]
    if resize:
        trans.insert(0, transforms.Resize(resize))
    trans = transforms.Compose(trans)
    mnist_train = torchvision.datasets.FashionMNIST(
        root="../data", train=True, transform=trans, download=True)
    mnist_test = torchvision.datasets.FashionMNIST(
        root="../data", train=False, transform=trans, download=True)
    return (data.DataLoader(mnist_train, batch_size, shuffle=True,
                            num_workers=get_dataloader_workers()),
            data.DataLoader(mnist_test, batch_size, shuffle=False,
                            num_workers=get_dataloader_workers()))
```

å¦‚ä¸Š,é€šè¿‡data.DataLoaderå‡½æ•°è½½å…¥äº†è®­ç»ƒé›†å’Œæµ‹è¯•é›†,shuffle=Trueæ§åˆ¶æ˜¯å¦è¿›è¡Œåå‘ä¼ æ’­(testé›†æ˜¯ä¸èƒ½ç”¨æ¥è®­ç»ƒçš„)



```python
def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):  #@save
    """è®­ç»ƒæ¨¡å‹ï¼ˆå®šä¹‰è§ç¬¬3ç« ï¼‰"""
    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],
                        legend=['train loss', 'train acc', 'test acc'])
    for epoch in range(num_epochs):
        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)
        test_acc = evaluate_accuracy(net, test_iter)
        animator.add(epoch + 1, train_metrics + (test_acc,))
    train_loss, train_acc = train_metrics
    assert train_loss < 0.5, train_loss
    assert train_acc <= 1 and train_acc > 0.7, train_acc
    assert test_acc <= 1 and test_acc > 0.7, test_acc
```

æå‰å®šä¹‰ä¸€ä¸ªè®­ç»ƒå‡½æ•°(éœ€è¦çš„å‚æ•°å‡ ä¹éƒ½å¯ä»¥åœ¨nn. çš„å‡½æ•°ä¸­æ‰¾åˆ°)



è¯¦è§http://localhost:8888/notebooks/d2l-zh%20(1)/pytorch/chapter_linear-networks/softmax-regression-scratch.ipynb



nn.CrossEntropyLoss = nn.softmax + nn.log + nn.NLLLossï¼Œä¹Ÿå°±æ˜¯apiè‡ªå¸¦çš„çš„äº¤å‰ç†µæŸå¤±å‡½æ•°å·²ç»æŠŠsoftmaxè‡ªåŠ¨ç®—äº†.

###  æ„ŸçŸ¥æœº

![image-20220228214100325](ææ²pytorch.assets/image-20220228214100325-16460556625657.png)

å³è¾“å…¥ç»è¿‡è¿ç®—,è¾¾æˆæ¡ä»¶è¾“å‡º1,å¦åˆ™è¾“å‡º0(å³å®ç°ä¸€ä¸ªäºŒåˆ†ç±»)



![image-20220228214512355](ææ²pytorch.assets/image-20220228214512355.png)

å¼‚å·åˆ™è¾“å‡ºä¸ºè´Ÿ,æ‰€ä»¥éœ€è¦æ›´æ–°

ä¸‹é¢çš„losså‡½æ•°åˆ™æ˜¯:å¦‚æœä¸Šé¢çš„yi[<w,xi>+b]<0,åˆ™loss=-yi[<w,xi>+b]

æ‰€ä»¥æ˜¯æ‰¹é‡batchä¸º1çš„æ¢¯åº¦ä¸‹é™

![image-20220228215345966](ææ²pytorch.assets/image-20220228215345966-16460564280098.png)

æ„ŸçŸ¥æœºçš„æ”¶æ•›:åœ¨rä¸ºåŠå¾„çš„åŒºåŸŸå†…,åˆ†ç±»è¯¯å·®å°äºé¢„è®¾ä½™é‡ or æ­¥æ•°è¶…è¿‡â€¦â€¦æ­¥åæ”¶æ•›



#### å¤šå±‚æ„ŸçŸ¥æœº:ä½ç»´åº¦çš„å¹³é¢ä¸èƒ½åˆ†å‰²çš„äº‹ç‰©,é€šè¿‡å¤šå±‚æ„ŸçŸ¥æœºå‡ç»´æ¥è§£å†³

è€Œä¸”é€šè¿‡éšè—å±‚å’Œæ¿€æ´»å‡½æ•°(sigmoid,tanh,relu)å¾—åˆ°äº†éçº¿æ€§æ¨¡å‹



#### è®­ç»ƒè¯¯å·®å’Œæ³›åŒ–è¯¯å·®

è®­ç»ƒè¯¯å·®training lossï¼šæ¨¡æ‹Ÿè€ƒï¼Œå¯ä»¥æ€»ç»“ç»éªŒï¼ˆå¯ä»¥ç”¨äºè®­ç»ƒï¼‰,å¤ªå°ä¸ä¸€å®šå¥½,å¯èƒ½æ˜¯è¿‡æ‹Ÿåˆ

æ³›åŒ–è¯¯å·®ï¼šæœŸæœ«è€ƒï¼ˆä¸èƒ½ç”¨äºè®­ç»ƒï¼‰,è¶Šå°è¶Šå¥½



è®­ç»ƒtraining_data,éªŒè¯dev_data,æµ‹è¯•test_data	ä¸è¦æ··æ·†

**devæ˜¯ä¸å¯ä»¥ç”¨äºè®­ç»ƒçš„**,å±äºæ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æŸ¥çœ‹è®­ç»ƒæ•ˆæœçš„æ–¹æ³•

åƒä¸‡ä¸è¦å’Œtraining_dataæ··åœ¨ä¸€èµ·

 mnist_dev = torchvision.datasets.FashionMNIST(
        root="../data", train=False, transform=trans, download=True)

è€Œtesté›†åªèƒ½è·‘1æ¬¡,å³æ¨¡å‹è§£å†³åçš„é‚£æ¬¡



- devç”¨æ¥ç»Ÿè®¡çš„é‚£ä¸€è¯„ä¼°æŒ‡æ ‡ã€è°ƒèŠ‚å‚æ•°ï¼Œé€‰æ‹©ç®—æ³•ï¼›è€Œtestç”¨æ¥åœ¨æœ€åæ•´ä½“è¯„ä¼°æ¨¡å‹æ€§èƒ½
- devå’Œè®­ç»ƒé›†ä¸€èµ·è¢«è¾“å…¥åˆ°æ¨¡å‹ç®—æ³•ä¸­ï¼Œä½†åˆä¸å‚ä¸æ¨¡å‹è®­ç»ƒï¼Œå¯ä»¥ä¸€è¾¹è®­ç»ƒä¸€è¾¹æ ¹æ®devæŸ¥çœ‹æŒ‡æ ‡



kæŠ˜äº¤å‰éªŒè¯

![image-20220301124101171](ææ²pytorch.assets/image-20220301124101171-16461096632671.png)

æ•°æ®ä¸å¤Ÿç”¨çš„æ—¶å€™çš„åšæ³•,å½“ç„¶è¿™ä¸ªæ—¶å€™æ•°æ®å¢å¼ºä¹Ÿåˆé€‚

æ•°æ®å¤Ÿçš„æ—¶å€™ç®—10æ¬¡å°±å¤ªæŠ˜ç£¨äº†,åˆ«å‚»æ†¨æ†¨çš„



![image-20220301125011317](ææ²pytorch.assets/image-20220301125011317-16461102133692.png)



ä¸€å›¾è§£æ¨¡å‹å®¹é‡(å¤æ‚åº¦),å’Œä¸¤ç±»è¯¯å·®é—´çš„å…³ç³»



è€Œå¤æ‚åº¦çš„è®¡ç®—å¯ä»¥ç”±â€”â€”å‚æ•°ä¸ªæ•°å’Œå‚æ•°é€‰æ‹©èŒƒå›´æ¥é¢„ä¼°(æ²¡æœ‰ä¸€ä¸ªå‡†ç¡®çš„å€¼æˆ–å…¬å¼æ¯”è¾ƒ )



VCç»´:å¯¹äºä¸€ä¸ªåˆ†ç±»æ¨¡å‹,VCç­‰äºä¸€ä¸ªæœ€å¤§çš„æ•°æ®é›†çš„å¤§å°.ä¸ç®¡å¦‚ä½•ç»™å®šæ ‡å·,éƒ½å­˜åœ¨ä¸€ä¸ªæ¨¡å‹å¯¹å®ƒè¿›è¡Œå®Œç¾åˆ†ç±»(ç†è®ºä¸Š)



![image-20220301131043054](ææ²pytorch.assets/image-20220301131043054-16461114442543.png)

äºŒç»´æ„ŸçŸ¥æœºçš„VCç»´æ˜¯3,å³èƒ½åŒºåˆ†**ä»»æ„**3ä¸ªç‚¹çš„åˆ†ç±»,ä½†æ˜¯4ä¸ªç‚¹å­˜åœ¨xorå…³ç³»(å¼‚æˆ–),æ‰€ä»¥ä¸æ˜¯4



<img src="ææ²pytorch.assets/image-20220301131340188.png" alt="image-20220301131340188" style="zoom:50%;" />

è¿™ä¸ªå°±æ›´åŠ ä¸å¥½è¡¡é‡,å› ç´ å¤ªå¤šäº†



kernel_SVMå¯¹äºåºå¤§çš„æ•°æ®é›†(åä¸‡ç™¾ä¸‡ä¸ªç‚¹)æ•ˆæœå¹¶ä¸å¤§å¥½,ç¥ç»ç½‘ç»œåœ¨è¿™æ–¹é¢æ•ˆæœå¥½

å› ä¸ºå¤§çš„SVMè®­ç»ƒå¤ªè´µäº†,æ²¡å¿…è¦ç”¨SVMæ‹Ÿåˆ

SVMçš„å¯è§£é‡Šæ€§è¾ƒå¥½(æœ‰æ˜ç¡®çš„æ•°å­¦è§£é‡Š),ä½†æ˜¯èƒ½åŠ›ä¸å¦‚ç¥ç»ç½‘ç»œ



##### æƒé‡è¡°é€€ä¸é™åˆ¶

![image-20220301141109031](ææ²pytorch.assets/image-20220301141109031-16461150707005.png)

é€šè¿‡è¿™æ ·çš„å‚æ•°èŒƒå›´é™åˆ¶å¼€æ§åˆ¶æ¨¡å‹å®¹é‡ 





![image-20220301143155978](ææ²pytorch.assets/image-20220301143155978-16461163179946.png)

å°±æ˜¯è¯´ï¼Œl2æ­£åˆ™é¡¹ä¼šå¯¹å¤§æ•°å€¼çš„æƒå€¼è¿›è¡Œæƒ©ç½šï¼Œé¼“åŠ±æƒå€¼åˆ†æ•£ï¼Œå°†æ‰€æœ‰é¢ç‰¹å¾è¿ç”¨èµ·æ¥ï¼Œè€Œä¸æ˜¯ä¾èµ–å…¶ä¸­çš„å°‘æ•°ç‰¹å¾





<img src="ææ²pytorch.assets/image-20220301143408061.png" alt="image-20220301143408061" style="zoom:50%;" />

é˜²æ­¢å¡åœ¨å‘çš„ä¸¤è¾¹ä¸‹é™ä¸åˆ°æœ€ä¼˜ç‚¹

![image-20220301144436898](ææ²pytorch.assets/image-20220301144436898-16461170778168.png)

æƒé‡è¡°é€€é™åˆ¶äº†æ¨¡å‹å‚æ•°å¤§å°,ä»è€Œæ§åˆ¶æ¨¡å‹å¤æ‚åº¦  

  

#### dropoutä¸¢å¼ƒæ³•

ä»…åœ¨å…¨è¿æ¥å±‚ä½¿ç”¨

sigmoidå’Œsoftmaxè¿™ä¸¤ä¸ªæ¿€æ´»å‡½æ•°è·Ÿdropoutçš„é¡ºåºæœ‰è®²ç©¶ï¼Œä½†æ˜¯reluæ²¡æœ‰ï¼Œå› ä¸ºreluå°±æ˜¯ä¸€ä¸ªçº¿æ€§çš„å‡½æ•°ï¼Œå…ˆé™¤ä»¥ï¼ˆ1-pï¼‰æˆ–è€…åé™¤ä»¥ï¼ˆ1-pï¼‰å…¶å®æ²¡æœ‰å½±å“ã€‚ä¸è¿‡ï¼Œsigmoidå’Œsoftmaxçš„è¯ï¼Œå¾—å…ˆdropoutç„¶åå†è¿›æ¿€æ´»å‡½æ•°ï¼Œå› ä¸ºå¯¹äºè¾“å…¥åšdropoutå’Œå¯¹è¾“å‡ºåšdropoutæ˜¯ä¸ä¸€æ ·çš„

<img src="ææ²pytorch.assets/image-20220301154732913.png" alt="image-20220301154732913" style="zoom:50%;" />

å¦‚ä¸Šdropout,ä½¿å¾—è¾“å‡ºå€¼æ”¹å˜(æ¯•ç«Ÿå°‘äº†ä¸€äº›å±‚),ä½†æ˜¯æœŸæœ›ä¸å˜(x_ié™¤ä»¥äº†ä¸è¢«dropoutçš„æ¦‚ç‡(1-p))

![image-20220301155744458](ææ²pytorch.assets/image-20220301155744458-16461214658069.png)

å¦‚ä¸Š,è¿›è¡Œäº†ä¸€æ¬¡dropout,,å‡å°‘äº†éšè—å±‚çš„æ•°ç›®,é™ä½äº†å¤æ‚åº¦

dropoutåŸºæœ¬ä¸Šæ˜¯æ¯ä¸ªbatchæ¢ä¸€æ¬¡æ¨¡å‹(é‡æ–°é€‰æ‹©è¾“å‡ºè¢«ç½®é›¶çš„ç¥ç»å…ƒ)

å¥¥å¡å§†å‰ƒåˆ€:å®ç°ç›®æ ‡çš„å‡½æ•°è¶Šç®€å•è¶Šå¥½

ä»¥ä¸‹ä¸ºdropoutçš„å‡½æ•°

```python
def dropout_layer(X, dropout):
    assert 0 <= dropout <= 1
    # åœ¨æœ¬æƒ…å†µä¸­ï¼Œæ‰€æœ‰å…ƒç´ éƒ½è¢«ä¸¢å¼ƒ
    if dropout == 1:
        return torch.zeros_like(X)
    # åœ¨æœ¬æƒ…å†µä¸­ï¼Œæ‰€æœ‰å…ƒç´ éƒ½è¢«ä¿ç•™
    if dropout == 0:
        return X
    mask = (torch.rand(X.shape) > dropout).float()
    return mask * X / (1.0 - dropout)
```

ç„¶åå†é€šè¿‡ä»¥ä¸‹apiå³å¯å°†å‚æ•°è¿›è¡Œå˜åŒ–

```
dropout_layer(X, 0.)
```

0.ä¿®æ”¹ä¸ºéšè—ä¸€ä¸ªç¥ç»å…ƒçš„æ¦‚ç‡



```python
class Net(nn.Module):
    def __init__(self, num_inputs, num_outputs, num_hiddens1, num_hiddens2,
                 is_training = True):
        super(Net, self).__init__()
        self.num_inputs = num_inputs
        self.training = is_training
        self.lin1 = nn.Linear(num_inputs, num_hiddens1)
        self.lin2 = nn.Linear(num_hiddens1, num_hiddens2)
        self.lin3 = nn.Linear(num_hiddens2, num_outputs)
        self.relu = nn.ReLU()

    def forward(self, X):
        H1 = self.relu(self.lin1(X.reshape((-1, self.num_inputs))))
        # åªæœ‰åœ¨è®­ç»ƒæ¨¡å‹æ—¶æ‰ä½¿ç”¨dropout
        if self.training == True:
            # åœ¨ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚ä¹‹åæ·»åŠ ä¸€ä¸ªdropoutå±‚
            H1 = dropout_layer(H1, dropout1)
        H2 = self.relu(self.lin2(H1))
        if self.training == True:
            # åœ¨ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚ä¹‹åæ·»åŠ ä¸€ä¸ªdropoutå±‚
            H2 = dropout_layer(H2, dropout2)
        out = self.lin3(H2)
        return out


net = Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2)
```

ç½‘ç»œå¤šä¸€ä¸ªis_trainingçš„å‚æ•°,åœ¨è®­ç»ƒæ—¶æ‰ä½¿ç”¨dropout,è€Œä¸”å…ˆdropoutå†relu

æ³¨æ„,ä½¿ç”¨classçš„å†™æ³•æ›´å¥½,æ›´åŠ é¢å‘å¯¹è±¡,å½“ç„¶è¿™é‡Œä¸€å±‚å±‚å†™ä¸å»ºè®®è¿™ä¹ˆåš

```python
dropout1, dropout2 = 0.2, 0.5
num_epochs, lr, batch_size = 10, 0.5, 256
loss = nn.CrossEntropyLoss(reduction='none')

train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
trainer = torch.optim.SGD(net.parameters(), lr=lr)
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)

net = nn.Sequential(nn.Flatten(),
        nn.Linear(784, 256),
        nn.ReLU(),
        # åœ¨ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚ä¹‹åæ·»åŠ ä¸€ä¸ªdropoutå±‚
        nn.Dropout(dropout1),
        nn.Linear(256, 256),
        nn.ReLU(),
        # åœ¨ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚ä¹‹åæ·»åŠ ä¸€ä¸ªdropoutå±‚
        nn.Dropout(dropout2),
        nn.Linear(256, 10))

def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01)

net.apply(init_weights);



trainer = torch.optim.SGD(net.parameters(), lr=lr)
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)
```

ç„¶åç›´æ¥è°ƒç”¨å°±è¡Œ

![image-20220301214159456](ææ²pytorch.assets/image-20220301214159456-164614212115810.png)

ä¸dropoutçš„æƒ…å†µ(æŠŠdropout1, dropout2=0å°±è¡Œ)

dropoutå›ºå®šä½randon seedçš„æƒ…å†µä¸‹å¯é‡å¤æ€§ä¸ä½,è¿™ä¹Ÿæ˜¯æ¯”è¾ƒå¥½çš„åœ°æ–¹ 



ä¼˜ç‚¹:dropoutçš„è¶…å‚æ•°**P**æ¯”**æƒé‡è¡°é€€çš„Î»**å¥½è°ƒå‚,æ‰€ä»¥ç”¨çš„äººæ›´å¤š 



#### æ•°å€¼ç¨³å®šæ€§çš„ä¸¤ä¸ªå¸¸è§é—®é¢˜:

![image-20220301223211555](ææ²pytorch.assets/image-20220301223211555.png)

â€‹						æ¢¯åº¦çˆ†ç‚¸														æ¢¯åº¦è¡°å‡

##### 

#### æ¢¯åº¦çˆ†ç‚¸

![image-20220302130115404](ææ²pytorch.assets/image-20220302130115404-16461972782831.png)

å¦‚å›¾ï¼Œæ¢¯åº¦çš„é“¾å¼æ³•åˆ™å†³å®šäº†æ¢¯åº¦å¾ˆå®¹æ˜“çˆ†ç‚¸æˆ–è€…æ¶ˆå¤± 

æ¢¯åº¦çˆ†ç‚¸å¾ˆæœ‰å¯èƒ½å¯¼è‡´è¶…å‡ºå€¼åŸŸ(infinity),ä»è€Œæ— æ³•ç»§ç»­è®­ç»ƒ

è€Œä¸”â€”â€”

```
å¤§å­¦ä¹ ç‡-->å¤§å‚æ•°->å¤§æ¢¯åº¦
å°å­¦ä¹ ç‡->è®­ç»ƒä¸åŠ¨
```

æ‰€ä»¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸æ–­è°ƒæ•´å­¦ä¹ ç‡ä¹Ÿæ˜¯æœ‰å¿…è¦çš„ 

#### æ¢¯åº¦æ¶ˆå¤±

### <img src="ææ²pytorch.assets/image-20220301225309509.png" alt="image-20220301225309509" style="zoom: 67%;" />

åœ¨xè¿‡å¤§åŠè¿‡å°æ—¶æ¢¯åº¦éå¸¸å°,ä»è€Œä¼šæœ‰å¤šä¸ªå°æ¢¯åº¦ç›¸ä¹˜(é“¾å¼æ³•åˆ™),æœ€åå¯¼è‡´æ¢¯åº¦æ¥è¿‘0

äº§ç”Ÿçš„é—®é¢˜ 

<img src="ææ²pytorch.assets/image-20220301225523775.png" alt="image-20220301225523775" style="zoom:67%;" />

#### è®©è®­ç»ƒæ›´ç¨³å®š

1.æ¢¯åº¦å€¼åœ¨åˆç†èŒƒå›´å†…

2.ä¹˜æ³•å˜åŠ æ³• ResNet,LSTM

3.å½’ä¸€åŒ–(æ¢¯åº¦å½’ä¸€åŒ–,æ¢¯åº¦è£å‰ª)

4.è®¾ç½®åˆç†çš„åˆå§‹æƒé‡å’Œæ¿€æ´»å‡½æ•° 

å¯¹äºå°ç½‘ç»œ,N(0,0.01)ä½œä¸ºåˆå§‹æ²¡é—®é¢˜,ä½†æ˜¯å¤§ç½‘ç»œå°±è¦è€ƒè™‘ä¸€ä¸‹äº†.

##### æ•°å€¼è°ƒæ•´

1. è°ƒæ•´å„å±‚å¾—åˆ°:ç›¸ç­‰çš„æ–¹å·®å’Œå‡å€¼

   Xavieråˆå§‹ï¼Œå‚è€ƒä»¥ä¸‹ç½‘ç«™

https://blog.csdn.net/shuzfan/article/details/51338178

![image-20220302132812097](ææ²pytorch.assets/image-20220302132812097-16461988938762.png)

![image-20220303131907090](ææ²pytorch.assets/image-20220303131907090-16462847490991.png)

```python
all_features[numeric_features] = all_features[numeric_features].apply(
    lambda x: (x - x.mean()) / (x.std()))
```

é€šè¿‡è¿™ä¸ªä»£ç å®ç°æ­£åˆ™åŒ–æ•°æ®(ä¸Šé¢çš„å…¬å¼ ),ä¸€èˆ¬è€Œè¨€è¿™ä¸ªæ–¹æ³•åªèƒ½æ­£åˆ™è‡ªå·±çš„training_data



é€šè¿‡è¿™æ ·çš„è®¡ç®—ï¼Œä½¿å¾—æ•°æ®å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1(å³å®ç°äº†ä¸€ä¸ªæ­£åˆ™åŒ–)



ç›®å‰çš„ç»å¤§å¤šæ•°æ‰‹æ®µåªèƒ½ç¼“è§£æ•°å€¼ä¸ç¨³å®šï¼Œä¸èƒ½è§£å†³æ•°å€¼ä¸ç¨³å®šé—®é¢˜

å‡å€¼æ–¹å·®åšé™åˆ¶ï¼Œé˜»æ­¢äº†æå¤§æˆ–æå°å€¼å‡ºç°çš„æ¦‚ç‡

![image-20220302133348162](ææ²pytorch.assets/image-20220302133348162-16461992297304.png)



å¦‚å›¾ï¼Œå³æ‰€éœ€çš„æ¿€æ´»å‡½æ•°å¿…é¡»è¿‡åœ†ç‚¹ï¼ˆÎ²=0)



![ ](ææ²pytorch.assets/image-20220302133335521-16461992174683.png)

è€Œé€šè¿‡æ³°å‹’å±•å¼€å¯çŸ¥ï¼Œsigmoidå‡½æ•°ä¸è¿‡åŸç‚¹ï¼Œæ‰€ä»¥éœ€è¦ä¸€äº›å¹³ç§»å’Œæ”¾ç¼©è¿›è¡Œè°ƒæ•´

### ç¥ç»ç½‘ç»œåŸºç¡€

##### 5.æ¨¡å‹æ„é€ 

å®ä¾‹:

http://localhost:8888/notebooks/d2l-zh%20(1)/pytorch/chapter_deep-learning-computation/model-construction.ipynb

```python
class MLP(nn.Module):
    # ç”¨æ¨¡å‹å‚æ•°å£°æ˜å±‚ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬å£°æ˜ä¸¤ä¸ªå…¨è¿æ¥çš„å±‚
    def __init__(self):
        # è°ƒç”¨MLPçš„çˆ¶ç±»Moduleçš„æ„é€ å‡½æ•°æ¥æ‰§è¡Œå¿…è¦çš„åˆå§‹åŒ–ã€‚
        # è¿™æ ·ï¼Œåœ¨ç±»å®ä¾‹åŒ–æ—¶ä¹Ÿå¯ä»¥æŒ‡å®šå…¶ä»–å‡½æ•°å‚æ•°ï¼Œä¾‹å¦‚æ¨¡å‹å‚æ•°paramsï¼ˆç¨åå°†ä»‹ç»ï¼‰
        super().__init__()	#ç»§æ‰¿çˆ¶ç±»çš„åˆå§‹åŒ–å‡½æ•°,å¾—åˆ°å¤§é‡çš„å‡½æ•°
        self.hidden = nn.Linear(20, 256)  # éšè—å±‚
        self.out = nn.Linear(256, 10)  # è¾“å‡ºå±‚

    # å®šä¹‰æ¨¡å‹çš„å‰å‘ä¼ æ’­ï¼Œå³å¦‚ä½•æ ¹æ®è¾“å…¥Xè¿”å›æ‰€éœ€çš„æ¨¡å‹è¾“å‡º
    def forward(self, X):
        # æ³¨æ„ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ReLUçš„å‡½æ•°ç‰ˆæœ¬ï¼Œå…¶åœ¨nn.functionalæ¨¡å—ä¸­å®šä¹‰ã€‚
        return self.out(F.relu(self.hidden(X)))
```

ä»¥ä¸Šä¸ºå®šä¹‰ä¸€ä¸ªå‘½åä¸ºMLPçš„ç±»,ç±»åŒ…å«ç»§æ‰¿çš„å‡½æ•°

```python
net = MLP()
net(X)
```

ä½¿ç”¨è¿™æ ·çš„ä¸¤è¡Œä»£ç å³å¯è½»æ¾è°ƒç”¨MLP



## [**é¡ºåºå—**]

```python
class MySequential(nn.Module):
    def __init__(self, *args):
        super().__init__()
        for idx, module in enumerate(args):
            # è¿™é‡Œï¼Œmoduleæ˜¯Moduleå­ç±»çš„ä¸€ä¸ªå®ä¾‹ã€‚æˆ‘ä»¬æŠŠå®ƒä¿å­˜åœ¨'Module'ç±»çš„æˆå‘˜
            # å˜é‡_modulesä¸­ã€‚moduleçš„ç±»å‹æ˜¯OrderedDict
            self._modules[str(idx)] = module

    def forward(self, X):
        # OrderedDictä¿è¯äº†æŒ‰ç…§æˆå‘˜æ·»åŠ çš„é¡ºåºéå†å®ƒä»¬
        for block in self._modules.values():
            X = block(X)
        return X
```



1. ä¸€ç§å°†å—é€ä¸ªè¿½åŠ åˆ°åˆ—è¡¨ä¸­çš„å‡½æ•°ã€‚
2. ä¸€ç§å‰å‘ä¼ æ’­å‡½æ•°ï¼Œç”¨äºå°†è¾“å…¥æŒ‰è¿½åŠ å—çš„é¡ºåºä¼ é€’ç»™å—ç»„æˆçš„â€œé“¾æ¡â€ã€‚

```python
net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))
net(X)
```

å½“`MySequential`çš„å‰å‘ä¼ æ’­å‡½æ•°è¢«è°ƒç”¨æ—¶ï¼Œ æ¯ä¸ªæ·»åŠ çš„å—éƒ½æŒ‰ç…§å®ƒä»¬è¢«æ·»åŠ çš„é¡ºåºæ‰§è¡Œã€‚ ç°åœ¨å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„`MySequential`ç±»é‡æ–°å®ç°å¤šå±‚æ„ŸçŸ¥æœºã€‚(äº§ç”Ÿäº†å’Œé»˜è®¤`Sequential`ç±»ç›¸åŒçš„åŠŸèƒ½)



ä»¥ä¸Šçš„ä¸¤ä¸ªå¯¹è±¡éƒ½è°ƒç”¨äº†ä¸€äº›æ–¹æ³•,ç”Ÿæˆäº†ç›¸åŒçš„ç½‘ç»œç»“æ„



```python
class FixedHiddenMLP(nn.Module):
    def __init__(self):
        super().__init__()
        # ä¸è®¡ç®—æ¢¯åº¦çš„éšæœºæƒé‡å‚æ•°ã€‚å› æ­¤å…¶åœ¨è®­ç»ƒæœŸé—´ä¿æŒä¸å˜
        self.rand_weight = torch.rand((20, 20), requires_grad=False)
        self.linear = nn.Linear(20, 20)
        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),
                                 nn.Linear(64, 32), nn.ReLU())
    def forward(self, X):
        X = self.linear(self.net(X))
        # ä½¿ç”¨åˆ›å»ºçš„å¸¸é‡å‚æ•°ä»¥åŠreluå’Œmmå‡½æ•°
        X = F.relu(torch.mm(X, self.rand_weight) + 1)
        # å¤ç”¨å…¨è¿æ¥å±‚ã€‚è¿™ç›¸å½“äºä¸¤ä¸ªå…¨è¿æ¥å±‚å…±äº«å‚æ•°
        X = self.linear(X)
        # æ§åˆ¶æµ
        while X.abs().sum() > 1:
            X /= 2
        return X.sum()
    
net =  nn.Sequential(FixedHiddenMLP(), nn.Linear(1, 20))
net(X)
```

è¿™æ ·å¯ä»¥å°†whileæ”¾åœ¨ç¥ç»ç½‘ç»œçš„è®¡ç®—ä¸­(ä¸€èˆ¬éƒ½ä¸è¿™ä¹ˆåš,ä¸ºäº†è¡¨è¾¾è¿™ä¸ªforwardçš„çµæ´»æ€§è€Œå·²)ï¼Œç”šè‡³å¯ä»¥è°ƒç”¨nn.Sequentialå®šä¹‰çš„å±‚ã€‚

è€Œä¸”nn.Sequential()åŒæ ·å¯ä»¥è°ƒç”¨è‡ªå®šä¹‰çš„å—ä¸­å®šä¹‰çš„å±‚è¿›è¡Œå®šä¹‰æ–°çš„å±‚

 

### æ€»ç»“

ä½¿ç”¨

```python
class FixedHiddenMLP(nn.Module):
    def __init__(self):
        super().__init__()
        
        
    def forward(self, X):
```

è¿™æ ·çš„å½¢åŠ¿å¯ä»¥çµæ´»å®šä¹‰å„ä¸ªå±‚,å¥½ç”¨ä¸”ç®€å•

### å‚æ•°ç®¡ç†

http://localhost:8888/notebooks/d2l-zh%20(1)/pytorch/chapter_deep-learning-computation/custom-layer.ipynb

```python
import torch
from torch import nn

net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))
X = torch.rand(size=(2, 4))
net(X)
print(net[2].state_dict())
print(net[2]. bias)
print(net[2]. bias.data)
```

é€šè¿‡print(net[2].state_dict())å‡½æ•°è¾“å‡ºç¬¬ä¸‰å±‚( nn.Linear(8, 1))çš„å‚æ•°

net[2]. biasè¾“å‡ºçš„æ˜¯æœ¬å±‚çš„bias(åå·®),ä½†æ˜¯åå·®æ˜¯å«æœ‰æ¢¯åº¦å±æ€§çš„(å› ä¸ºæ²¡æœ‰è®­ç»ƒ,æ‰€ä»¥æ¢¯åº¦ä¸ºNone), bias.dataå¯ä»¥è°ƒç”¨åˆ°biasçš„å€¼(ä¹Ÿå°±å¯ä»¥è¿›è¡Œä¿®æ”¹äº†)

åŒç†,net[2]. weight.grad	å¯ä»¥è®¿é—®å…¶æ¢¯åº¦ä¿¡æ¯

```python
print(*[(name, param.shape) for name, param in net[0].named_parameters()])
```

ä¸€æ¬¡æ€§è®¿é—®ç¬¬ä¸€å±‚æ‰€æœ‰çš„å‚æ•°(åˆ æ‰[0]å³å¯è®¿é—®æ‰€æœ‰çš„å±‚çš„æ‰€æœ‰å‚æ•°)

æ‰€ä»¥

```python
net.state_dict()['2.bias'].data
```

ä¸€æ ·å¯ä»¥è®¿é—®ç¬¬ä¸‰å±‚çš„biaså‚æ•°



```python
def block1():
    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),
                         nn.Linear(8, 4), nn.ReLU())

def block2():
    net = nn.Sequential()
    for i in range(4):
        # åœ¨è¿™é‡ŒåµŒå¥—
        net.add_module(f'block {i}', block1())
    return net

rgnet = nn.Sequential(block2(), nn.Linear(4, 1))
rgnet(X)

print(rgnet)
```

è¿™æ ·å¯ä»¥è¾“å‡ºrgnet(ç”±)çš„å„å±‚ä¿¡æ¯



```python
def init_normal(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, mean=0, std=0.01)
        nn.init.zeros_(m.bias)
net[0].apply(init_normal)	#å¯¹ä»»ä¸€å±‚æˆ–æ•´ä¸ªnetä½¿ç”¨applyéƒ½æ˜¯å¯è¡Œçš„
net[0].weight.data[0], net[0].bias.data[0]

```

 nn.init.normal_	å¸¦ä¸‹åˆ’çº¿çš„å‡½æ•°ä¼šç›´æ¥æ›¿æ¢æ‰m.weightçš„å€¼(æ¢æˆå‡å€¼ä¸º0,æ–¹å·®ä¸º0.01)

nn.init.zeros_æ›¿æ¢æ‰m.bias

net.apply(init_normal)	å¯¹è¿™ä¸ªç½‘ç»œè°ƒç”¨è¿™ä¸ªå‡½æ•°

nn.init.constant_(m.weight, 1)	ä¿®æ”¹ä¸ºå…¨1(apiç®—æ³•ä¸‹æ˜¯å¯è¡Œçš„)

```python
shared = nn.Linear(8, 8)
net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),
                    shared, nn.ReLU(),
                    shared, nn.ReLU(),
                    nn.Linear(8, 1))
net(X)
```

shareå±‚:å‚æ•°ä¸€å®šæ°¸è¿œç›¸ç­‰(ä»¥ä¸Šä¸ºä¸€ä¸ªshareå±‚çš„ä¸€èˆ¬å†™æ³•,ä¸”å¿…é¡»è¦æœ‰ä¸€ä¸ªå˜é‡è€Œä¸æ˜¯ç›´æ¥ç”¨nn.å®šä¹‰å±‚)

#### 

#### è‡ªå®šä¹‰å±‚

```python
class CenteredLayer(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, X):
        return X - X.mean()
```

æœ€ç®€å•çš„,é€šè¿‡è¿™ä¸ªå‡½æ•°å®šä¹‰çš„å±‚çš„å‚æ•°æ”¹å˜äº†(å‡å€¼ä¸º0)

```python
net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())

Y = net(torch.rand(4, 8))
Y.mean()#çœ‹çœ‹å‡å€¼æ˜¯ä¸æ˜¯çœŸçš„=0
```

è‡ªå®šä¹‰çš„å±‚ä¹Ÿå¯ä»¥ä½œä¸ºç»„ä»¶åˆå¹¶åˆ°æ›´å¤æ‚çš„æ¨¡å‹ä¸­



ä¸‹é¢æˆ‘ä»¬ç»§ç»­å®šä¹‰å…·æœ‰å‚æ•°çš„å±‚ï¼Œ è¿™äº›å‚æ•°å¯ä»¥é€šè¿‡è®­ç»ƒè¿›è¡Œè°ƒæ•´ã€‚ æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å†…ç½®å‡½æ•°æ¥åˆ›å»ºå‚æ•°ï¼Œè¿™äº›å‡½æ•°æä¾›ä¸€äº›åŸºæœ¬çš„ç®¡ç†åŠŸèƒ½ã€‚ æ¯”å¦‚ç®¡ç†è®¿é—®ã€åˆå§‹åŒ–ã€å…±äº«ã€ä¿å­˜å’ŒåŠ è½½æ¨¡å‹å‚æ•°ã€‚ è¿™æ ·åšçš„å¥½å¤„ä¹‹ä¸€æ˜¯ï¼šæˆ‘ä»¬ä¸éœ€è¦ä¸ºæ¯ä¸ªè‡ªå®šä¹‰å±‚ç¼–å†™è‡ªå®šä¹‰çš„åºåˆ—åŒ–ç¨‹åºã€‚      

```python
class MyLinear(nn.Module):
    def __init__(self, in_units, units):
        super().__init__()
        self.weight = nn.Parameter(torch.randn(in_units, units))
        self.bias = nn.Parameter(torch.randn(units,))
        
    def forward(self, X):
        linear = torch.matmul(X, self.weight.data) + self.bias.data
        return F.relu(linear)
    
    
linear = MyLinear(5, 3)
linear.weight
linear(torch.rand(2, 5))

net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))
net(torch.rand(2, 64))
```

è¿™æ ·çš„ç±»,ä»…æ¥æ”¶è¾“å…¥å’Œè¾“å‡ºçš„å¤§å°,å‚æ•°ç”± self.weight,self.biaså®šä¹‰

æˆ‘ä»¬å¯ä»¥[**ä½¿ç”¨è‡ªå®šä¹‰å±‚ç›´æ¥æ‰§è¡Œå‰å‘ä¼ æ’­è®¡ç®—**] (linear(torch.rand(2, 5)))

æˆ‘ä»¬è¿˜å¯ä»¥(**ä½¿ç”¨è‡ªå®šä¹‰å±‚æ„å»ºæ¨¡å‹**)ï¼Œå°±åƒä½¿ç”¨å†…ç½®çš„å…¨è¿æ¥å±‚ä¸€æ ·ä½¿ç”¨è‡ªå®šä¹‰å±‚ã€‚(æœ€åä¸€æ­¥)



### è¯»å†™æ–‡ä»¶

http://localhost:8888/notebooks/d2l-zh%20(1)/pytorch/chapter_deep-learning-computation/read-write.ipynb

```python
import torch
from torch import nn
from torch.nn import functional as F

x = torch.arange(4)
torch.save(x, 'x-file')
x2 = torch.load('x-file')
```

æ•°æ®çš„ä¿å­˜å’Œè¯»å–

```python
class MLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.hidden = nn.Linear(20, 256)
        self.output = nn.Linear(256, 10)

    def forward(self, x):
        return self.output(F.relu(self.hidden(x)))

net = MLP()
X = torch.randn(size=(2, 20))
Y = net(X)

torch.save(net.state_dict(), 'mlp.params')

clone = MLP()
clone.load_state_dict(torch.load('mlp.params'))
clone.eval()
```

å°†æ¨¡å‹ä¿å­˜ä¸º.paramsæ–‡ä»¶å¹¶è¯»å–

```
model.eval()
```

æˆ‘ä»¬é€šå¸¸ä¼šåŠ ä¸ŠDropoutå±‚å’Œbatch normalizationå±‚ï¼Œåœ¨æ¨¡å‹é¢„æµ‹é˜¶æ®µï¼Œæˆ‘ä»¬éœ€è¦å°†è¿™äº›å±‚è®¾ç½®åˆ°é¢„æµ‹æ¨¡å¼ï¼Œmodel.eval()å°±æ˜¯å¸®æˆ‘ä»¬ä¸€é”®æå®šçš„ï¼Œå¦‚æœåœ¨é¢„æµ‹çš„æ—¶å€™å¿˜è®°ä½¿ç”¨model.eval()ï¼Œä¼šå¯¼è‡´ä¸ä¸€è‡´çš„é¢„æµ‹ç»“æœã€‚



å„å±‚ä¹‹é—´çš„è¾“å…¥å’Œè¾“å‡ºå¤§å°å¯ä»¥å‚è€ƒå…¶ä»–äººçš„æ¨¡å‹æ¥æ‰¾åˆ°ä¸€ä¸ªæ¯”è¾ƒé€‚åˆçš„å¤§å° 

æˆ‘è®°å¾—PyTorchçš„å®˜æ–¹æ•™ç¨‹ï¼Œè¯´ä¸è¦ç›´æ¥è°ƒç”¨.forward()ï¼Œä¼šå¯¼è‡´æœªé¢„æœŸçš„ç»“æœä¸ä¸€æ ·ï¼Œå¯ä»¥å»çœ‹çœ‹å®˜æ–¹è‡ªå·±å†™çš„é‚£æœ¬ä¹¦,è€Œ.forward()å‡½æ•°ä¼šè‡ªå·±è°ƒç”¨

##### 17.ä½¿ç”¨å’Œè´­ä¹° GPUã€åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ v2ã€‘

```python
import torch
from torch import nn

torch.device('cpu'), torch.device('cuda'), torch.device('cuda:1')
```

torch.device('cuda')ä½¿ç”¨cudaGPU				 torch.device('cuda:1')	é€‰æ‹©ç¬¬ä¸€å—GPU



```python
torch.cuda.device_count()
```

æˆ‘ä»¬å¯ä»¥(**æŸ¥è¯¢å¯ç”¨gpuçš„æ•°é‡ã€‚**)





```python
def try_gpu(i=0):  #@save
    """gpu(i)å¦‚æœå­˜åœ¨ï¼Œåˆ™è¿”å›gpu(i)ï¼Œå¦åˆ™è¿”å›cpu()"""
    if torch.cuda.device_count() >= i + 1:
        return torch.device(f'cuda:{i}')
    return torch.device('cpu')

def try_all_gpus():  #@save
    """è¿”å›æ‰€æœ‰å¯ç”¨çš„GPUï¼Œå¦‚æœæ²¡æœ‰GPUï¼Œåˆ™è¿”å›[cpu(),]"""
    devices = [torch.device(f'cuda:{i}')
             for i in range(torch.cuda.device_count())]
    return devices if devices else [torch.device('cpu')]

try_gpu(), try_gpu(10), try_all_gpus()
```

æ¨¡æ¿,æœ‰GPUç”¨GPU,æ²¡æœ‰GPUå°±é€‰CPU



```python
x = torch.tensor([1, 2, 3])
print(x.device)
```

æˆ‘ä»¬å¯ä»¥[**æŸ¥è¯¢å¼ é‡æ‰€åœ¨çš„è®¾å¤‡ã€‚**] é»˜è®¤æƒ…å†µä¸‹ï¼Œå¼ é‡æ˜¯åœ¨CPUä¸Šåˆ›å»ºçš„ã€‚



```python
X = torch.ones(2, 3, device=try_gpu())
```

è¿™ç§æ–¹æ³•å®šä¹‰tensorä»è€Œå°†æ•°æ®æ”¾åœ¨GPUä¸Š(æ˜¾å­˜é‡Œé¢), try_all_gpus()è¿”å›å¤šä¸ªdevice,æ‰€ä»¥ä¸èƒ½ç”¨



```python
Z = X.cuda(1)
Y = torch.rand(2, 3, device=try_gpu(1))
print(X)
print(Y)
print(Z)
#A=X + Y
A=Y + Z
```

å¦‚ä¸Š,å¦‚æœXå’ŒYçš„æ•°æ®ä¸åœ¨åŒä¸€å—GPUä¸Šæ—¶,éœ€è¦é€šè¿‡.cuda(i)æ¥åˆ›å»ºä¸€ä¸ªåœ¨å¦ä¸€GPUçš„ç›¸åŒçš„æ–°æ•°æ®ï¼Œä½¿ç”¨åœ¨åŒä¸€GPUä¸Šçš„æ•°æ®æ‰èƒ½è¿›è¡Œè®¡ç®—



```python
net = nn.Sequential(nn.Linear(3, 1))
net = net.to(device=try_gpu())
```

æŠŠé»˜è®¤å»ºå¥½çš„æ¨¡å‹è½¬ç§»åˆ°GPUä¸Š

ä¸€èˆ¬è€Œè¨€,å¦‚æœæ•°æ®çš„è®¡ç®—åœ¨GPUä¸Šåšçš„æ¯”è¾ƒå¥½,é‚£ä¹ˆæ•°æ®æ”¾è¿›GPUçš„ä»£ç å‘å‰æŒªæ˜¯åˆç†çš„

ä½†æ˜¯æœ‰çš„è¿ç®—tensorä¸æ”¯æŒ,é‚£å°±åšå®Œå†æ”¾å›å»å‘—





## å·ç§¯ 

 åŸåˆ™:

1. å¹³ç§»ä¸å˜æ€§:åœ¨ä¸¤ä¸ªä¸åŒçš„åœ°æ–¹ä½¿ç”¨,æ•ˆæœåº”è¯¥å·®ä¸å¤šç”šè‡³ä¸€æ ·

2. å±€éƒ¨æ€§:å·ç§¯æ¯æ¬¡æ“ä½œä»…ä¸å·ç§¯æ ¸è¦†ç›–èŒƒå›´æœ‰å…³,å·ç§¯æ ¸ä»¥å¤–çš„éƒ¨åˆ†æ²¡æœ‰å½±å“

![image-20220304135952740](ææ²pytorch.assets/image-20220304135952740-16463735941481.png)

kernelçš„å­¦ä¹ å–å†³äºç½‘ç»œè®¤ä¸ºå“ªç§kernelå¯¹å­¦ä¹ æœ‰åˆ©



ä¸ºä»€ä¹ˆkernelä¸æ˜¯è¶Šå¤§è¶Šå¥½ï¼Ÿ

åœ¨æ„Ÿå—é‡ç›¸åŒçš„æƒ…å†µä¸‹ï¼Œæ ¸è¶Šå°ï¼Œè®¡ç®—é‡è¶Šå°ã€‚ç”¨æ›´æ·±çš„å±‚è€Œä¸æ˜¯æ›´å¤§çš„kernelæ¥å¾—åˆ°ç›¸åŒçš„æ„Ÿå—é‡æ•ˆæœæ›´å¥½

![image-20220304145140086](ææ²pytorch.assets/image-20220304145140086-16463767019492.png)

1. å¡«å……ï¼šå­¦ä¹ è¾¹ç¼˜ä¿¡æ¯ä½¿å…¶ä¸è¢«ä¸¢å¼ƒï¼›å·ç§¯ä»¥åå½¢çŠ¶ä¸å˜(å˜æˆæƒ³è¦çš„å½¢çŠ¶)

   ![image-20220304145707001](ææ²pytorch.assets/image-20220304145707001.png)

   ```python
   conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)
   ```

   padding=1			æ‰€æœ‰ä¾§è¾¹å„å¡«å……1ä¸ªåƒç´ 

   ```python
   conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1),stride=2)
   ```

   ä½¿ç”¨paddingå‚æ•°è¿›è¡Œå¡«å……,ä½¿ç”¨strideå‚æ•°é€‰æ‹©æ­¥å¹…(é»˜è®¤ä¸º1)

   ä¸Šä¸‹å„å¡«å……2è¡Œ,å·¦å³å„å¡«å……1è¡Œ

2. æ­¥å¹…:æ¯æ¬¡å·ç§¯è®¡ç®—è·¨ä¸€å®šæ ¼æ•°çš„æ­¥å¹…

![image-20220304150058535](ææ²pytorch.assets/image-20220304150058535-16463772597695.png)

æ­¥å¹…ä¼šä½¿å¾—é«˜å’Œå®½å¤§å¹…åº¦è¡°å‡,æ‰€ä»¥ä¸€èˆ¬ä»…åœ¨å±‚ä¸å±‚ä¹‹é—´æ‰

##### å·ç§¯å®é™…ä¸Šæ˜¯ä¿¡æ¯çš„æœ‰æŸå‹ç¼©,è€Œæˆ‘ä»¬è¦åšçš„å°±æ˜¯åœ¨	ä¿¡æ¯é‡, è®¡ç®—é€Ÿç‡ ä»¥åŠå‡†ç¡®æ€§ ä¸­æ‰¾åˆ°å¹³è¡¡ç‚¹

ä¸€èˆ¬è€Œè¨€,æˆ‘ä»¬å¯ä»¥ç›´æ¥å¥—ç”¨ç»å…¸çš„ç¥ç»ç½‘ç»œç»“æ„,å½“ç„¶å¯¹äºç‰¹æ®Šå½¢çŠ¶çš„è¾“å…¥,å¯èƒ½éœ€è¦å¯¹è¾“å…¥åšä¸€æ¬¡å¤„ç†,ç„¶åå†è¾“å…¥ç½‘ç»œä¸­

ä¸€èˆ¬è€Œè¨€,ç½‘ç»œå¹¶ä¸æ˜¯éå¸¸éå¸¸é‡è¦çš„éƒ¨åˆ†(resnet åŠå…¶å„ä¸ªå˜ç§é—´çš„è¯¯å·®å·²ç»åšçš„éå¸¸å¥½äº†)

 å¤šä¸ªå°kernelçš„ç»“æœä¸å°‘é‡å¤§kernelæ¥è¿‘,ä½†æ˜¯è¿ç®—é‡æ›´å°‘

# easy is best

ç®€å•çš„æ¨¡å‹æ›´é€šç”¨,æ›´æ”¹åˆ°å…¶ä»–æ•°æ®é›†ä¸Šä¹Ÿæ›´æ–¹ä¾¿ 



#### å·ç§¯å±‚å¤šè¾“å‡ºé€šé“

ä½¿ç”¨å¤šä¸ªkernelè¿›è¡Œå·ç§¯,å¾—åˆ°å¤šä¸ªcharnelçš„ç»“æœ(æ¯ä¸ªæ ¸ç”Ÿæˆä¸€ä¸ªcharnal)(æœ‰çš„kernelæå–è¾¹ç¼˜,æœ‰çš„æ”¾ç¼©å›¾åƒ,æœ‰çš„é”åŒ–å›¾åƒâ€¦â€¦ï¼Œå¤šä¸ªæ ¸æå–å„ç§ä¸åŒçš„ä¿¡æ¯,ä»è€Œåœ¨poolingä¸­å®ç°ä¿¡æ¯èåˆ)

å°±æ˜¯æŠŠå›¾ç‰‡å½“åšä¸€ä¸ªå‘é‡ï¼ŒåŠ æƒå¹³å‡ï¼Œä¿¡æ¯èåˆï¼Œä¸ä¸€å±‚mlpä¸­çš„ä¸€ä¸ªç¥ç»å…ƒå¹²çš„æ˜¯ä¸€ä»¶äº‹



![image-20220304161503768](ææ²pytorch.assets/image-20220304161503768-16463817056727.png)

é€šè¿‡è¿™ä¸ªå…¬å¼å‚è€ƒè®¡ç®—çš„å¤æ‚åº¦ 

![image-20220304161810866](ææ²pytorch.assets/image-20220304161810866-16463818918368.png)

**zip()** å‡½æ•°ç”¨äºå°†å¯è¿­ä»£çš„å¯¹è±¡ä½œä¸ºå‚æ•°ï¼Œå°†å¯¹è±¡ä¸­å¯¹åº”çš„å…ƒç´ æ‰“åŒ…æˆä¸€ä¸ªä¸ªå…ƒç»„ï¼Œç„¶åè¿”å›ç”±è¿™äº›å…ƒç»„ç»„æˆçš„åˆ—è¡¨ã€‚

å¦‚æœå„ä¸ªè¿­ä»£å™¨çš„å…ƒç´ ä¸ªæ•°ä¸ä¸€è‡´ï¼Œåˆ™è¿”å›åˆ—è¡¨é•¿åº¦ä¸æœ€çŸ­çš„å¯¹è±¡ç›¸åŒï¼Œåˆ©ç”¨ * å·æ“ä½œç¬¦ï¼Œå¯ä»¥å°†å…ƒç»„è§£å‹ä¸ºåˆ—è¡¨ã€‚



```python
def corr2d_multi_in(X, K):
    # å…ˆéå†â€œXâ€å’Œâ€œKâ€çš„ç¬¬0ä¸ªç»´åº¦ï¼ˆé€šé“ç»´åº¦ï¼‰ï¼Œå†æŠŠå®ƒä»¬åŠ åœ¨ä¸€èµ·
    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))
X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],
               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])
K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])

print(corr2d_multi_in(X, K))
```

ä¸€ä¸ªåŸºç¡€çš„2*2å·ç§¯

è¾“å‡ºï¼š

```
tensor([[ 56.,  72.],
        [104., 120.]])
```

ä»è€Œå®ç°äº†ä¸€ä¸ª2*2çš„å·ç§¯

![image-20220304195013080](ææ²pytorch.assets/image-20220304195013080-16463946157339-164639462353510.png)

ç¤ºæ„å›¾å¦‚æ­¤



```python
def corr2d_multi_in_out(X, K):
    # è¿­ä»£â€œKâ€çš„ç¬¬0ä¸ªç»´åº¦ï¼Œæ¯æ¬¡éƒ½å¯¹è¾“å…¥â€œXâ€æ‰§è¡Œäº’ç›¸å…³è¿ç®—ã€‚
    # æœ€åå°†æ‰€æœ‰ç»“æœéƒ½å åŠ åœ¨ä¸€èµ·
    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)

K = torch.stack((K, K + 1, K + 2), 0)
print(K.shape)
print(corr2d_multi_in_out(X, K))
```

è¾“å‡º:

```
tensor([[[ 56.,  72.],
         [104., 120.]],

        [[ 76., 100.],
         [148., 172.]],

        [[ 96., 128.],
         [192., 224.]]])
```

åšäº†ä¸€ä¸ªå¤šè¾“å‡ºçš„è®¾è®¡(ä»1ä¸ªkernelå˜æˆäº†3ä¸ªkernel)





```python
def corr2d_multi_in_out_1x1(X, K):	#ç”¨reshapeåšå…¨è¿æ¥
    c_i, h, w = X.shape
    c_o = K.shape[0]
    X = X.reshape((c_i, h * w))
    K = K.reshape((c_o, c_i))
    # å…¨è¿æ¥å±‚ä¸­çš„çŸ©é˜µä¹˜æ³•
    Y = torch.matmul(K, X)
    return Y.reshape((c_o, h, w))

X = torch.normal(0, 1,    (3, 3, 3))
K = torch.normal(0, 1, (2, 3, 1, 1))

Y1 = corr2d_multi_in_out_1x1(X, K)		#å…¨è¿æ¥
Y2 = corr2d_multi_in_out(X, K)			#å·ç§¯
assert float(torch.abs(Y1 - Y2).sum()) < 1e-6#å¯¹æ¯” Y1 Y2ç›¸ç­‰,åˆ™ä¸æŠ¥é”™
```

å³è¿™ä¸¤ä¸ªå‡½æ•°å¯¹äºXå’ŒKçš„è®¡ç®—æ˜¯ç­‰æ•ˆçš„





![image-20220304161029022](ææ²pytorch.assets/image-20220304161029022-16463814302496.png)





åšäº†ä¸€ä¸ª1*1çš„å·ç§¯

1*1å·ç§¯,ä»…èåˆä¿¡æ¯,ä¸æ”¹å˜å½¢çŠ¶(å¯è§†ä¸ºä¸€ä¸ªå·ç§¯å±‚(æ“ä½œç±»ä¼¼))

1X1çš„æ ¸ï¼Œç›¸å½“äºå°†å›¾ç‰‡åœ¨æ¯ä¸ªchanelä¸‹è¢«æ‹‰æˆäº†å‘é‡ï¼Œchanelå˜batch_size



ä¸€èˆ¬è€Œè¨€,2æ­¥é•¿çš„å·ç§¯ä½¿å¾—é•¿å®½å‡å°‘ä¸€åŠ,ä»è€Œæ‹“å®½ä¸€å€çš„é€šé“æ•°ä»¥å‡å°‘å‚æ•°çš„åŒæ—¶ä¿ç•™æ›´å¤šçš„ä¿¡æ¯(å³ä¸‹é‡‡æ ·çš„å¸¸è§„åšæ³•)

å·ç§¯å¯¹ä½ç½®ä¿¡æ¯éå¸¸æ•æ„Ÿ,è€Œé€šè¿‡æ± åŒ–å±‚å¯ä»¥å¼±åŒ–å·ç§¯å¯¹ä½ç½®ä¿¡æ¯çš„æ•æ„Ÿåº¦



3då·ç§¯åœ¨è§†é¢‘é¢†åŸŸæ¯”è¾ƒå¸¸ç”¨,å¯¹å›¾ç‰‡(å«æ·±åº¦ä¿¡æ¯)æ•ˆæœæ¯”2d(2då·ç§¯å†ç›¸åŠ )å¥½ä¸€ç‚¹,ä½†æ˜¯å¤æ‚åº¦å¤§å¾ˆå¤š,æ‰€ä»¥è§†é¢‘é¢†åŸŸçš„è®¡ç®—ä»ç„¶ä¸å¤§ç†æƒ³ 

### poolingæ± åŒ– 

![image-20220304205534757](ææ²pytorch.assets/image-20220304205534757-164639853635511.png)

è¿™ä¸å®Œå…¨æ˜¯å¥½äº‹ï¼Œæˆ‘ä»¬æ›´æœŸæœ›å·ç§¯æ ¸æœ‰ä¸€å®šçš„å¹³ç§»ä¸å˜æ€§(æ³›ç”¨æ€§),å¦åˆ™æ¢äº†ä¸ªä½ç½®å°±ä¸èƒ½ç”¨,é‚£å°±éœ€è¦éå¸¸éå¸¸å¤šçš„å·ç§¯æ ¸.æ•ˆæœå°±ä¸å¥½äº†

<img src="ææ²pytorch.assets/image-20220304205834538.png" alt="image-20220304205834538" style="zoom: 80%;" />

æœ€å¤§æ± åŒ–å±‚(å½“ç„¶è¿˜æœ‰å¹³å‡æ± åŒ–å±‚ç­‰)å¦‚ä¸Šå›¾æ‰€ç¤º

![image-20220304210239316](ææ²pytorch.assets/image-20220304210239316-164639896195213.png)

å¯¹æ¯”ä»¥ä¸‹,æ± åŒ–å…è®¸å°å¹…åº¦çš„åç§»,åˆ¤å®šæ¯”å·ç§¯æ›´å®½æ¾

å’Œ**å·ç§¯çš„åŒºåˆ«**:æ²¡æœ‰å¯å­¦ä¹ çš„å‚æ•°(ä¸éœ€è¦æ¢¯åº¦æ¥å­¦ä¹ å…¶å‚æ•°,ä½†æ˜¯æœ€å¤§æ± åŒ–ä»æœ‰å’Œæ¢¯åº¦ç›¸å…³çš„ä¿¡æ¯max idéœ€è¦è®°å½•,ä»¥æ­¤åˆ¤æ–­å“ªä¸ªå‚æ•°éœ€è¦æ›´æ–°)



#### æœ€å¤§å€¼æ± åŒ–max pooling 

max poolingä¹Ÿè¦æ»¡è¶³æ¢¯åº¦ä¹‹å’Œä¸å˜çš„åŸåˆ™ï¼Œmax poolingçš„å‰å‘ä¼ æ’­æ˜¯æŠŠpatchä¸­æœ€å¤§çš„å€¼ä¼ é€’ç»™åä¸€å±‚ï¼Œè€Œå…¶ä»–åƒç´ çš„å€¼ç›´æ¥è¢«èˆå¼ƒæ‰ã€‚é‚£ä¹ˆåå‘ä¼ æ’­ä¹Ÿå°±æ˜¯æŠŠæ¢¯åº¦ç›´æ¥ä¼ ç»™å‰ä¸€å±‚æŸä¸€ä¸ªåƒç´ ï¼Œè€Œå…¶ä»–åƒç´ ä¸æ¥å—æ¢¯åº¦ï¼Œä¹Ÿå°±æ˜¯ä¸º0ã€‚æ‰€ä»¥max poolingæ“ä½œå’Œmean poolingæ“ä½œä¸åŒç‚¹åœ¨äºéœ€è¦è®°å½•ä¸‹æ± åŒ–æ“ä½œæ—¶åˆ°åº•å“ªä¸ªåƒç´ çš„å€¼æ˜¯æœ€å¤§ï¼Œä¹Ÿå°±æ˜¯max idï¼Œ

![img](ææ²pytorch.assets/SouthEast.jpeg)



#### å¹³å‡æ± åŒ–mean pooling

mean poolingçš„å‰å‘ä¼ æ’­å°±æ˜¯æŠŠä¸€ä¸ªpatchä¸­çš„å€¼æ±‚å–å¹³å‡æ¥åšpoolingï¼Œé‚£ä¹ˆåå‘ä¼ æ’­çš„è¿‡ç¨‹ä¹Ÿå°±æ˜¯æŠŠæŸä¸ªå…ƒç´ çš„æ¢¯åº¦ç­‰åˆ†ä¸ºnä»½åˆ†é…ç»™å‰ä¸€å±‚ï¼Œè¿™æ ·å°±ä¿è¯æ± åŒ–å‰åçš„æ¢¯åº¦ï¼ˆæ®‹å·®ï¼‰ä¹‹å’Œä¿æŒä¸å˜ï¼Œè¿˜æ˜¯æ¯”è¾ƒç†è§£çš„ï¼Œå›¾ç¤ºå¦‚ä¸‹ ï¼š 

![img](ææ²pytorch.assets/SouthEast-164639934909615.jpeg)

mean poolingæ¯”è¾ƒå®¹æ˜“è®©äººç†è§£é”™çš„åœ°æ–¹å°±æ˜¯ä¼šç®€å•çš„è®¤ä¸ºç›´æ¥æŠŠæ¢¯åº¦å¤åˆ¶Néä¹‹åç›´æ¥åå‘ä¼ æ’­å›å»ï¼Œä½†æ˜¯è¿™æ ·ä¼šé€ æˆlossä¹‹å’Œå˜ä¸ºåŸæ¥çš„Nå€ï¼Œç½‘ç»œæ˜¯ä¼šäº§ç”Ÿæ¢¯åº¦çˆ†ç‚¸çš„ã€‚

##### ä»£ç 

```python
def pool2d(X, pool_size, mode='max'):
    p_h, p_w = pool_size
    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))
    for i in range(Y.shape[0]):	#æŒ‰è¡Œ
        for j in range(Y.shape[1]):	#æŒ‰åˆ—
            if mode == 'max':
                Y[i, j] = X[i: i + p_h, j: j + p_w].max()
            elif mode == 'avg':
                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()
    return Y

X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])
pool2d(X, (2, 2))
```

æ²¡æœ‰å¤šé€šé“,æ²¡æœ‰padding,æ²¡æœ‰strideçš„ç®€å•æ± åŒ–



```python
X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))
pool2d = nn.MaxPool2d(3)
pool2d(X)
```

é»˜è®¤æƒ…å†µä¸‹ï¼Œ(**æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­çš„æ­¥å¹…ä¸æ±‡èšçª—å£çš„å¤§å°ç›¸åŒ**)ã€‚ å› æ­¤ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨å½¢çŠ¶ä¸º`(3, 3)`çš„æ±‡èšçª—å£ï¼Œé‚£ä¹ˆé»˜è®¤æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¾—åˆ°çš„æ­¥å¹…å½¢çŠ¶ä¸º`(3, 3)`



```python
pool2d = nn.MaxPool2d(3, padding=1, stride=2)
pool2d(X)
```

[**å¡«å……å’Œæ­¥å¹…å¯ä»¥æ‰‹åŠ¨è®¾å®š**]ã€‚



å½“ç„¶ï¼Œæˆ‘ä»¬å¯ä»¥(**è®¾å®šä¸€ä¸ªä»»æ„å¤§å°çš„çŸ©å½¢æ±‡èšçª—å£ï¼Œå¹¶åˆ†åˆ«è®¾å®šå¡«å……å’Œæ­¥å¹…çš„é«˜åº¦å’Œå®½åº¦**)ã€‚

In [8]:

```python
pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))
pool2d(X)
```

Out[8]:

```
tensor([[[[ 5.,  7.],
          [13., 15.]]]])
```



##### å¤šé€šé“

```python
X = torch.cat((X, X + 1), 1)

pool2d = nn.MaxPool2d(3, padding=1, stride=2)
pool2d(X)
```

è¾“å‡º:

```
tensor([[[[ 5.,  7.],
          [13., 15.]],

         [[ 6.,  8.],
          [14., 16.]]]])
```

ä¸€èˆ¬è€Œè¨€ï¼Œæ± åŒ–å±‚æ”¾åœ¨å·ç§¯å±‚åé¢

çª—å£é‡å å’Œä¸é‡å åŒºåˆ«ä¸å¤§ 

åœ¨è€ƒè™‘æ€§èƒ½çš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨pythonè‡ªå·±çš„å…ƒç»„æ“ä½œè€Œä¸æ˜¯çŸ©é˜µæ‹¼æ¥é€Ÿåº¦ä¼šå¿«ä¸å°‘

æ± åŒ–å±‚é€æ¸å°‘ç”¨ï¼šç›´æ¥å¯¹æ•°æ®åšæ”¹å˜(å˜å½¢,å¹³ç§»,æ”¾å¤§ç¼©å°ç­‰),æ·¡åŒ–äº†æ± åŒ–å±‚çš„ä½œç”¨(ç¼“è§£å·ç§¯å¯¹ä½ç½®çš„æ•æ„Ÿæ€§) 



#### LetNet

http://localhost:8888/notebooks/d2l-zh%20(1)/pytorch/chapter_convolutional-neural-networks/lenet.ipynb

![image-20220305134741595](ææ²pytorch.assets/image-20220305134741595-16464592631501.png)

ç¤ºæ„å›¾

```python
import torch
from torch import nn
from d2l import torch as d2l

net = nn.Sequential(
    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),
    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),
    nn.Flatten(),
    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),
    nn.Linear(120, 84), nn.Sigmoid(),
    nn.Linear(84, 10))
```

ç½‘ç»œæ„å»º		nn.Flatten()æŠŠç½‘ç»œæ‹‰ç›´ç”¨äºå…¨è¿æ¥



<div><br class="Apple-interchange-newline">layer in net:  </div>

```python
X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)
for layer in net:
    X = layer(X)
    print(layer.__class__.__name__,'output shape: \t',X.shape)

```

è¾“å‡º

```python
Conv2d output shape: 	 torch.Size([1, 6, 28, 28])
Sigmoid output shape: 	 torch.Size([1, 6, 28, 28])
AvgPool2d output shape: 	 torch.Size([1, 6, 14, 14])
Conv2d output shape: 	 torch.Size([1, 16, 10, 10])
Sigmoid output shape: 	 torch.Size([1, 16, 10, 10])
AvgPool2d output shape: 	 torch.Size([1, 16, 5, 5])
Flatten output shape: 	 torch.Size([1, 400])
Linear output shape: 	 torch.Size([1, 120])
Sigmoid output shape: 	 torch.Size([1, 120])
Linear output shape: 	 torch.Size([1, 84])
Sigmoid output shape: 	 torch.Size([1, 84])
Linear output shape: 	 torch.Size([1, 10])
```

å› ä¸ºæ˜¯nn.Sequential()æ„é€ çš„,æ‰€ä»¥å¯ä»¥é€šè¿‡for layer in net()å¯¹æ¯ä¸€å±‚è¿›è¡Œè¿­ä»£,å°†Xé€šè¿‡æ‹¿å‡ºæ¥çš„å±‚è¿›è¡Œè¿ç®—

åˆšå¼€å§‹çš„å·ç§¯å½¢çŠ¶æ²¡æœ‰æ”¹å˜:paddingä¸€ä¸‹,é¿å…è¾¹ç¼˜ä¿¡æ¯ä¸¢å¤±



```
batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)
```

è®¾ç½®batch_size, è¯»å–train_iter, test_iteræ•°æ®

```python
def evaluate_accuracy_gpu(net, data_iter, device=None): #@save
    """ä½¿ç”¨GPUè®¡ç®—æ¨¡å‹åœ¨æ•°æ®é›†ä¸Šçš„ç²¾åº¦"""
    if isinstance(net, nn.Module):
        net.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        if not device:
            device = next(iter(net.parameters())).device
    # æ­£ç¡®é¢„æµ‹çš„æ•°é‡ï¼Œæ€»é¢„æµ‹çš„æ•°é‡
    metric = d2l.Accumulator(2)
    with torch.no_grad():
        for X, y in data_iter:
            if isinstance(X, list):
                # BERTå¾®è°ƒæ‰€éœ€çš„ï¼ˆä¹‹åå°†ä»‹ç»ï¼‰
                X = [x.to(device) for x in X]
            else:
                X = X.to(device)
            y = y.to(device)
            metric.add(d2l.accuracy(net(X), y), y.numel())
    return metric[0] / metric[1]
```

net.eval() ,ä½¿ç”¨è¯„ä¼°æ¨¡å¼,åœ¨æ­¤æ¨¡å¼ä¸‹ä¼šå›ºå®šæ¨¡å‹(å‚æ•°ä¸å˜),ç”¨äºéªŒè¯accç­‰å‚æ•°

```python
#@save
def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):
    """ç”¨GPUè®­ç»ƒæ¨¡å‹(åœ¨ç¬¬å…­ç« å®šä¹‰)"""
    def init_weights(m):
        if type(m) == nn.Linear or type(m) == nn.Conv2d:
            nn.init.xavier_uniform_(m.weight)
    net.apply(init_weights)
    print('training on', device)
    net.to(device)
    optimizer = torch.optim.SGD(net.parameters(), lr=lr)
    loss = nn.CrossEntropyLoss()
    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],
                            legend=['train loss', 'train acc', 'test acc'])
    timer, num_batches = d2l.Timer(), len(train_iter)
    for epoch in range(num_epochs):
        # è®­ç»ƒæŸå¤±ä¹‹å’Œï¼Œè®­ç»ƒå‡†ç¡®ç‡ä¹‹å’Œï¼Œæ ·æœ¬æ•°
        metric = d2l.Accumulator(3)
        net.train()
        for i, (X, y) in enumerate(train_iter):
            timer.start()
            optimizer.zero_grad()
            X, y = X.to(device), y.to(device)
            y_hat = net(X)
            l = loss(y_hat, y)
            l.backward()
            optimizer.step()
            #è‡³æ­¤å·²ç»è®­ç»ƒå®Œæ¯•äº†,ä¸‹é¢æ˜¯ç²¾åº¦éªŒè¯ä»¥åŠè¾“å‡ºå›¾ç‰‡çš„éƒ¨åˆ†
            
            
            with torch.no_grad():
                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])
            timer.stop()
            train_l = metric[0] / metric[2]
            train_acc = metric[1] / metric[2]
            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:
                animator.add(epoch + (i + 1) / num_batches,
                             (train_l, train_acc, None))
        test_acc = evaluate_accuracy_gpu(net, test_iter)
        animator.add(epoch + 1, (None, None, test_acc))
    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '
          f'test acc {test_acc:.3f}')
    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '
          f'on {str(device)}')
```

reshapeä¸€èˆ¬æ¯”viewæ›´å¥½,ä¸è¿‡å¯èƒ½æ…¢ä¸€ç‚¹(reshapeè‡ªåŠ¨é€‰æ‹©è¦ä¸è¦æ”¹å˜å†…å­˜å­˜å‚¨æ–¹å¼(ä¸€èˆ¬æ˜¯æ”¹å˜çš„)ï¼Œè€Œviewä¸èƒ½æ”¹å˜)

#### 

åœ¨AlexNetä¹‹å‰,æ ¸æ–¹æ³•å¾ˆå—é‡è§†(å› ä¸ºæ•°æ®é‡æš´å¢)

SVMè¢«å¹¿æ³›ä½¿ç”¨(é²æ£’æ€§å¼º,ä¸æ€ä¹ˆéœ€è¦è°ƒå‚),ç°åœ¨ä¹Ÿè›®å¥½ç”¨çš„

å‡¸ä¼˜åŒ–:å¯ä»¥ç®€å•ç†è§£ä¸ºæœ‰æ¼‚äº®æ˜¾å¼è§£çš„ä¼˜åŒ–(å‡ ä½•å­¦å†…å®¹)

ç‰¹å¾å·¥ç¨‹:SIFT,SURF

åœ¨æ·±åº¦å­¦ä¹ ä»¥å‰,ä»¥ä¸Šä¸‰è€…å¯¹ç»“æœæå‡éå¸¸å¤§,åè€Œæ˜¯æ¨¡å‹ç»“æ„ä¸å—é‡è§† 

æ ¸æ–¹æ³•:æ•°æ®å¤š,ç ”ç©¶æ•°æ®å¾—ä¿¡æ¯

ç¥ç»ç½‘ç»œ:è®¡ç®—èµ„æºå¤š,ç”¨ç®—åŠ›æ¢ä¿¡æ¯



#### AlexNet

ä¼˜ç‚¹:ä½¿ç”¨äº†**dropout,ReLu,Max Poolingä»¥åŠæ•°æ®å¢å¼º(æ¢è‰²,å¹³ç§»,å±€éƒ¨æ”¾å¤§,å¢å‡äº®åº¦)**

æœ¬è´¨ä¸Šå°±æ˜¯ä¸€ä¸ªæ›´æ·±(æ›´å¤šæ¬¡å·ç§¯æ ¸æ± åŒ–)æ›´å¤§(å¤§è¾“å…¥,å¤§è¾“å‡º,å¤šé€šé“)çš„LeNet,ä½¿ç”¨äº†å¦‚ä¸Šçš„å±‚è¿›è¡Œæ”¹è¿›

![image-20220305155722744](ææ²pytorch.assets/image-20220305155722744-16464670437992.png)

å·¦è¾¹æ˜¯ç»å…¸æœºå™¨å­¦ä¹ ,å³è¾¹æ˜¯deep learningçš„åšæ³•

äººå·¥ç‰¹å¾æå–å¾—åˆ°è®¡ç®—æœºèƒ½ç†è§£çš„ç‰¹å¾,å†é€šè¿‡SVMè¿›è¡Œè¿ç®—

![image-20220305160425386](ææ²pytorch.assets/image-20220305160425386-16464674668273.png)

ç®€å•å¯¹æ¯”ä¸€ä¸‹ä¼ é€’çš„å‚æ•°é‡

![image-20220305161009904](ææ²pytorch.assets/image-20220305161009904-16464678118874.png)

 

10xå‚æ•°,250xè®¡ç®—å¤æ‚åº¦

ä»£ç å®ç°:

```python
import torch
from torch import nn
from d2l import torch as d2l

net = nn.Sequential(
    # è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ª11*11çš„æ›´å¤§çª—å£æ¥æ•æ‰å¯¹è±¡ã€‚
    # åŒæ—¶ï¼Œæ­¥å¹…ä¸º4ï¼Œä»¥å‡å°‘è¾“å‡ºçš„é«˜åº¦å’Œå®½åº¦ã€‚
    # å¦å¤–ï¼Œè¾“å‡ºé€šé“çš„æ•°ç›®è¿œå¤§äºLeNet
    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    # å‡å°å·ç§¯çª—å£ï¼Œä½¿ç”¨å¡«å……ä¸º2æ¥ä½¿å¾—è¾“å…¥ä¸è¾“å‡ºçš„é«˜å’Œå®½ä¸€è‡´ï¼Œä¸”å¢å¤§è¾“å‡ºé€šé“æ•°
    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    # ä½¿ç”¨ä¸‰ä¸ªè¿ç»­çš„å·ç§¯å±‚å’Œè¾ƒå°çš„å·ç§¯çª—å£ã€‚
    # é™¤äº†æœ€åçš„å·ç§¯å±‚ï¼Œè¾“å‡ºé€šé“çš„æ•°é‡è¿›ä¸€æ­¥å¢åŠ ã€‚
    # åœ¨å‰ä¸¤ä¸ªå·ç§¯å±‚ä¹‹åï¼Œæ±‡èšå±‚ä¸ç”¨äºå‡å°‘è¾“å…¥çš„é«˜åº¦å’Œå®½åº¦
    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nn.Flatten(),
    # è¿™é‡Œï¼Œå…¨è¿æ¥å±‚çš„è¾“å‡ºæ•°é‡æ˜¯LeNetä¸­çš„å¥½å‡ å€ã€‚ä½¿ç”¨dropoutå±‚æ¥å‡è½»è¿‡æ‹Ÿåˆ
    nn.Linear(6400, 4096), nn.ReLU(),
    nn.Dropout(p=0.5),
    nn.Linear(4096, 4096), nn.ReLU(),
    nn.Dropout(p=0.5),
    # æœ€åæ˜¯è¾“å‡ºå±‚ã€‚ç”±äºè¿™é‡Œä½¿ç”¨Fashion-MNISTï¼Œæ‰€ä»¥ç”¨ç±»åˆ«æ•°ä¸º10ï¼Œè€Œéè®ºæ–‡ä¸­çš„1000
    nn.Linear(4096, 10))
```

æ„å»ºç½‘ç»œç»“æ„ 



```python
X = torch.randn(1, 1, 224, 224)
for layer in net:
    X=layer(X)
    print(layer.__class__.__name__,'output shape:\t',X.shape)
```

æŸ¥çœ‹å„ä¸ªç½‘ç»œç»“æ„çš„è¾“å‡º



```python
batch_size = 128
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)

lr, num_epochs = 0.01, 10
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
```

å› ä¸ºæˆ‘ä»¬çš„æ•°æ®ä¸æ˜¯ååˆ†ç†æƒ³(æ•°æ®æ ¸ç½‘ç»œçš„è¾“å…¥ä¸ä¸€è‡´),æ‰€ä»¥éœ€è¦resize=224(ä¸€èˆ¬ä¸å¯èƒ½è¿™ä¹ˆåšå°±æ˜¯äº†,æˆ‘ä»¬éƒ½æ˜¯æ¨¡å‹åŒ¹é…æ•°æ®çš„),å…¶ä½™çš„ä¹Ÿå°±æ˜¯ä¹‹å‰çš„éƒ¨åˆ†



æœ‰ä¸å°‘Normalizationæ˜¯æœ‰ç”¨çš„,ä¹Ÿæœ‰ä¸å°‘æ˜¯åæ¥è¯æ˜æ²¡æœ‰æ•ˆæœ,éœ€è¦æˆ‘ä»¬è‡ªå·±é‰´åˆ«

å¢å¼ºäº†åè€Œæœ‰æ›´å·®çš„æ•ˆæœæ˜¯éå¸¸æ­£å¸¸çš„,å¢å¼ºç±»ä¼¼äºæ·»åŠ å™ªéŸ³,ä¸ä¸€å®šèƒ½é™ä½è¯¯å·® 



#### VGG ä½¿ç”¨å—çš„ç½‘ç»œ 

æ¯”ALexNetæ›´æ·±æ›´å¤§

1. more å…¨è¿æ¥(å¤ªè´µå•¦)

2. more å·ç§¯

3. **å·ç§¯å±‚ç»„åˆæˆå—**

ä¸ºä»€ä¹ˆå †å·ç§¯å±‚ä¸ºå—:

ç›¸åŒè§†é‡æƒ…å†µä¸‹,å¤šä¸ªå°çª—å£æ•ˆæœæ¯”å•ä¸ªå¤§(å®½)çª—å£å¥½(å®éªŒè¯æ˜)



ä»£ç 

```python
import torch
from torch import nn
from d2l import torch as d2l


def vgg_block(num_convs, in_channels, out_channels):
    layers = []
    for _ in range(num_convs):
        layers.append(nn.Conv2d(in_channels, out_channels,
                                kernel_size=3, padding=1))
        layers.append(nn.ReLU())
        in_channels = out_channels
    layers.append(nn.MaxPool2d(kernel_size=2,stride=2))
    return nn.Sequential(*layers)

```

 æ„å»ºVGGå—



```python
conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))
#å®šä¹‰å·ç§¯

def vgg(conv_arch):
    conv_blks = []
    in_channels = 1
    # å·ç§¯å±‚éƒ¨åˆ†
    for (num_convs, out_channels) in conv_arch:
        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))
        in_channels = out_channels

    return nn.Sequential(
        *conv_blks, nn.Flatten(),
        # å…¨è¿æ¥å±‚éƒ¨åˆ†
        nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(), nn.Dropout(0.5),
        nn.Linear(4096, 4096), nn.ReLU(), nn.Dropout(0.5),
        nn.Linear(4096, 10))

net = vgg(conv_arch)

X = torch.randn(size=(1, 1, 224, 224))
for blk in net:
    X = blk(X)
    print(blk.__class__.__name__,'output shape:\t',X.shape)
```

  æ„å»ºç½‘ç»œç»“æ„ ,éšæœºäº§ç”Ÿä¸€ä¸ªXçœ‹çœ‹ç½‘ç»œç»“æ„



```python
ratio = 4		#æ‰€æœ‰é€šé“æ•°/4,ä»¥å‡å°‘é€šé“æ•°,åŠ å¿«è®­ç»ƒ
small_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]
net = vgg(small_conv_arch)

lr, num_epochs, batch_size = 0.05, 10, 128
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
```

[**ç”±äºVGG-11æ¯”AlexNetè®¡ç®—é‡æ›´å¤§ï¼Œå› æ­¤æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªé€šé“æ•°è¾ƒå°‘çš„ç½‘ç»œ**]ï¼Œè¶³å¤Ÿç”¨äºè®­ç»ƒFashion-MNISTæ•°æ®é›†ã€‚

é™¤äº†ä½¿ç”¨ç•¥é«˜çš„å­¦ä¹ ç‡å¤–ï¼Œ[**æ¨¡å‹è®­ç»ƒ**]è¿‡ç¨‹ä¸ :numref:`sec_alexnet`ä¸­çš„AlexNetç±»ä¼¼ã€‚





### NiN Network In Network



å…¨è¿æ¥å±‚æœ€å¤§çš„é—®é¢˜:éœ€è¦å¤§é‡çš„å‚æ•°,å¤§é‡å‚æ•°å¸¦æ¥åºå¤§çš„è®¡ç®—é‡,

![image-20220305212248989](ææ²pytorch.assets/image-20220305212248989-16464865701735.png)

ä¸¾ä¸ªä¾‹å­å¦‚ä¸Š



![image-20220305212830418](ææ²pytorch.assets/image-20220305212830418-16464869119096.png)

1*1å·ç§¯ä»£æ›¿å…¨è¿æ¥å±‚,å‚æ•°å°‘(å…±ç”¨å‚æ•°) 

![image-20220305212943795](ææ²pytorch.assets/image-20220305212943795-16464869855147.png)

å’ŒVGGå¯¹æ¯”ä¸€ä¸‹

![image-20220305213416822](ææ²pytorch.assets/image-20220305213416822-16464872594178.png)

å¯¹æ¯”ä¸€ä¸‹å¯å‘ç°,ä½¿ç”¨NiN blockå–æ¶ˆäº†å…¨è¿æ¥å¤§é‡å‡å°‘å‚æ•°å’Œè®¡ç®—,ä½¿å¾—ç½‘ç»œå¾—ä»¥å‘æ›´æ·±å¤„å‘å±•

1. (NiNä½¿ç”¨å·ç§¯å±‚+ä¸¤ä¸ª1*1å·ç§¯å±‚ (å¯¹æ¯ä¸ªåƒç´ å¢åŠ äº†éçº¿æ€§æ€§)

2. ä½¿ç”¨å…¨å±€å¹³å‡æ± åŒ–å±‚ä»£æ›¿å…¨è¿æ¥,ä¸å®¹æ˜“è¿‡æ‹Ÿåˆ(åŒæ—¶ä¹Ÿæ„å‘³ç€ä¸å®¹æ˜“æ‹Ÿåˆ)



ä»£ç :

```
import torch
from torch import nn
from d2l import torch as d2l


def nin_block(in_channels, out_channels, kernel_size, strides, padding):
    return nn.Sequential(
        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),
        nn.ReLU(),
        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU(),
        nn.Conv2d(out_channels, out_channels, kernel_size=1), nn.ReLU())
```

å·ç§¯,ReLU,1* 1å·ç§¯*2	ç®€å•ç»„è£…æˆNiNå—

```python
net = nn.Sequential(
    nin_block(1, 96, kernel_size=11, strides=4, padding=0),
    nn.MaxPool2d(3, stride=2),
    nin_block(96, 256, kernel_size=5, strides=1, padding=2),
    nn.MaxPool2d(3, stride=2),
    nin_block(256, 384, kernel_size=3, strides=1, padding=1),
    nn.MaxPool2d(3, stride=2),
    nn.Dropout(0.5),	#é˜²è¿‡æ‹Ÿåˆ
    # æ ‡ç­¾ç±»åˆ«æ•°æ˜¯10
    nin_block(384, 10, kernel_size=3, strides=1, padding=1),
    nn.AdaptiveAvgPool2d((1, 1)),	#é€šé“å…¨å±€å¹³å‡æ± åŒ–å°†å®½é«˜å˜æˆ(1,1)
    # å°†å››ç»´çš„è¾“å‡ºè½¬æˆäºŒç»´çš„è¾“å‡ºï¼Œå…¶å½¢çŠ¶ä¸º(æ‰¹é‡å¤§å°,10)
    nn.Flatten())
```

(bn, 10, 1, 1)--flatten--(bn, 10)



```python
X = torch.rand(size=(1, 1, 224, 224))
for layer in net:
    X = layer(X)
    print(layer.__class__.__name__,'output shape:\t', X.shape)
```



è¾“å‡º

```python
Sequential output shape:	 torch.Size([1, 96, 54, 54])
MaxPool2d output shape:	 torch.Size([1, 96, 26, 26])
Sequential output shape:	 torch.Size([1, 256, 26, 26])
MaxPool2d output shape:	 torch.Size([1, 256, 12, 12])
Sequential output shape:	 torch.Size([1, 384, 12, 12])
MaxPool2d output shape:	 torch.Size([1, 384, 5, 5])
Dropout output shape:	 torch.Size([1, 384, 5, 5])
Sequential output shape:	 torch.Size([1, 10, 5, 5])
AdaptiveAvgPool2d output shape:	 torch.Size([1, 10, 1, 1])
Flatten output shape:	 torch.Size([1, 10])
```

ç”¨1ä¸ªå•é€šé“224*224çš„éšæœºæ•°çœ‹çœ‹æ¨¡å‹ç»“æ„

softmaxå¸è½½trainingçš„losså‡½æ•°ä¸­,è€Œä¸æ˜¯æ”¾åœ¨ç½‘ç»œé‡Œé¢

```python
lr, num_epochs, batch_size = 0.1, 10, 128
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=224)
d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())
```

è€è§„çŸ©è·‘ä¸€ä¸‹



1. è¶…å¤§çš„å•éšè—å±‚NLPæ•ˆæœä¸ä¸€å®šå·®,ä½†æ˜¯å¾ˆå®¹æ˜“è¿‡æ‹Ÿåˆ

2.  torchscriptå¯ä»¥å°†torchæ¨¡å‹è½¬åˆ°c++,ä½†æ˜¯è¿‡äºå¤æ‚çš„æ¨¡å‹å¯èƒ½ä¼šå¤±è´¥

3. å…¨å±€æ± åŒ–å±‚å¯ä»¥**ä¸æ”¹å˜é€šé“æ•°**çš„åŒæ—¶**å‹ä½é«˜å®½,é™ä½è¾“å…¥å‚æ•°ä¸”ä¸éœ€è¦è®­ç»ƒ**,ä¸”æœ‰åŠ©äº**æå‡æ³›åŒ–æ€§**,åå¤„åˆ™æ˜¯**é™ä½æ”¶æ•›é€Ÿåº¦**,è¿™ä¸ªå°±åªèƒ½å¢åŠ epochäº†
4. pytorchç½‘ç»œæ„å»ºçš„å‚æ•°ä¼šè‡ªåŠ¨åˆå§‹åŒ–



### GoogLeNet

è¶…çº§å¤§è¶…çº§æ·±ï¼Œå¤šä¸ªç½‘ç»œå¹¶è¡Œ

Inceptionå—ï¼š

![image-20220306125537533](ææ²pytorch.assets/image-20220306125537533-16465425394322.png)

ç»“åˆäº†å¤šä¸ªå¸¸ç”¨çš„åšæ³•(æˆæœ¬é«˜)ï¼Œç›´æ¥åœ¨è¾“å‡ºçš„é€šé“æ•°channalä¸Šåšåˆå¹¶

è“è‰²éƒ¨åˆ†ä¸ºæŠ½å–ä¿¡æ¯éƒ¨åˆ†ï¼Œæ©™è‰²ä¸ºé€šé“æ•° 

**å’Œå•çº¯çš„3*3æˆ–5*5å·ç§¯æ¯”ï¼ŒInceptionå—å‚æ•°æ›´å°‘ï¼Œè®¡ç®—å¤æ‚åº¦æ›´ä½**ï¼Œè¾“å‡ºç»“æœä¹Ÿæ˜¯é€šé“æ•°åŠ å€

![image-20220306130146299](ææ²pytorch.assets/image-20220306130146299-16465429084333.png)

 

![image-20220306130352403](ææ²pytorch.assets/image-20220306130352403-16465430342594.png)

ç»„æˆ 

Inceptionæœ‰å„ç§åç»­å˜ç§
 â€¢ Inception-BN ï¼ˆv2ï¼‰-ä½¿ç”¨ batch normalization ï¼ˆåé¢ä»‹ç»ï¼‰
 â™¦ lnception-V3-ä¿®æ”¹äº†Inceptionå—
  â€¢ æ›¿æ¢5x5ä¸ºå¤šä¸ª3x3å·ç§¯å±‚
  â€¢ æ›¿æ¢5x5ä¸º1x7å’Œ7x1å·ç§¯å±‚
  â€¢ æ›¿æ¢3x3ä¸º1x3å’Œ3x1å·ç§¯å±‚
  â€¢ æ›´æ·±
 â€¢ lnception-V4-ä½¿ç”¨æ®‹å·®è¿æ¥ï¼ˆåé¢ä»‹ç»ï¼‰

  

- nceptionå—ç›¸å½“äºä¸€ä¸ªæœ‰4æ¡è·¯å¾„çš„å­ç½‘ç»œã€‚å®ƒé€šè¿‡ä¸åŒçª—å£å½¢çŠ¶çš„å·ç§¯å±‚å’Œæœ€å¤§æ±‡èšå±‚æ¥å¹¶è¡ŒæŠ½å–ä¿¡æ¯ï¼Œå¹¶ä½¿ç”¨1Ã—11Ã—1å·ç§¯å±‚å‡å°‘æ¯åƒç´ çº§åˆ«ä¸Šçš„é€šé“ç»´æ•°ä»è€Œé™ä½æ¨¡å‹å¤æ‚åº¦ã€‚ 
- GoogLeNetå°†å¤šä¸ªè®¾è®¡ç²¾ç»†çš„Inceptionå—ä¸å…¶ä»–å±‚ï¼ˆå·ç§¯å±‚ã€å…¨è¿æ¥å±‚ï¼‰ä¸²è”èµ·æ¥ã€‚å…¶ä¸­Inceptionå—çš„é€šé“æ•°åˆ†é…ä¹‹æ¯”æ˜¯åœ¨ImageNetæ•°æ®é›†ä¸Šé€šè¿‡å¤§é‡çš„å®éªŒå¾—æ¥çš„ã€‚
- GoogLeNetå’Œå®ƒçš„åç»§è€…ä»¬ä¸€åº¦æ˜¯ImageNetä¸Šæœ€æœ‰æ•ˆçš„æ¨¡å‹ä¹‹ä¸€ï¼šå®ƒä»¥è¾ƒä½çš„è®¡ç®—å¤æ‚åº¦æä¾›äº†ç±»ä¼¼çš„æµ‹è¯•ç²¾åº¦ã€‚

å…¨è¿æ¥å®¹æ˜“æ‹Ÿåˆï¼Œå¤šé€šé“å®¹æ˜“æ‹Ÿåˆï¼Œè€Œä¸”å…¨è¿æ¥å¯¹ç®—åŠ›è¦æ±‚é«˜ï¼Œæ‰€ä»¥é€‚é‡é€šé“(1024æœ€å¤š)èƒ½é˜²æ­¢è¿‡æ‹Ÿåˆ



trick:ä¸æ”¹å˜æ¨¡å‹,ä»…æ”¹å˜ä¸€äº›è¶…å‚æ•°(lr,æ•°æ®åˆå§‹åŒ–ç­‰ç­‰),å°±å¯ä»¥è®©accæœ‰å¾ˆå¤§çš„æå‡



### æ‰¹é‡å½’ä¸€åŒ–	batch normalization

å°¤å…¶æ˜¯åœ¨æ·±ç½‘ç»œçš„æ•ˆæœç‰¹åˆ«å¥½

æ‰¹é‡å½’ä¸€åŒ–
â€¢æŸå¤±å‡ºç°åœ¨æœ€åï¼Œåé¢çš„å±‚è®­ç»ƒè¾ƒå¿«
æ•°æ®åœ¨æœ€åº•éƒ¨
  â€¢ åº•éƒ¨çš„å±‚è®­ç»ƒè¾ƒæ…¢
  â€¢ åº•éƒ¨å±‚ä¸€å˜åŒ–ï¼Œæ‰€æœ‰éƒ½å¾—è·Ÿç€å˜
  â€¢ æœ€åçš„é‚£äº›å±‚éœ€è¦é‡æ–°å­¦ä¹ å¤šæ¬¡
  â€¢ å¯¼è‡´æ”¶æ•›å˜æ…¢
â€¢æˆ‘ä»¬å¯ä»¥åœ¨å­¦ä¹ åº•éƒ¨å±‚çš„æ—¶å€™é¿å…å˜ åŒ–é¡¶éƒ¨å±‚å—ï¼Ÿ



åº•éƒ¨æ‹Ÿåˆæ…¢(ä¸Šé¢çš„å‚æ•°ä¼ ä¸åˆ°ä¸‹é¢,å¯¼è‡´ä¸‹é¢è®­ç»ƒç¼“æ…¢)

å›ºå®šå°æ‰¹é‡é‡Œé¢çš„å‡å€¼å’Œæ–¹å·®

![image-20220306142036334](ææ²pytorch.assets/image-20220306142036334.png)

<img src="ææ²pytorch.assets/image-20220306142128891.png" alt="image-20220306142128891" style="zoom:50%;" />

ï¼ˆx-å‡å€¼Î¼_B)/Ïƒ _B(æ–¹å·®)		Î³å’ŒÎ²æ˜¯å¯å­¦ä¹ çš„å‚æ•°(å½“ç„¶,Î³å’ŒÎ²ä½äºä¸€å®šåŒºé—´å†…)

ãƒ»å¯å­¦ä¹ çš„å‚æ•°Î³å’ŒÎ²
ãƒ»ä½œç”¨åœ¨
	 â€¢**å…¨è¿æ¥å±‚å’Œå·ç§¯å±‚è¾“å‡ºä¸Šï¼Œæ¿€æ´»å‡½æ•°å‰**
 	â€¢å…¨è¿æ¥å±‚å’Œå·ç§¯å±‚è¾“å…¥ä¸Š
**â€¢å¯¹å…¨è¿æ¥å±‚ï¼Œä½œç”¨åœ¨ç‰¹å¾ç»´(å®½å’Œé«˜)
â€¢å¯¹äºå·ç§¯å±‚ï¼Œä½œç”¨åœ¨é€šé“ç»´(channal)**

é‡ç‚¹ï¼šå¯¹äºå·ç§¯å±‚ï¼Œä½œç”¨åœ¨é€šé“ç»´

Î¼_B,Ïƒ _Bç­‰ä»·äºå™ªéŸ³,æ§åˆ¶äº†æ¨¡å‹å¤æ‚åº¦(å’Œdropoutç›¸åŒæ•ˆæœ)(å› ä¸ºéšæœºæŠ½å°æ‰¹é‡å‡ºæ¥ç®—ï¼Œéšæœºå°±éšæœºåœ¨äº†æŠ½å–è¿™æ­¥ä¸Š)



æ€»ç»“:

â€¢æ‰¹é‡å½’ä¸€åŒ–å›ºå®šå°æ‰¹é‡ä¸­çš„å‡å€¼å’Œæ–¹å·®ï¼Œç„¶ åå­¦ä¹ å‡ºé€‚åˆçš„åç§»å’Œç¼©æ”¾
â€¢å¯ä»¥**åŠ é€Ÿæ”¶æ•›é€Ÿåº¦(å¯ä»¥ç”¨å¤§lr,å°‘epochå°±å¯ä»¥åšåˆ°å¤šepochçš„æ•ˆæœ)**ï¼Œä½†ä¸€èˆ¬**ä¸æ”¹å˜æ¨¡å‹ç²¾åº¦**		(ä¸æ”¹ç²¾åº¦è¿˜åŠ é€Ÿæ”¶æ•›,å¾ˆå¥½äº†å·²ç»)



```python
net = nn.Sequential(
    nn.Conv2d(1, 6, kernel_size=5), nn.BatchNorm2d(6), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2),
    nn.Conv2d(6, 16, kernel_size=5), nn.BatchNorm2d(16), nn.Sigmoid(),
    nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),
    nn.Linear(256, 120), nn.BatchNorm1d(120), nn.Sigmoid(),
    nn.Linear(120, 84), nn.BatchNorm1d(84), nn.Sigmoid(),
    nn.Linear(84, 10))
```

ç›´æ¥åœ¨linerå’Œsigmoidçš„è¾“å‡ºä¹‹é—´æ·»åŠ nn.BatchNorm1d(),å‚æ•°ä¸ºè¾“å‡ºå¤§å°

Conv2då·ç§¯å’Œsigmoidçš„è¾“å‡ºä¹‹é—´æ·»åŠ nn.BatchNorm2d(),å‚æ•°ä¸ºè¾“å‡ºå¤§å°

ä¸Šé¢çš„ä»£ç æ˜¯å¯¹LeNetæ·»åŠ batch Normçš„æ¼”ç¤º,å¯ä»¥è‡ªå·±å¯¹æ¯”ä¸€ä¸‹

Î¼_B,Ïƒ _Bè¿™ä¸¤ä¸ªå‚æ•°è‡ªåŠ¨æ›´æ–°



xavieræ˜¯å‚æ•°çš„å½’ä¸€åŒ–ï¼Œbatch_normalæ˜¯æ•°æ®çš„å½’ä¸€åŒ–

BNé‡Œçš„å‡å€¼å’Œæ–¹å·®éƒ½å’Œè¾“å…¥æœ‰å…³çš„ï¼Œä¸¥æ ¼æ„ä¹‰ä¸Šä¸æ˜¯çº¿æ€§å˜æ¢



layernorm	

instance normalization 





## ResNet

åŠ æ·±è®­ç»ƒä¸ä¸€å®šèƒ½å¸¦æ¥t_accçš„æé«˜

Fä¸æ˜¯å€¼åŸŸï¼Œæ˜¯å‡½æ•°ç©ºé—´ã€‚nnå°±æ˜¯å‡½æ•°æ‹Ÿåˆï¼ŒF1~6è¡¨ç¤º6ä¸ªå¯é€‰æ‹©å‡½æ•°çš„é›†åˆã€‚æ¨¡å‹è¡¨è¾¾èƒ½åŠ›çš„å¼ºå¼±ä½“ç°åœ¨ç½‘ç»œå¯æ‹Ÿåˆçš„å‡½æ•°çš„æ•°é‡

![image-20220306153937909](ææ²pytorch.assets/image-20220306153937909-16465523797975.png)

å¦‚å·¦å›¾,è™½ç„¶å‡½æ•°ç©ºé—´F_iè¶Šæ¥è¶Šå¤§,ä½†æ˜¯ç†æœ€ä½³å€¼f*è¶Šæ¥è¶Šè¿œ

ä½†æ˜¯å¦‚æœåƒå³å›¾,**å‡½æ•°ç©ºé—´F_iå±‚å±‚åµŒå¥—(nested),åˆ™F_i+1ä¸¥æ ¼(è‡³å°‘ä¸ä¼šå˜å·®)æ¯”F_iæ›´æ¥è¿‘æœ€ä¼˜å€¼f***

æ®‹å·®å—
 ãƒ»ä¸²è”ä¸€ä¸ªå±‚æ”¹å˜å‡½æ•°ç±»ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½æ‰©å¤§å‡½æ•°ç±»
 ãƒ»æ®‹å·®å—åŠ å…¥å¿«é€Ÿé€šé“(å³è¾¹)æ¥å¾—åˆ°
/(x) =x + g(x)çš„ç»“æ„

/(x) =x + g(x),ä»è€Œä½¿å¾—F_i+1çš„è¦†ç›–èŒƒå›´ä¸¥æ ¼å¤§äºF_i,ä½¿å¾—F_i+1æ¢¯åº¦è®­ç»ƒæ—¶å¯å¾—çš„æœ€ä¼˜è§£å¿…ç„¶ä¸¥æ ¼æ¯”F_iå¥½(è‡³å°‘ä¸ä¼šæ¯”F_iå·®)

å‰é¦ˆè¡¥å¿ï¼Œä½¿å¾—æ¢¯åº¦ä¸å®¹æ˜“æ¶ˆå¤±

![image-20220306154731980](ææ²pytorch.assets/image-20220306154731980-16465528534166.png)

ä½¿ç”¨1*1çš„å·ç§¯,ä½¿å¾—é€šé“æ•°å’Œæ®‹å·®ç›¸åŒ,ä»è€Œå¯ä»¥åŠ å›å»(é¿å…é€šé“æ•°ä¸ç»Ÿä¸€ï¼Œç›¸åŠ å‡ºé”™)



æ®‹å·®å—çš„å‡ºç°ä½¿å¾—ç½‘ç»œå¯ä»¥å¾ˆæ·±å¾ˆæ·±ä¹Ÿä¸è¿‡æ‹Ÿåˆ



```python
import torch
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l


class Residual(nn.Module):  #@save
    def __init__(self, input_channels, num_channels,
                 use_1x1conv=False, strides=1):
        super().__init__()
        self.conv1 = nn.Conv2d(input_channels, num_channels,
                               kernel_size=3, padding=1, stride=strides)
        self.conv2 = nn.Conv2d(num_channels, num_channels,
                               kernel_size=3, padding=1)
        if use_1x1conv:
            self.conv3 = nn.Conv2d(input_channels, num_channels,
                                   kernel_size=1, stride=strides)
            #ä½¿ç”¨1*1çš„å·ç§¯ä½¿å¾—é€šé“åŠ å€,è¦ä¸è¦å°±çœ‹è‡ªå·±éœ€æ±‚
        else:
            self.conv3 = None
        self.bn1 = nn.BatchNorm2d(num_channels)
        self.bn2 = nn.BatchNorm2d(num_channels)

    def forward(self, X):
        Y = F.relu(self.bn1(self.conv1(X)))
        Y = self.bn2(self.conv2(Y))
        if self.conv3:
            X = self.conv3(X)
        Y += X
        return F.relu(Y)
```

å»ºç«‹æ®‹å·®å—



ä¸‹é¢æˆ‘ä»¬æ¥æŸ¥çœ‹[**è¾“å…¥å’Œè¾“å‡ºå½¢çŠ¶ä¸€è‡´**]çš„æƒ…å†µ

```python
blk = Residual(3,3)
X = torch.rand(4, 3, 6, 6)
Y = blk(X)
Y.shape
```

è¾“å‡º

```
torch.Size([4, 3, 6, 6])
```



æˆ‘ä»¬ä¹Ÿå¯ä»¥åœ¨**[å¢åŠ è¾“å‡ºé€šé“æ•°çš„åŒæ—¶ï¼Œå‡åŠè¾“å‡ºçš„é«˜å’Œå®½]**ã€‚

```python
blk = Residual(3,6, use_1x1conv=True, strides=2)
blk(X).shape

```


torch.Size([4, 6, 3, 3])



ä¸‹é¢çœŸæ­£å®ç°ä¸€ä¸ª**ResNetæ¨¡å‹**



```python
b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),
                   nn.BatchNorm2d(64), nn.ReLU(),
                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))
```

å¯¹b1å—åšç‰¹æ®Šå¤„ç†( ç¬¬ä¸€ä¸ªæ¨¡å—çš„é€šé“æ•°åŒè¾“å…¥é€šé“æ•°ä¸€è‡´ã€‚ ç”±äºä¹‹å‰å·²ç»ä½¿ç”¨äº†æ­¥å¹…ä¸º2çš„æœ€å¤§æ±‡èšå±‚ï¼Œæ‰€ä»¥æ— é¡»å‡å°é«˜å’Œå®½ã€‚ ä¹‹åçš„æ¯ä¸ªæ¨¡å—åœ¨ç¬¬ä¸€ä¸ªæ®‹å·®å—é‡Œå°†ä¸Šä¸€ä¸ªæ¨¡å—çš„é€šé“æ•°ç¿»å€ï¼Œå¹¶å°†é«˜å’Œå®½å‡åŠã€‚)å½“ç„¶ä½¿ç”¨ä¹‹å‰å®šä¹‰çš„æ®‹å·®å—å‡½æ•°ä¹Ÿæ˜¯å¯ä»¥çš„

```python
def resnet_block(input_channels, num_channels, num_residuals,
                 first_block=False):
    blk = []
    for i in range(num_residuals):
        if i == 0 and not first_block:
            blk.append(Residual(input_channels, num_channels,
                                use_1x1conv=True, strides=2))
        else:
            blk.append(Residual(num_channels, num_channels))
    return blk

b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))
b3 = nn.Sequential(*resnet_block(64, 128, 2))
b4 = nn.Sequential(*resnet_block(128, 256, 2))
b5 = nn.Sequential(*resnet_block(256, 512, 2))
```

ä»…è¾“å…¥è¾“å‡ºchannalå’Œå·ç§¯æ¬¡æ•°ä¸åŒçš„æ¨¡å—ç”¨å‡½æ•°å®šä¹‰,*è§£åŒ…å nn.Sequentialæ„å»ºå±‚

```python
net = nn.Sequential(b1, b2, b3, b4, b5,
                    nn.AdaptiveAvgPool2d((1,1)),
                    nn.Flatten(), nn.Linear(512, 10))
```

nn.Sequential()å°†å°è£…å¥½çš„å±‚åˆå¹¶,å†åŠ ä¸Šå¹³å‡poolingå±‚,æ‹‰é•¿ç„¶åå…¨è¿æ¥(512channalå…¥10channalå‡º  )



batch sizeå¤ªå°è®­ç»ƒæ—¶é—´éå¸¸é•¿,å¤ªå¤§åˆ™æ³›åŒ–èƒ½åŠ›å·®(å®¹æ˜“è¿‡æ‹Ÿåˆ),æ‰€ä»¥ç›¸å¯¹å°çš„batchæ˜¯æ¯”è¾ƒæœ‰åˆ©çš„

![image-20220306162718954](ææ²pytorch.assets/image-20220306162718954-16465552403237.png)

çº¢è‰²:å›ºå®šå­¦ä¹ ç‡	è“è‰²:è¡°å‡å­¦ä¹ ç‡	ç»¿è‰²:coså­¦ä¹ ç‡(å–coså‡½æ•°çš„ä¸€éƒ¨åˆ†)



æ¯ä¸ªconvæœ‰è‡ªå·±çš„bn,æ¯ä¸ªbnæœ‰è‡ªå·±çš„å‚æ•°éœ€è¦å­¦ä¹ ,å› æ­¤æ¯ä¸ªå—ä¸­è¦å®šä¹‰num_residualsä¸ªbn

test_accå¤§äºtrain_accæ˜¯æ­£å¸¸çš„,train_accä¼šå­˜åœ¨dropout,data argumentç­‰å™ªéŸ³



éæ®‹å·®è®­ç»ƒæ—¶,å› ä¸ºä¸Šå±‚è®­ç»ƒçš„æ¯”è¾ƒå¥½,å¯¼è‡´ä¸Šå±‚çš„losså°,æ‰€ä»¥é“¾å¼æ³•åˆ™å¾—åˆ°çš„ä¸‹å±‚çš„losså˜å°äº†,å¯¼è‡´ä¸‹å±‚çš„å‚æ•°ä¸èƒ½åŠæ—¶æ›´æ–°(ç‰¹åˆ«æ˜¯ä¸Šå±‚ä½¿ç”¨å…¨è¿æ¥ç­‰æ¯”è¾ƒå¼ºæ€§èƒ½çš„å±‚æ—¶)

![image-20220306165917410](ææ²pytorch.assets/image-20220306165917410-16465571582418.png)

![image-20220306170635643](ææ²pytorch.assets/image-20220306170635643-16465575972229.png)

æ®‹å·®å—é¿å…äº†é“¾å¼æ³•åˆ™å¯¼è‡´çš„æ¢¯åº¦æ¶ˆå¤±ä»¥åŠæ¢¯åº¦çˆ†ç‚¸(å…¶ä¸­ä¸€ä¸ªåŸå› )



QA:

å­¦ä¹ ç‡å¯ä»¥è®©é è¿‘è¾“å‡ºçš„å°ä¸€äº›ï¼Œé è¿‘è¾“å…¥çš„å¤§ä¸€äº›ï¼Œè¿™æ ·å¯ä»¥ç¼“è§£æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜,(å¦‚greedy layer-wise pre-training (é€å±‚è´ªå©ªé¢„è®­ç»ƒ))



### æ•°æ®å¢å¹¿ï¼ˆæ•°æ®å¢å¼ºï¼‰

æ­¤å¤„è¯¾ç¨‹ä¸ºä¹¦æœ¬ç¬¬13ç« çš„å†…å®¹,ä»£ç åœ¨è¿™é‡Œ

http://localhost:8888/notebooks/d2l-zh%20(1)/pytorch/chapter_computer-vision/image-augmentation.ipynb

å˜è‰²(è‰²è°ƒ,é¥±å’Œåº¦,æ˜äº®åº¦)åˆ‡å‰²,ç¿»è½¬(å·¦å³ç¿»è½¬å¤š,ä¸Šä¸‹ç¿»è½¬æ¯”è¾ƒå°‘)è¿™äº›éƒ½å±äºæ•°æ®å¢å¼º(å¦‚imgaugï¼Œalbumentationsç­‰ï¼Œéƒ½å¯ä»¥çœ‹çœ‹)

![image-20220306183200076](ææ²pytorch.assets/image-20220306183200076-164656272163710.png)

ä¸€å¼ å›¾å¾—å¤šå¼ å›¾

ä»£ç :å¯¼å…¥å›¾ç‰‡å’ŒåŒ…å…ˆè·³è¿‡

```python
def apply(img, aug, num_rows=2, num_cols=4, scale=1.5):
    Y = [aug(img) for _ in range(num_rows * num_cols)]
    d2l.show_images(Y, num_rows, num_cols, scale=scale)
```

ä¼ å…¥å›¾ç‰‡,å¢å¹¿æ–¹æ³•ç­‰å‚æ•°,å±•ç¤ºå¢å¹¿åçš„å›¾ç‰‡

```python
apply(img, torchvision.transforms.RandomHorizontalFlip())
```

æ°´å¹³æ–¹å‘éšæœºç¿»è½¬

```python
apply(img, torchvision.transforms.RandomVerticalFlip())
```

å‚ç›´æ–¹å‘éšæœºç¿»è½¬



```python
shape_aug = torchvision.transforms.RandomResizedCrop(
    (200, 200), scale=(0.1, 1), ratio=(0.5, 2))
apply(img, shape_aug)
```

ç¼©æ”¾	(200, 200)è¾“å‡ºå½¢çŠ¶	scale=(0.1, 1)æ”¾å¤§å€æ•°	 ratio=(0.5, 2)é«˜å®½æ¯” 



```python
apply(img, torchvision.transforms.ColorJitter(
    brightness=0.5, contrast=0, saturation=0, hue=0))
```

[**éšæœºæ›´æ”¹å›¾åƒçš„äº®åº¦**]ï¼Œéšæœºå€¼ä¸ºåŸå§‹å›¾åƒçš„50%ï¼ˆ1âˆ’0.5ï¼‰åˆ°150%ï¼ˆ1+0.5ï¼‰ä¹‹é—´ã€‚



```python
apply(img, torchvision.transforms.ColorJitter(
    brightness=0, contrast=0, saturation=0, hue=0.5))
```

åŒæ ·ï¼Œæˆ‘ä»¬å¯ä»¥[**éšæœºæ›´æ”¹å›¾åƒçš„è‰²è°ƒ**]ã€‚



```python
color_aug = torchvision.transforms.ColorJitter(
    brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)
apply(img, color_aug)
```

åˆ›å»ºä¸€ä¸ª`RandomColorJitter`å®ä¾‹color_augï¼Œå¹¶è®¾ç½®å¦‚ä½•åŒæ—¶[**éšæœºæ›´æ”¹å›¾åƒçš„äº®åº¦ï¼ˆ`brightness`ï¼‰ã€å¯¹æ¯”åº¦ï¼ˆ`contrast`ï¼‰ã€é¥±å’Œåº¦ï¼ˆ`saturation`ï¼‰å’Œè‰²è°ƒï¼ˆ`hue`ï¼‰**]ã€‚



```python
augs = torchvision.transforms.Compose([
    torchvision.transforms.RandomHorizontalFlip(), color_aug, shape_aug])
apply(img, augs)
```

ç”¨torchvision.transforms.Composeå¯¹åˆšåˆšçš„ä¸¤ä¸ªæ“ä½œè¿›è¡Œåˆå¹¶



```python
augs = torchvision.transforms.Compose([
    torchvision.transforms.RandomHorizontalFlip(), color_aug, shape_aug])
apply(img, augs)
```

åˆå¹¶åˆšåˆšå®ä¾‹åŒ–äº†çš„æ“ä½œ

è®­ç»ƒå‰å…ˆä¿å­˜å¢å¼ºçš„trainingæ•°æ®,å†è¿›è¡Œ

#### å°ç»“

- å›¾åƒå¢å¹¿åŸºäºç°æœ‰çš„è®­ç»ƒæ•°æ®ç”Ÿæˆéšæœºå›¾åƒï¼Œæ¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
- ä¸ºäº†åœ¨é¢„æµ‹è¿‡ç¨‹ä¸­å¾—åˆ°ç¡®åˆ‡çš„ç»“æœï¼Œæˆ‘ä»¬é€šå¸¸å¯¹è®­ç»ƒæ ·æœ¬åªè¿›è¡Œå›¾åƒå¢å¹¿ï¼Œè€Œåœ¨é¢„æµ‹è¿‡ç¨‹ä¸­ä¸ä½¿ç”¨å¸¦éšæœºæ“ä½œçš„å›¾åƒå¢å¹¿ã€‚
- æ·±åº¦å­¦ä¹ æ¡†æ¶æä¾›äº†è®¸å¤šä¸åŒçš„å›¾åƒå¢å¹¿æ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•å¯ä»¥è¢«åŒæ—¶åº”ç”¨ã€‚



ç†è®ºä¸Šæ•°æ®å¤Ÿå¤šå°±ä¸ç”¨åšå¢å¹¿,ä½†æ˜¯å®é™…å¾ˆéš¾è¯´æ•°æ®çœŸçš„å¤Ÿå¤šäº†**å› ä¸ºæ•°æ®å¤šä¸ä¸€å®šå¤šæ ·æ€§å¤Ÿå¥½**

å¯¹äºæåº¦åæ–œé¢„æµ‹(æ­£ç¡®oré”™è¯¯æ ·æœ¬å æ€»æ¯”éå¸¸éå¸¸å°‘),å¯ä»¥å¯¹æ­£æ ·æœ¬é‡‡ç”¨æ•°æ®å¢å¼º

å›¾ç‰‡å¢å¹¿æ˜¯ä¸å½±å“è®­ç»ƒé›†çš„åˆ†å¸ƒçš„, 

 mixup:ä¸€ç§ä¸é”™çš„å¢å¹¿æ–¹å¼,æµ‹è¯•å›¾ç‰‡çº¿æ€§å åŠ ,æ ‡ç­¾é¡µå åŠ (æŒ‰çº¿æ€§æ¯”ä¾‹,æ¯”å¦‚ç”¨one-hotå°±å¥½è¡¨ç¤ºäº†)

 å¢é‡å­¦ä¹ ï¼Œincremental learning

å¢å¹¿ä¸æ”¹å˜å‡å€¼,ä½†æ˜¯è®©æ–¹å·®å˜å¤§äº†

å¢å¹¿ä¸€èˆ¬ä¸ä¼šå‡å°‘ç±»é—´å·®å¼‚

 



### å¾®è°ƒ	fine-tuning

http://localhost:8888/notebooks/d2l-zh%20(1)/pytorch/chapter_computer-vision/fine-tuning.ipynb

åœ¨å·²æœ‰çš„æ¨¡å‹åŸºç¡€ä¸Šï¼Œä»…éœ€è¦å°‘é‡ä¿¡æ¯å³å¯åšåˆ°ä¸é”™çš„æ•ˆæœ(è¿ç§»å­¦ä¹ çš„ä¸€éƒ¨åˆ†)

æ­£å¸¸è€Œè¨€,æå–ç‰¹å¾çš„å±‚ä»ç„¶æ˜¯å¯ç”¨çš„(å­¦ä¹ ä¸€ä¸‹æ•ˆæœå°±ä¸é”™äº†),ä½†æ˜¯æœ€åçš„è¾“å‡º(softmaxå±‚)è¦é‡æ–°æ„å»º

è®­ç»ƒæ—¶,ä½¿ç”¨æ›´å°çš„lr,æ›´å°‘çš„æ•°æ®è¿­ä»£

é‡ç”¨åˆ†ç±»å™¨æƒé‡
ãƒ»æºæ•°æ®é›†å¯èƒ½ä¹Ÿæœ‰ç›®æ ‡æ•° æ®ä¸­çš„éƒ¨åˆ†æ ‡å·
ãƒ»å¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒå¥½æ¨¡å‹åˆ† ç±»å™¨ä¸­å¯¹åº”æ ‡å·å¯¹åº”çš„å‘ é‡æ¥åšåˆå§‹åŒ–



å›ºå®šä¸€äº›å±‚
ãƒ»ç¥ç»ç½‘ç»œé€šå¸¸å­¦ä¹ æœ‰å±‚æ¬¡çš„ç‰¹å¾è¡¨ç¤º
 	â€¢ä½å±‚æ¬¡çš„ç‰¹å¾æ›´åŠ é€šç”¨
 	â€¢é«˜å±‚æ¬¡çš„ç‰¹å¾åˆ™æ›´è·Ÿæ•°æ®é›†ç›¸å…³
ãƒ»å¯ä»¥å›ºå®šåº•éƒ¨ä¸€äº›å±‚çš„å‚æ•°ï¼Œä¸å‚ä¸æ›´æ–°
	 â€¢æ›´å¼ºçš„æ­£åˆ™



##### æ€»ç»“

ãƒ» å¾®è°ƒé€šè¿‡ä½¿ç”¨åœ¨å¤§æ•°æ®ä¸Šå¾—åˆ°çš„é¢„è®­ç»ƒå¥½ çš„æ¨¡å‹æ¥åˆå§‹åŒ–æ¨¡å‹æƒé‡æ¥å®Œæˆæå‡ç²¾åº¦
ãƒ» é¢„è®­ç»ƒæ¨¡å‹è´¨é‡å¾ˆé‡è¦
ãƒ» å¾®è°ƒé€šå¸¸é€Ÿåº¦æ›´å¿«ã€ç²¾åº¦æ›´é«˜







ä»£ç :

åœ¨è®­ç»ƒæœŸé—´ï¼Œæˆ‘ä»¬é¦–å…ˆä»å›¾åƒä¸­è£åˆ‡éšæœºå¤§å°å’Œéšæœºé•¿å®½æ¯”çš„åŒºåŸŸï¼Œç„¶åå°†è¯¥åŒºåŸŸç¼©æ”¾ä¸º224Ã—224è¾“å…¥å›¾åƒã€‚ åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å›¾åƒçš„é«˜åº¦å’Œå®½åº¦éƒ½ç¼©æ”¾åˆ°256åƒç´ ï¼Œç„¶åè£å‰ªä¸­å¤®224Ã—224åŒºåŸŸä½œä¸ºè¾“å…¥ã€‚ æ­¤å¤–ï¼Œå¯¹äºRGBï¼ˆçº¢ã€ç»¿å’Œè“ï¼‰é¢œè‰²é€šé“ï¼Œæˆ‘ä»¬åˆ†åˆ«*æ ‡å‡†åŒ–*æ¯ä¸ªé€šé“ã€‚ å…·ä½“è€Œè¨€ï¼Œè¯¥é€šé“çš„æ¯ä¸ªå€¼å‡å»è¯¥é€šé“çš„å¹³å‡å€¼ï¼Œç„¶åå°†ç»“æœé™¤ä»¥è¯¥é€šé“çš„æ ‡å‡†å·®ã€‚		**å³æ•°æ®å¢å¹¿**

```python
# ä½¿ç”¨RGBé€šé“çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼Œä»¥æ ‡å‡†åŒ–æ¯ä¸ªé€šé“(è¿™é‡Œçš„å‡å€¼å’Œæ–¹å·®æ¥è‡ªæ•°æ®é›†æœ¬èº«)
normalize = torchvision.transforms.Normalize(
    [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])

train_augs = torchvision.transforms.Compose([
    torchvision.transforms.RandomResizedCrop(224),
    torchvision.transforms.RandomHorizontalFlip(),
    torchvision.transforms.ToTensor(),
    normalize])

test_augs = torchvision.transforms.Compose([
    torchvision.transforms.Resize(256),
    torchvision.transforms.CenterCrop(224),
    torchvision.transforms.ToTensor(),
    normalize])
```



æ¨¡å‹éƒ¨åˆ†:

```python
pretrained_net = torchvision.models.resnet18(pretrained=True)
finetune_net.fc = nn.Linear(finetune_net.fc.in_features, 2)
nn.init.xavier_uniform_(finetune_net.fc.weight)#åªå¯¹æœ€åä¸€å±‚åšéšæœºåˆå§‹åŒ–
```

pretrained=Trueä½¿ç”¨æ¨¡å‹æœ¬èº«çš„å‚æ•°	finetune_net.fc:full connectå…¨è¿æ¥å±‚åˆå§‹åŒ–ä¸ºè¾“å‡ºç±»åˆ«ä¸º2		

```python
# å¦‚æœparam_group=Trueï¼Œè¾“å‡ºå±‚ä¸­çš„æ¨¡å‹å‚æ•°å°†ä½¿ç”¨åå€çš„å­¦ä¹ ç‡
def train_fine_tuning(net, learning_rate, batch_size=128, num_epochs=5,
                      param_group=True):
    train_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(
        os.path.join(data_dir, 'train'), transform=train_augs),
        batch_size=batch_size, shuffle=True)
    test_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(
        os.path.join(data_dir, 'test'), transform=test_augs),
        batch_size=batch_size)
    devices = d2l.try_all_gpus()
    loss = nn.CrossEntropyLoss(reduction="none")
    if param_group:
        params_1x = [param for name, param in net.named_parameters()
             if name not in ["fc.weight", "fc.bias"]]
        trainer = torch.optim.SGD([{'params': params_1x},
                                   {'params': net.fc.parameters(),
                                    'lr': learning_rate * 10}],
                                lr=learning_rate, weight_decay=0.001)
    else:
        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate,
                                  weight_decay=0.001)
    d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,
                   devices)
```

if param_groupéƒ¨åˆ†:param_group=True,åˆ™æœ€åä¸€å±‚çš„å­¦ä¹ ç‡æ˜¯å‰é¢å±‚çš„10å€,å¦åˆ™å’Œå‰é¢ä¸€æ ·



QA:

æ•°æ®ä¸å¹³è¡¡å¯¼è‡´çš„ä¸»è¦æ˜¯æ ‡å·çš„ä¸å¹³è¡¡(ä¸Šå±‚æŠ½è±¡å±‚),å¯¹ç‰¹å¾æå–å™¨å½±å“ä¸å¤§

åŸæ•°æ®é›†å’Œæ–°æ•°æ®é›†å¯¹äºåŒä¸€ç§ç±»çš„åç§°å¯èƒ½ä¸ä¸€æ ·,è¿˜å¾—åšä¸€ä¸ªè¯­ä¹‰åŒ¹é…

åŸæ•°æ®é›†å’Œç›®æ ‡æ•°æ®é›†æœ€å¥½æœ‰ç›¸ä¼¼éƒ¨åˆ†

å…³äºâ€œé‡ç”¨åˆ†ç±»å™¨æƒé‡â€ï¼Œå¯¹äºä¸€ä¸ª80ç±»çš„æ•°æ®é›†ï¼Œåªæƒ³é€‰ç”¨å…¶ä¸­5 ç±»ï¼ŒåŠ ä¸Šå¦å¤–çš„4ç±»ï¼Œæ–¹æ³•åªæœ‰æ‰‹åŠ¨æå–,æˆ–è€…ç›´æ¥è®­ç»ƒè¾“å‡ºå±‚

å›ºå®šä¸€äº›å±‚å¯ä»¥çœ‹ä½œæ˜¯ä¸€ç§æ­£åˆ™åŒ–(æ‹Ÿåˆåº¦é™ä½),å“ªäº›å›ºå®šå“ªäº›æ”¹å­¦ä¹ ç‡çœ‹å®é™…æƒ…å†µ

åŸºæœ¬ä¸Š,åº•å±‚å’Œç‰¹å¾æœ‰å…³çš„å±‚å¤§éƒ½å¯¹å…¶ä»–æ¨¡å‹æœ‰å¸®åŠ©,ä¸Šå±‚æŠ½è±¡åŒ–çš„ç‰¹å¾ç»„åˆé‡æ–°è®­ç»ƒä¹Ÿæ˜¯ä¸€ç§å¥½é€‰æ‹©





### ç›®æ ‡æ£€æµ‹å’Œè¾¹ç•Œæ¡†

ç›®æ ‡æ£€æµ‹å’Œå›¾ç‰‡åˆ†ç±»åŒºåˆ«:

1. ç›®æ ‡æ£€æµ‹éœ€è¦åœ¨å›¾ç‰‡ä¸­æ‰¾å‡ºæ‰€æœ‰æ„Ÿå…´è¶£çš„ç›®æ ‡(å…ˆæ‰¾ä½ç½®å†è¯†åˆ«,è€Œä¸”ä¸æ­¢ä¸€ä¸ª)

   å›¾ç‰‡åˆ†ç±»åªéœ€è¦è¯†åˆ«å›¾ç‰‡ä¸­å«æœ‰çš„å…ƒç´ 

â€‹	æ¡†ä¸€èˆ¬ç”¨ä¸­å¿ƒç‚¹åæ ‡(x,y),å®½é«˜(h,r)æˆ–è€…å·¦ä¸Šå³ä¸‹çš„(x,y)



#### é”šæ¡†

é‡‡é›†å›¾ç‰‡åŒºåŸŸ, åˆ¤æ–­è¿™äº›åŒºåŸŸä¸­æ˜¯å¦åŒ…å«æˆ‘ä»¬æ„Ÿå…´è¶£çš„ç›®æ ‡ï¼Œå¹¶è°ƒæ•´åŒºåŸŸè¾¹ç•Œä»è€Œæ›´å‡†ç¡®åœ°é¢„æµ‹ç›®æ ‡çš„*çœŸå®è¾¹ç•Œæ¡†*ï¼ˆground-truth bounding boxï¼‰ã€‚ ä¸åŒçš„æ¨¡å‹ä½¿ç”¨çš„åŒºåŸŸé‡‡æ ·æ–¹æ³•å¯èƒ½ä¸åŒã€‚ è¿™é‡Œæˆ‘ä»¬ä»‹ç»å…¶ä¸­çš„ä¸€ç§æ–¹æ³•ï¼šä»¥æ¯ä¸ªåƒç´ ä¸ºä¸­å¿ƒï¼Œç”Ÿæˆå¤šä¸ªç¼©æ”¾æ¯”å’Œå®½é«˜æ¯”ï¼ˆaspect ratioï¼‰ä¸åŒçš„è¾¹ç•Œæ¡†ã€‚ è¿™äº›è¾¹ç•Œæ¡†è¢«ç§°ä¸º*é”šæ¡†*ï¼ˆanchor boxï¼‰



å¯¹äºæ•°æ®é›†æ ‡è®°,ä¸€èˆ¬æ‰‹åŠ¨æ ‡è®°100ä¸ªæ ·æœ¬,ç„¶åè¿ç§»å­¦ä¹ +åŠç›‘ç£å­¦ä¹ å°†å‰©ä¸‹çš„æ ‡å·æå®š

â€¢ä¸€ç±»ç›®æ ‡æ£€æµ‹ç®—æ³•æ˜¯åŸºäºé”šæ¡†
 â€¢ æå‡ºå¤šä¸ªè¢«ç§°ä¸ºé”šæ¡†çš„åŒºåŸŸ è¾¹ç¼˜æ¡†ï¼‰
 â€¢ é¢„æµ‹æ¯ä¸ªé”šæ¡†é‡Œæ˜¯å¦å«æœ‰å…³æ³¨çš„ç‰©ä½“(æ˜¯æˆ–ä¸æ˜¯)
 â€¢ å¦‚æœæ˜¯ï¼Œé¢„æµ‹ä»è¿™ä¸ªé”šæ¡†åˆ°çœŸå®è¾¹ç¼˜æ¡†çš„åç§»(loss)

##### IOUäº¤å¹¶æ¯”

è®¡ç®—ä¸¤ä¸ªæ¡†çš„ç›¸ä¼¼åº¦![image-20220307194052805](ææ²pytorch.assets/image-20220307194052805-16466532541831.png)

ç¤ºæ„å›¾ ![image-20220307194300745](ææ²pytorch.assets/image-20220307194300745-16466533825182.png)

###### å¯¹äºé”šæ¡†è€Œè¨€

â€¢ æ¯ä¸ªé”šæ¡†æ˜¯ä¸€ä¸ªè®­ç»ƒæ ·æœ¬
â€¢ å°†æ¯ä¸ªé”šæ¡†ï¼Œè¦ä¹ˆæ ‡æ³¨æˆèƒŒæ™¯(è¢«æŠ›å¼ƒ)ï¼Œè¦ä¹ˆ å…³è”ä¸Šä¸€ä¸ªçœŸå®è¾¹ç¼˜æ¡†(å¯ä»¥è®¡ç®—lossäº†)
â€¢ æˆ‘ä»¬å¯èƒ½ä¼šç”Ÿæˆå¤§é‡çš„é”šæ¡†ï¼šè¿™å¯¼è‡´å¤§é‡çš„è´Ÿç±»æ ·æœ¬

###### é”šæ¡†éšæœºç”Ÿæˆ,å› æ­¤æ•°é‡ä¸€èˆ¬è¿œå¤§äºè¾¹ç¼˜æ¡†(ä¸€å¼ å›¾çš„è¾¹ç¼˜æ¡†ä¸ªæ•°æœ‰ä¸Šé™)ã€‚å¯¹ç›¸æ¡†æ‰¾å’Œè‡ªå·±IOUæœ€é«˜çš„é‚£ä¸ªé”šæ¡†

â€¢åœ¨æ¯ä¸€ä¸ªç‰©ä½“åˆ†é…ä¸€ä¸ªé”šæ¡†å å‰©ä¸‹çš„é”šæ¡†è¿˜ä¼šå†æ ¹æ®è®¾å®šçš„é˜ˆå€¼åˆ†é…ä¸€æ¬¡ï¼Œè¿™ä¸€æ­¥ä¼šè¿‡æ»¤æ‰å¾ˆå¤šé”šæ¡†ï¼Œä½†æ˜¯ä¹Ÿæœ‰ä¸€äº›é”šæ¡†ä¼šè¢«åˆ†é…ç»™çœŸå®æ¡†

###### ç„¶åä½¿ç”¨éæå¤§å€¼æŠ‘åˆ¶ï¼ˆNMSï¼‰è¾“å‡º

â€¢æ¯ä¸ªé”šæ¡†é¢„æµ‹ä¸€ä¸ªè¾¹ç¼˜æ¡†
â€¢ NMSå¯ä»¥åˆå¹¶ç›¸ä¼¼çš„é¢„æµ‹
  â€¢ é€‰ä¸­æ˜¯éèƒŒæ™¯ç±»çš„æœ€å¤§é¢„æµ‹å€¼
  â€¢ å»æ‰æ‰€æœ‰å…¶å®ƒé”šæ¡†å’Œè¿™ä¸ªè¾¹ç¼˜æ¡†loUå€¼å¤§äºÎ¸çš„é¢„æµ‹
  â€¢ é‡å¤ä¸Šè¿°è¿‡ç¨‹ç›´åˆ°æ‰€æœ‰é”šæ¡†è¦ä¹ˆè¢«é€‰ä¸­ï¼Œè¦ä¹ˆè¢«å»æ‰(è¢«NMSå»æ‰æˆ–å½“ä½œèƒŒæ™¯å»æ‰)

ä¸€ç±»ç›®æ ‡æ£€æµ‹ç®—æ³•åŸºäºé”šæ¡†æ¥é¢„æµ‹
â€¢é¦–å…ˆç”Ÿæˆå¤§é‡é”šæ¡†ï¼Œå¹¶èµ‹äºˆæ ‡å·ï¼Œæ¯ä¸ª é”šæ¡†ä½œä¸ºä¸€ä¸ªæ ·æœ¬è¿›è¡Œè®­ç»ƒ
â€¢åœ¨é¢„æµ‹æ—¶ï¼Œä½¿ç”¨NMSæ¥å»æ‰å†—ä½™çš„é¢„æµ‹



ä»£ç ï¼š

sizeé”šæ¡†å¤§å°  ratioé«˜å®½æ¯”

é”šæ¡†çš„å®½å’Œé«˜åˆ†åˆ«ä¸ºwsâˆšrå’Œhs/âˆšr

```python
#@save
def multibox_prior(data, sizes, ratios):
    """ç”Ÿæˆä»¥æ¯ä¸ªåƒç´ ä¸ºä¸­å¿ƒå…·æœ‰ä¸åŒå½¢çŠ¶çš„é”šæ¡†"""
    in_height, in_width = data.shape[-2:]
    device, num_sizes, num_ratios = data.device, len(sizes), len(ratios)
    boxes_per_pixel = (num_sizes + num_ratios - 1)
    size_tensor = torch.tensor(sizes, device=device)
    ratio_tensor = torch.tensor(ratios, device=device)

    # ä¸ºäº†å°†é”šç‚¹ç§»åŠ¨åˆ°åƒç´ çš„ä¸­å¿ƒï¼Œéœ€è¦è®¾ç½®åç§»é‡ã€‚
    # å› ä¸ºä¸€ä¸ªåƒç´ çš„çš„é«˜ä¸º1ä¸”å®½ä¸º1ï¼Œæˆ‘ä»¬é€‰æ‹©åç§»æˆ‘ä»¬çš„ä¸­å¿ƒ0.5
    offset_h, offset_w = 0.5, 0.5
    steps_h = 1.0 / in_height  # åœ¨yè½´ä¸Šç¼©æ”¾æ­¥é•¿
    steps_w = 1.0 / in_width  # åœ¨xè½´ä¸Šç¼©æ”¾æ­¥é•¿

    # ç”Ÿæˆé”šæ¡†çš„æ‰€æœ‰ä¸­å¿ƒç‚¹
    center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h
    center_w = (torch.arange(in_width, device=device) + offset_w) * steps_w
    shift_y, shift_x = torch.meshgrid(center_h, center_w)
    shift_y, shift_x = shift_y.reshape(-1), shift_x.reshape(-1)

    # ç”Ÿæˆâ€œboxes_per_pixelâ€ä¸ªé«˜å’Œå®½ï¼Œ
    # ä¹‹åç”¨äºåˆ›å»ºé”šæ¡†çš„å››è§’åæ ‡(xmin,xmax,ymin,ymax)
    w = torch.cat((size_tensor * torch.sqrt(ratio_tensor[0]),
                   sizes[0] * torch.sqrt(ratio_tensor[1:])))\
                   * in_height / in_width  # å¤„ç†çŸ©å½¢è¾“å…¥
    h = torch.cat((size_tensor / torch.sqrt(ratio_tensor[0]),
                   sizes[0] / torch.sqrt(ratio_tensor[1:])))
    # é™¤ä»¥2æ¥è·å¾—åŠé«˜å’ŒåŠå®½
    anchor_manipulations = torch.stack((-w, -h, w, h)).T.repeat(
                                        in_height * in_width, 1) / 2

    # æ¯ä¸ªä¸­å¿ƒç‚¹éƒ½å°†æœ‰â€œboxes_per_pixelâ€ä¸ªé”šæ¡†ï¼Œ
    # æ‰€ä»¥ç”Ÿæˆå«æ‰€æœ‰é”šæ¡†ä¸­å¿ƒçš„ç½‘æ ¼ï¼Œé‡å¤äº†â€œboxes_per_pixelâ€æ¬¡
    out_grid = torch.stack([shift_x, shift_y, shift_x, shift_y],
                dim=1).repeat_interleave(boxes_per_pixel, dim=0)
    output = out_grid + anchor_manipulations
    return output.unsqueeze(0)
```

åˆ›å»ºå‡½æ•°,è‡ªåŠ¨ç”Ÿæˆé”šæ¡†

```python
img = d2l.plt.imread('../img/catdog.jpg')
h, w = img.shape[:2]

print(h, w)
X = torch.rand(size=(1, 3, h, w))
Y = multibox_prior(X, sizes=[0.75, 0.5, 0.25], ratios=[1, 2, 0.5])
Y.shape

boxes = Y.reshape(h, w, 5, 4)
boxes[250, 250, 0, :]
```

å®ä¾‹åŒ–ä¸€ä¸‹,è¾“å‡ºå¦‚ä¸‹

```python
561 728
torch.Size([1, 2042040, 4])	#ç”Ÿæˆäº†ä¸¤ç™¾ä¸‡ä¸ªé”šæ¡†

tensor([0.06, 0.07, 0.63, 0.82])	#ç¬¬ä¸€ä¸ªé”šæ¡†çš„å·¦ä¸‹å³ä¸Šç›¸å¯¹åæ ‡
```



IOU

```python
#@save
def box_iou(boxes1, boxes2):
    """è®¡ç®—ä¸¤ä¸ªé”šæ¡†æˆ–è¾¹ç•Œæ¡†åˆ—è¡¨ä¸­æˆå¯¹çš„äº¤å¹¶æ¯”"""
    box_area = lambda boxes: ((boxes[:, 2] - boxes[:, 0]) *
                              (boxes[:, 3] - boxes[:, 1]))
    # boxes1,boxes2,areas1,areas2çš„å½¢çŠ¶:
    # boxes1ï¼š(boxes1çš„æ•°é‡,4),
    # boxes2ï¼š(boxes2çš„æ•°é‡,4),
    # areas1ï¼š(boxes1çš„æ•°é‡,),
    # areas2ï¼š(boxes2çš„æ•°é‡,)
    areas1 = box_area(boxes1)
    areas2 = box_area(boxes2)
    # inter_upperlefts,inter_lowerrights,intersçš„å½¢çŠ¶:
    # (boxes1çš„æ•°é‡,boxes2çš„æ•°é‡,2)
    inter_upperlefts = torch.max(boxes1[:, None, :2], boxes2[:, :2])  #äº¤é›†
    inter_lowerrights = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])
    inters = (inter_lowerrights - inter_upperlefts).clamp(min=0)
    # inter_areasandunion_areasçš„å½¢çŠ¶:(boxes1çš„æ•°é‡,boxes2çš„æ•°é‡)
    inter_areas = inters[:, :, 0] * inters[:, :, 1]
    union_areas = areas1[:, None] + areas2 - inter_areas #å¹¶é›†=box1+box2-äº¤é›†
    return inter_areas / union_areas
```





  ```python
  inter_upperlefts = torch.max(boxes1[:, None, :2], boxes2[:, :2])
  ```

Noneå€ŸåŠ©å¹¿æ’­ä»¤ä¸¤ä¸ªliståˆ›å»ºäº†æ–°çš„ç»´åº¦



éƒ¨åˆ†ä»£ç çš„ç†è§£å‚è€ƒä»¥ä¸‹ç½‘å€

https://blog.csdn.net/qq_36136196/article/details/118862685



```python
#è¾“å…¥çœŸå®gtè¾¹ç•Œæ¡†[n1,4],ç”Ÿæˆçš„é”šæ¡†[n2,4],deviceè®¾å¤‡,åˆ†é…ç»™é”šæ¡†æ˜¯éèƒŒæ™¯çš„é˜ˆå€¼,è¾“å‡ºå€¼ä¸ºæ¯ä¸ªanchorå¯¹åº”çš„çœŸå®gtè¾¹ç•Œæ¡†çš„ç´¢å¼•[n2]
def assign_anchor_to_bbox(ground_truth,anchors,device,iou_threshold=0.5):
    """ç»™æ¯ä¸€ä¸ªé”šæ¡†åˆ†é…æœ€æ¥è¿‘çš„çœŸå®è¾¹ç•Œæ¡†ï¼ˆæˆ–è€…èƒŒæ™¯ï¼‰"""
    # é”šæ¡†çš„æ•°é‡anchor[n1],çœŸå®è¾¹ç•Œæ¡†çš„æ•°é‡[n2]
    num_anchors,num_gt_boxes = anchors.shape[0],ground_truth[0]
    # è®¡ç®—æ¯ä¸ªé”šæ¡†ä¸æ¯ä¸ªçœŸå®è¾¹ç•Œæ¡†çš„iouå€¼ï¼Œ[n1,n2]
    jaccard = box_iou(anchors,ground_truth)
    # å»ºä¸€ä¸ªtensorå½“ä½œmapï¼Œç”¨æ¥æ”¾å¯¹æ¯ä¸ªé”šæ¡†æ‰€å¯¹åº”çš„çœŸå®è¾¹ç•Œæ¡†ï¼Œé»˜è®¤ä¸º-1,[n1]
    anchors_bbox_map = torch.full((num_anchors,),-1,dtype=torch.long,device=device)
    # å¾—åˆ°æ¯è¡Œçš„æœ€å¤§å€¼ï¼Œå³å¯¹äºæ¯ä¸ªé”šæ¡†æ¥è¯´ï¼Œiouæœ€å¤§çš„é‚£ä¸ªçœŸå®è¾¹ç•Œæ¡†ï¼Œè¿”å›iouå€¼å’Œå¯¹åº”çœŸå®è¾¹ç•Œæ¡†ç´¢å¼•å€¼[n1],[n1]
    max_ious,indices = torch.max(jaccard,dim=1)
    # æ ¹æ®é˜ˆå€¼å¾—åˆ°é”šæ¡†ä¸ä¸ºèƒŒæ™¯çš„ç›¸åº”çš„ç´¢å¼•å€¼[<=n1]
    anc_i = torch.nonzero(max_ious>=iou_threshold).reshape(-1)
    # æ ¹æ®é˜ˆå€¼å¾—åˆ°é”šæ¡†ä¸ä¸ºèƒŒæ™¯çš„çœŸå®è¾¹ç•Œæ¡†ç´¢å¼•å€¼[<=n1]ï¼Œä¸anc_iä¸€ä¸€å¯¹åº”çš„
    box_j = indices[max_ious>=iou_threshold]
    # æŒ‘å‡º>=iou_thresholdçš„å€¼,é‡æ–°èµ‹å€¼ï¼Œä¹Ÿå°±æ˜¯å¯¹æ¯ä¸ªé”šæ¡†ï¼Œå¾—åˆ°å¤§äºç»™å®šé˜ˆå€¼çš„åŒ¹é…çš„çœŸå®gtè¾¹ç•Œæ¡†çš„å¯¹åº”ç´¢å¼•
    anchors_bbox_map[anc_i] = box_j
    #è¡Œï¼Œåˆ—çš„é»˜è®¤å€¼[n1],[n2]
    col_discard = torch.full((num_anchors,),-1)
    row_discard = torch.full((num_gt_boxes,),-1)

    # ä»¥ä¸‹å¯¹æ¯ä¸ªçœŸå®è¾¹ç•Œæ¡†é‡æ–°åˆ†é…ç»™çš„é”šæ¡†ï¼Œæ‰€ä»¥ï¼Œå¾ªç¯æ¬¡æ•°æ˜¯gt boxçš„ä¸ªæ•°ã€‚é˜²æ­¢åœ¨æœ€å¤§å€¼èµ‹å€¼æ—¶ï¼ŒæŸå‡ ä¸ªé”šæ¡†å¯¹åº”åŒä¸€ä¸ªçœŸå®è¾¹ç•Œæ¡†
    for _ in range(num_gt_boxes):
        #å–å¾—è¯¥çŸ©å½¢ä¸­æœ€å¤§å€¼çš„ç´¢å¼•ï¼Œæ˜¯æŒ‰reshape(-1)å¾—åˆ°çš„ç´¢å¼• 0-(n1*n2-1)
        max_idx = torch.argmax(jaccard)
        # å¾—åˆ°çŸ©é˜µæœ€å¤§å€¼æ‰€åœ¨çš„åˆ—ï¼Œå°±æ˜¯å¯¹åº”çš„çœŸå®gtè¾¹ç•Œæ¡†çš„ç´¢å¼•
        box_idx = (max_idx%num_gt_boxes).long()
        # å¾—åˆ°çŸ©é˜µæœ€å¤§å€¼æ‰€åœ¨çš„è¡Œï¼Œæ˜¯å¯¹åº”çš„é”šæ¡†çš„ç´¢å¼•
        anc_idx = (max_idx/num_gt_boxes).long()
        # é‡æ–°èµ‹å€¼ï¼Œå°±æ˜¯çŸ©é˜µæœ€å¤§iouå€¼ä¸­é”šæ¡†ä¸å…¶å¯¹åº”çš„çœŸå®gtè¾¹ç•Œæ¡†
        anchors_bbox_map[anc_idx] = box_idx
        # å°†æœ€å¤§å€¼æ‰€åœ¨è¯¥è¡Œç½®ä¸º-1
        jaccard[:,box_idx] = col_discard
        # å°†æœ€å¤§å€¼æ‰€åœ¨è¯¥åˆ—ç½®ä¸º-1
        jaccard[anc_idx,:] = row_discard
    # è¿”å›å€¼æ˜¯æ¯ä¸ªanchorå¯¹åº”çš„çœŸå®gtè¾¹ç•Œæ¡†çš„ç´¢å¼•(å…¶å®æ˜¯list)
    return anchors_bbox_map

```

  jaccard(ä»£æŒ‡IOU)

```python
for _ in range(num_gt_boxes):
    max_idx = torch.argmax(jaccard)
    box_idx = (max_idx % num_gt_boxes).long()
    anc_idx = (max_idx / num_gt_boxes).long()
    anchors_bbox_map[anc_idx] = box_idx
    jaccard[:, box_idx] = col_discard
    jaccard[anc_idx, :] = row_discard
```

æ‰¾åˆ°æœ€å¤§å€¼,åˆ é™¤æœ€å¤§å€¼æ‰€åœ¨çš„è¡Œå’Œåˆ—é™¤è‡ªå·±ä»¥å¤–æ‰€æœ‰çš„å€¼,ç¤ºæ„å›¾å¦‚ä¸‹

![image-20220308003618853](ææ²pytorch.assets/image-20220308003618853-16466709802214.png)





ç°åœ¨æˆ‘ä»¬å¯ä»¥ä¸ºæ¯ä¸ªé”šæ¡†æ ‡è®°ç±»åˆ«å’Œåç§»é‡äº†ã€‚ å‡è®¾ä¸€ä¸ªé”šæ¡†Aè¢«åˆ†é…äº†ä¸€ä¸ªçœŸå®è¾¹ç•Œæ¡†Bã€‚ ä¸€æ–¹é¢ï¼Œé”šæ¡†AAçš„ç±»åˆ«å°†è¢«æ ‡è®°ä¸ºä¸Bç›¸åŒã€‚ å¦ä¸€æ–¹é¢ï¼Œé”šæ¡†Açš„åç§»é‡å°†æ ¹æ®Bå’ŒAä¸­å¿ƒåæ ‡çš„ç›¸å¯¹ä½ç½®ä»¥åŠè¿™ä¸¤ä¸ªæ¡†çš„ç›¸å¯¹å¤§å°è¿›è¡Œæ ‡è®°ã€‚ é‰´äºæ•°æ®é›†å†…ä¸åŒçš„æ¡†çš„ä½ç½®å’Œå¤§å°ä¸åŒï¼Œæˆ‘ä»¬å¯ä»¥å¯¹é‚£äº›ç›¸å¯¹ä½ç½®å’Œå¤§å°åº”ç”¨å˜æ¢ï¼Œä½¿å…¶è·å¾—åˆ†å¸ƒæ›´å‡åŒ€ä¸”æ˜“äºæ‹Ÿåˆçš„åç§»é‡ã€‚ åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä»‹ç»ä¸€ç§å¸¸è§çš„å˜æ¢ã€‚ ç»™å®šæ¡†Aå’ŒBï¼Œä¸­å¿ƒåæ ‡åˆ†åˆ«ä¸º(xa,ya)(xa,ya)å’Œ(xb,yb)(xb,yb)ï¼Œå®½åº¦åˆ†åˆ«ä¸ºwaå’Œwbï¼Œé«˜åº¦åˆ†åˆ«ä¸ºhaå’Œhbã€‚ æˆ‘ä»¬å¯ä»¥å°†AAçš„åç§»é‡æ ‡è®°ä¸ºï¼š

![image-20220308003958773](ææ²pytorch.assets/image-20220308003958773.png)

14:04,é”šæ¡†åç§»é‡

```python
def offset_boxes(anchors, assigned_bb, eps=1e-6):
    """å¯¹é”šæ¡†åç§»é‡çš„è½¬æ¢"""
    c_anc = d2l.box_corner_to_center(anchors)
    c_assigned_bb = d2l.box_corner_to_center(assigned_bb)
    offset_xy = 10 * (c_assigned_bb[:, :2] - c_anc[:, :2]) / c_anc[:, 2:]
    offset_wh = 5 * torch.log(eps + c_assigned_bb[:, 2:] / c_anc[:, 2:])
    offset = torch.cat([offset_xy, offset_wh], axis=1)
    return offset
```

å…¶ä¸­å¸¸é‡çš„é»˜è®¤å€¼ä¸º ğœ‡ğ‘¥=ğœ‡ğ‘¦=ğœ‡ğ‘¤=ğœ‡â„=0,ğœğ‘¥=ğœğ‘¦=0.1ï¼Œ ğœğ‘¤=ğœâ„=0.2ã€‚ è¿™ç§è½¬æ¢åœ¨ä¸‹é¢çš„ `offset_boxes` å‡½æ•°ä¸­å®ç°ã€‚

```python
#@save
def multibox_target(anchors, labels):
    """ä½¿ç”¨çœŸå®è¾¹ç•Œæ¡†æ ‡è®°é”šæ¡†"""
    batch_size, anchors = labels.shape[0], anchors.squeeze(0)
    batch_offset, batch_mask, batch_class_labels = [], [], []
    device, num_anchors = anchors.device, anchors.shape[0]
    for i in range(batch_size):
        label = labels[i, :, :]
        anchors_bbox_map = assign_anchor_to_bbox(
            label[:, 1:], anchors, device)
        bbox_mask = ((anchors_bbox_map >= 0).float().unsqueeze(-1)).repeat(
            1, 4)
        # å°†ç±»æ ‡ç­¾å’Œåˆ†é…çš„è¾¹ç•Œæ¡†åæ ‡åˆå§‹åŒ–ä¸ºé›¶
        class_labels = torch.zeros(num_anchors, dtype=torch.long,
                                   device=device)
        assigned_bb = torch.zeros((num_anchors, 4), dtype=torch.float32,
                                  device=device)
        # ä½¿ç”¨çœŸå®è¾¹ç•Œæ¡†æ¥æ ‡è®°é”šæ¡†çš„ç±»åˆ«ã€‚
        # å¦‚æœä¸€ä¸ªé”šæ¡†æ²¡æœ‰è¢«åˆ†é…ï¼Œæˆ‘ä»¬æ ‡è®°å…¶ä¸ºèƒŒæ™¯ï¼ˆå€¼ä¸ºé›¶ï¼‰
        indices_true = torch.nonzero(anchors_bbox_map >= 0)
        bb_idx = anchors_bbox_map[indices_true]
        class_labels[indices_true] = label[bb_idx, 0].long() + 1
        assigned_bb[indices_true] = label[bb_idx, 1:]
        # åç§»é‡è½¬æ¢
        offset = offset_boxes(anchors, assigned_bb) * bbox_mask
        batch_offset.append(offset.reshape(-1))
        batch_mask.append(bbox_mask.reshape(-1))
        batch_class_labels.append(class_labels)
    bbox_offset = torch.stack(batch_offset)
    bbox_mask = torch.stack(batch_mask)
    class_labels = torch.stack(batch_class_labels)
    return (bbox_offset, bbox_mask, class_labels)
```

è¿™ä¸ªå‡½æ•°bbox_offset:anchoråˆ°æ ‡æ³¨(lablel)çš„offset		

bbox_mask:0æŒ‡èƒŒæ™¯,1åˆ™æœ‰å¯¹åº”çš„è¾¹ç¼˜æ¡†

class_labels:é”šæ¡†å¯¹åº”çš„ç±»çš„æ ‡å· 



#### ä¸€ä¸ªä¾‹å­[Â¶](http://localhost:8888/notebooks/d2l-zh (1)/pytorch/chapter_computer-vision/anchor.ipynb#ä¸€ä¸ªä¾‹å­)

ä¸¾ä¸ªä¾‹å­,éšä¾¿æ–°å»ºå‡ ä¸ªé”šæ¡†,åŒæ—¶è¿˜å¾—æŠŠçœŸå®æ¡†é€‰å‡ºæ¥

```python
ground_truth = torch.tensor([[0, 0.1, 0.08, 0.52, 0.92],
                         [1, 0.55, 0.2, 0.9, 0.88]])
anchors = torch.tensor([[0, 0.1, 0.2, 0.3], [0.15, 0.2, 0.4, 0.4],
                    [0.63, 0.05, 0.88, 0.98], [0.66, 0.45, 0.8, 0.8],
                    [0.57, 0.3, 0.92, 0.9]])

fig = d2l.plt.imshow(img)
show_bboxes(fig.axes, ground_truth[:, 1:] * bbox_scale, ['dog', 'cat'], 'k')
show_bboxes(fig.axes, anchors * bbox_scale, ['0', '1', '2', '3', '4']);
```

IoUå¤§äºé˜ˆå€¼ä¸ºæ­£ç±»,å¦åˆ™ä¸ºèƒŒæ™¯



```python
labels = multibox_target(anchors.unsqueeze(dim=0),
                         ground_truth.unsqueeze(dim=0))

labels[2]
labels[1]
```

labels[2]æ˜¯å¯¹åº”çš„ç±»		labels[1]æ˜¯mask(1æœ‰å¯¹åº”çš„ç±»,0ä¸ºèƒŒæ™¯,4ä¸ªä¸€ç»„)		

labels[0]åŒ…å«äº†ä¸ºæ¯ä¸ªé”šæ¡†æ ‡è®°çš„å››ä¸ªåç§»å€¼ã€‚ è¯·æ³¨æ„ï¼Œè´Ÿç±»é”šæ¡†çš„åç§»é‡è¢«æ ‡è®°ä¸ºé›¶ã€‚





#### ä½¿ç”¨éæå¤§å€¼æŠ‘åˆ¶é¢„ æµ‹è¾¹ç•Œæ¡†[Â¶](http://localhost:8888/notebooks/d2l-zh (1)/pytorch/chapter_computer-vision/anchor.ipynb#ä½¿ç”¨éæå¤§å€¼æŠ‘åˆ¶é¢„æµ‹è¾¹ç•Œæ¡†)

åœ¨é¢„æµ‹æ—¶ï¼Œæˆ‘ä»¬å…ˆä¸ºå›¾åƒç”Ÿæˆå¤šä¸ªé”šæ¡†ï¼Œå†ä¸ºè¿™äº›é”šæ¡†ä¸€ä¸€é¢„æµ‹ç±»åˆ«å’Œåç§»é‡ã€‚ ä¸€ä¸ªâ€œé¢„æµ‹å¥½çš„è¾¹ç•Œæ¡†â€åˆ™æ ¹æ®å…¶ä¸­æŸä¸ªå¸¦æœ‰é¢„æµ‹åç§»é‡çš„é”šæ¡†è€Œç”Ÿæˆã€‚ ä¸‹é¢æˆ‘ä»¬å®ç°äº†`offset_inverse`å‡½æ•°ï¼Œè¯¥å‡½æ•°å°†é”šæ¡†å’Œåç§»é‡é¢„æµ‹ä½œä¸ºè¾“å…¥ï¼Œå¹¶[**åº”ç”¨é€†åç§»å˜æ¢æ¥è¿”å›é¢„æµ‹çš„è¾¹ç•Œæ¡†åæ ‡**]ã€‚

```python
def offset_inverse(anchors, offset_preds):
    """æ ¹æ®å¸¦æœ‰é¢„æµ‹åç§»é‡çš„é”šæ¡†æ¥é¢„æµ‹è¾¹ç•Œæ¡†"""
    anc = d2l.box_corner_to_center(anchors)
    pred_bbox_xy = (offset_preds[:, :2] * anc[:, 2:] / 10) + anc[:, :2]
    pred_bbox_wh = torch.exp(offset_preds[:, 2:] / 5) * anc[:, 2:]
    pred_bbox = torch.cat((pred_bbox_xy, pred_bbox_wh), axis=1)
    predicted_bbox = d2l.box_center_to_corner(pred_bbox)
    return predicted_bbox
```



[**ä»¥ä¸‹`nms`å‡½æ•°æŒ‰é™åºå¯¹ç½®ä¿¡åº¦è¿›è¡Œæ’åºå¹¶è¿”å›å…¶ç´¢å¼•**]ã€‚

```python
def nms(boxes, scores, iou_threshold):
    """å¯¹é¢„æµ‹è¾¹ç•Œæ¡†çš„ç½®ä¿¡åº¦è¿›è¡Œæ’åº"""
    B = torch.argsort(scores, dim=-1, descending=True)
    keep = []  # ä¿ç•™é¢„æµ‹è¾¹ç•Œæ¡†çš„æŒ‡æ ‡
    while B.numel() > 0:
        i = B[0]
        keep.append(i)
        if B.numel() == 1: break
        iou = box_iou(boxes[i, :].reshape(-1, 4),
                      boxes[B[1:], :].reshape(-1, 4)).reshape(-1)
        inds = torch.nonzero(iou <= iou_threshold).reshape(-1)
        B = B[inds + 1]
    return torch.tensor(keep, device=boxes.device)
```



nms(æå¤§å€¼æŠ‘åˆ¶),å°†non_keep(ç½®ä¿¡åº¦ä¸æ˜¯æœ€é«˜çš„)æ ‡ç­¾æ‰€æœ‰é¡¹è®¾ä¸ºèƒŒæ™¯

```python
def multibox_detection(cls_probs, offset_preds, anchors, nms_threshold=0.5,
                       pos_threshold=0.009999999):
    """ä½¿ç”¨éæå¤§å€¼æŠ‘åˆ¶æ¥é¢„æµ‹è¾¹ç•Œæ¡†"""
    device, batch_size = cls_probs.device, cls_probs.shape[0]
    anchors = anchors.squeeze(0)
    num_classes, num_anchors = cls_probs.shape[1], cls_probs.shape[2]
    out = []
    for i in range(batch_size):
        cls_prob, offset_pred = cls_probs[i], offset_preds[i].reshape(-1, 4)
        conf, class_id = torch.max(cls_prob[1:], 0)
        predicted_bb = offset_inverse(anchors, offset_pred)
        keep = nms(predicted_bb, conf, nms_threshold)

        # æ‰¾åˆ°æ‰€æœ‰çš„non_keepç´¢å¼•ï¼Œå¹¶å°†ç±»è®¾ç½®ä¸ºèƒŒæ™¯
        all_idx = torch.arange(num_anchors, dtype=torch.long, device=device)
        combined = torch.cat((keep, all_idx))
        uniques, counts = combined.unique(return_counts=True)
        non_keep = uniques[counts == 1]
        all_id_sorted = torch.cat((keep, non_keep))
        class_id[non_keep] = -1
        class_id = class_id[all_id_sorted]
        conf, predicted_bb = conf[all_id_sorted], predicted_bb[all_id_sorted]
        # pos_thresholdæ˜¯ä¸€ä¸ªç”¨äºéèƒŒæ™¯é¢„æµ‹çš„é˜ˆå€¼
        below_min_idx = (conf < pos_threshold)
        class_id[below_min_idx] = -1
        conf[below_min_idx] = 1 - conf[below_min_idx]
        pred_info = torch.cat((class_id.unsqueeze(1),
                               conf.unsqueeze(1),
                               predicted_bb), dim=1)
        out.append(pred_info)
    return torch.stack(out)
```





QA:è¿½æ±‚æ€§èƒ½è€ƒè™‘C++,ä½†æ˜¯pythonè¿ç§»æ€§å¥½

â€‹	ä¸€ä¸ªanchorå¯¹åº”ä¸€ä¸ªçœŸå®æ¡†

â€‹	æœ€å¤§çš„é¢„æµ‹å€¼ï¼ŒæŒ‡çš„æ˜¯åˆ†ç±»çš„ç½®ä¿¡åº¦(classçš„ç½®ä¿¡åº¦);é”šæ¡†æ˜¯ä¸€ä¸ªå›å½’é—®é¢˜,å›å½’æ²¡æœ‰ç½®ä¿¡åº¦

nmsæœ‰ä¸¤ç§åšæ³•:1.åªé’ˆå¯¹ç›¸åŒç±»åˆ«åšå¾ªç¯è¿‡æ»¤å»é™¤	2.å¯¹ä¸åŒç±»åˆ«åšè¿‡æ»¤å»é™¤

 æ³¨æ„,è¿™é‡Œæˆ‘ä»¬åªæ˜¯è®²äº†é”šæ¡†çš„åº”ç”¨å’Œå¤„ç†(nsmç­‰),ç”»é”šæ¡†çš„ç®—æ³•ä¸‹é¢è®²



### æ¯”èµ›æ€»ç»“2:

æŠ€æœ¯åˆ†æ:

å¯¹äºæ•°æ®å¢å¼º,å¤šæ¬¡ä½¿ç”¨ç¨å¼±çš„å¢å¼ºç„¶åå–å¹³å‡

ä½¿ç”¨å¤šä¸ªæ¨¡å‹é¢„æµ‹,ç„¶ååŠ æƒå¹³å‡ 

##### æ•°æ®åˆ†æ:

æ‰‹åŠ¨å»é™¤é‡å¤å›¾ç‰‡

â€¢æœ‰é‡å¤å›¾ç‰‡ï¼Œå¯ä»¥æ‰‹åŠ¨å»é™¤ 

â€¢å›¾ç‰‡èƒŒæ™¯è¾ƒå¤šï¼Œè€Œä¸”æ ‘å¶æ²¡æœ‰æ–¹å‘æ€§ï¼Œå¯ä»¥åšæ›´å¤šå¢å¼º 

â€‹	ãƒ»éšæœºæ—‹è½¬ï¼Œæ›´å¤§çš„å‰ªè£

â€¢è·¨å›¾ç‰‡å¢å¼ºï¼š 

â€‹	Mixupï¼šéšæœºå åŠ ä¸¤å¼ å›¾ç‰‡ 

â€‹	CutMixï¼šéšæœºç»„åˆæ¥è‡ªä¸åŒå›¾ç‰‡çš„å—

æ¨¡å‹æ–¹é¢
 â€¢æ¨¡å‹å¤šä¸ºResNetå˜ç§
  ãƒ» DenseNet, ResNeXt, ResNeSt,...
  ãƒ» EfficientNet
 â€¢ä¼˜åŒ–ç®—æ³•å¤šä¸ºAdam(ä¸æ€ä¹ˆè°ƒå‚æ•ˆæœä¹Ÿä¸é”™(ä¸‹é™é«˜ä¸Šé™ä½))æˆ–å…¶å˜ç§
 ãƒ»å­¦ä¹ ç‡ä¸€èˆ¬æ˜¯Cosineæˆ–è€…è®­ç»ƒä¸åŠ¨æ—¶å¾€ä¸‹è°ƒ(åæ­£æ¯ä¸€ä¸ªç‚¹éƒ½åšä¸€ä¸ªcheck point,ä¹Ÿä¸æ€•è¿‡æ‹Ÿåˆå•¥çš„)

#### AutoGluon

https://www.kaggle.com/zhreshold/autogluon-vision-0-96-with-15-lines

è¿™é‡Œæ˜¯ä¸€ä¸ªAutoGluonè®­ç»ƒçš„æ¨¡å‹,æ— éœ€è°ƒå‚,è‡ªåŠ¨æ„å»ºæ¨¡å‹,ç²¾åº¦ä¸é«˜ä½†æ˜¯éå¸¸ç®€å•



æ€»ç»“

â€¢æå‡ç²¾åº¦æ€è·¯ï¼šæ ¹æ®æ•°æ®æŒ‘é€‰å¢å¼ºï¼Œä½¿ç”¨æ–°æ¨¡å‹ã€æ–°ä¼˜åŒ– ç®—æ³•ï¼Œå¤šä¸ªæ¨¡å‹èåˆï¼Œæµ‹è¯•æ—¶ä½¿ç”¨å¢å¼º
â– æ•°æ®ç›¸å¯¹ç®€å•ï¼Œæ’åæœ‰ç›¸å¯¹éšæœºæ€§
â€¢åœ¨å·¥ä¸šç•Œåº”ç”¨ä¸­ï¼š(æ•°æ®è·å–è¾ƒä¸ºç®€å•,æ•°æ®æŒç»­æ”¹å˜(è·å–))
	 â€¢å°‘ä½¿ç”¨æ¨¡å‹èåˆå’Œæµ‹è¯•æ—¶å¢å¼ºï¼Œè®¡ç®—ä»£ä»·è¿‡é«˜
	 â€¢é€šå¸¸å›ºå®šæ¨¡å‹è¶…å‚æ•°ï¼Œ
 	 è€Œå°†ç²¾åŠ›ä¸»è¦èŠ±åœ¨æå‡æ•°æ®è´¨é‡

å­¦æœ¯:å›ºå®šæ•°æ®è°ƒæ¨¡å‹			å·¥ä¸š:å›ºå®šæ¨¡å‹è°ƒæ•°æ®(ä¼˜åŒ–æ•°æ®è´¨é‡)







#### åŒºåŸŸå·ç§¯ç¥ç»ç½‘ç»œï¼ˆR-CNNï¼‰

â€¢ ä½¿ç”¨å¯å‘å¼æœç´¢ç®—æ³•æ¥é€‰æ‹©é”šæ¡†
â€¢ ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹(CNNç­‰)æ¥å¯¹**æ¯ä¸ªé”šæ¡†æŠ½å–ç‰¹å¾**
â€¢ è®­ç»ƒä¸€ä¸ªSVMæ¥å¯¹ç±»åˆ«åˆ†ç±»
â€¢ è®­ç»ƒä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹æ¥é¢„æµ‹è¾¹ç¼˜æ¡†åç§»



RoI(region of interest)æ± åŒ–å±‚	å…´è¶£åŒºåŸŸ	

â€¢ç»™å®šä¸€ä¸ªé”šæ¡†, å‡åŒ€åˆ†å‰²æˆn x må—ï¼Œè¾“å‡ºæ¯å—é‡Œçš„æœ€å¤§å€¼
ãƒ»ä¸ç®¡é”šæ¡†å¤šå¤§,æ€»æ˜¯è¾“å‡ºn*mä¸ªå€¼(æ–¹ä¾¿åšbatch)

ç¤ºæ„å›¾,ä»å·¦åˆ°å³ç»å†äº†ä¸€ä¸ª2*2çš„ RoI Poolingå±‚

![image-20220308191307266](ææ²pytorch.assets/image-20220308191307266-16467379889901.png)



#### Fast RCNN

â€¢ä½¿ç”¨CNNå¯¹**æ•´å¼ å›¾ç‰‡**æŠ½å–ç‰¹å¾
â€¢ä½¿ç”¨å¯å‘å¼æœç´¢(selectice search)å¯»æ‰¾é”šæ¡†
â€¢ä½¿ç”¨Rolæ± åŒ–å±‚å¯¹æ¯ä¸ªé”šæ¡†ç”Ÿæˆå›ºå®šé•¿åº¦ ç‰¹å¾

![image-20220308192936381](ææ²pytorch.assets/image-20220308192936381-16467389774863.png)

#### Fastr RCNN

ä½¿ç”¨åŒºåŸŸæè®®ç½‘ç»œ(RPN)ä»£æ›¿å¯å‘å¼æœç´¢æ¥å¾—åˆ°æ›´å¥½çš„é”šæ¡†

![image-20220308192913412](ææ²pytorch.assets/image-20220308192913412-16467389544872.png)



#### Mask RCNN

å¦‚æœæœ‰åƒç´ çº§çš„æ ‡å·,ç”¨FCN(Fully convolutional network)æ¥åˆ©ç”¨è¿™äº›ä¿¡æ¯

RoI align:å¯èƒ½åšRoIæ± åŒ–çš„æ—¶å€™åƒç´ çº§æ ‡å·éšç€è®­ç»ƒå¯¼è‡´å‡ºé”™,æ‰€ä»¥é€‰ç”¨

<img src="https://pic4.zhimg.com/80/v2-03d820b27ffca39854f0febf0ef9e37b_720w.jpg" alt="img" style="zoom:50%;" />

ç±»ä¼¼è¿™æ ·çš„åˆ†ç±»æ–¹æ³•,è¿ç»­å¼åœ°æ± åŒ–åå†æŒ‰weightåˆ†é…æœ€å¤§å€¼å›å»

![image-20220308193414116](ææ²pytorch.assets/image-20220308193414116-16467392555294.png)

##### æ€»ç»“

â€¢R-CNNæ˜¯æœ€æ—©ã€ä¹Ÿæ˜¯æœ€æœ‰åçš„ä¸€ç±»åŸºäºé”š æ¡†å’ŒCNNçš„ç›®æ ‡æ£€æµ‹ç®—æ³•
â€¢ Fast/FasterR-CNNæŒç»­æå‡æ€§èƒ½
â€¢ Faster R-CNN å’Œ Mask Râ€”CNNæ˜¯åœ¨æœ€æ±‚é«˜ç²¾åº¦åœºæ™¯ä¸‹çš„å¸¸ç”¨ç®—æ³•



### 

å¦‚å›¾,ä¸€èˆ¬è€Œè¨€,å¯¹äºæ¯ä¸ªåƒç´ ç‚¹,ç”Ÿæˆnä¸ªé¢„è®¾é«˜å®½æ¯”çš„é”šæ¡†

![image-20220308195253842](ææ²pytorch.assets/image-20220308195253842-16467403756815.png)

### SSDå•å‘å¤šæ¡†æ£€æµ‹

![image-20220308195504204](ææ²pytorch.assets/image-20220308195504204-16467405060336.png)

Â·â€”ä¸ªåŸºç¡€ç½‘ç»œæ¥æŠ½å–ç‰¹å¾ï¼Œç„¶åå¤šä¸ªå·ç§¯å±‚å—æ¥å‡åŠé«˜å®½
Â·åº•éƒ¨æ®µæ¥æ‹Ÿåˆå°ç‰©ä½“,
Â·é¡¶éƒ¨æ®µæ¥æ‹Ÿåˆå¤§ç‰©ä½“
Â·å¯¹æ¯ä¸ªé”šæ¡†é¢„æµ‹ç±»åˆ«å’Œè¾¹ç¼˜æ¡†

Â·å¯¹äºä¸‹é¢çš„å±‚,åˆ†è¾¨ç‡é«˜,é”šæ¡†å¤š,åœˆå°ç‰©ä½“
Â·ä¸Šå±‚å·ç§¯å‡åŠé«˜å®½ä»¥å,é”šæ¡†å¤§å°ä¸å˜(æˆ–å˜å°ä¸€ç‚¹ç‚¹),æ‰€ä»¥å¯ä»¥é¢„æµ‹å¤§ç‰©ä½“

ç°åœ¨å·²ç»ä¸å’‹ç”¨çš„(å‡ºç°çš„å¤ªæ—©,æ²¡æœ‰æ€ä¹ˆä¿®æ­£)

##### æ€»ç»“

Â·SSDé€šè¿‡å•ç¥ç»ç½‘ç»œæ¥æ£€æµ‹æ¨¡å‹

Â·ä»¥æ¯ä¸ªåƒç´ ä¸ºä¸­å¿ƒçš„äº§ ç”Ÿå¤šä¸ªé”šæ¡†

Â·åœ¨å¤šä¸ªæ®µçš„è¾“å‡ºä¸Šè¿›è¡Œå¤šå°ºåº¦çš„æ£€æµ‹

#### ä»£ç ï¼š[Â¶](http://localhost:8888/notebooks/d2l-zh (1)/pytorch/chapter_computer-vision/ssd.ipynb#å•å‘å¤šæ¡†æ£€æµ‹ï¼ˆSSDï¼‰)



#### [**ç±»åˆ«é¢„æµ‹å±‚**] 

```python
%matplotlib inline
import torch
import torchvision
from torch import nn
from torch.nn import functional as F
from d2l import torch as d2l


def cls_predictor(num_inputs, num_anchors, num_classes):
    return nn.Conv2d(num_inputs, num_anchors * (num_classes + 1),
                     kernel_size=3, padding=1)
```

num_classes + 1	åŠ ä¸€ä¸ªèƒŒæ™¯ç±»

kernel_size=3, padding=1	ä¸æ”¹å˜é«˜å®½,åªæ”¹å˜é€šé“

ç‰¹å¾å›¾**æ¯ä¸ªåƒç´ **å¯¹åº”aé”šæ¡†,æ¯ä¸ªé”šæ¡†å¯¹åº”qä¸ªåˆ†ç±»,å•ä¸ªåƒç´ å°±è¦a*(q+1)ä¸ªé¢„æµ‹ä¿¡æ¯ï¼Œè¿™ä¸ªä¿¡æ¯ï¼Œé€šè¿‡å·ç§¯æ ¸çš„å¤šä¸ªé€šé“æ¥å­˜å‚¨, æ‰€ä»¥è¿™é‡Œè¿›è¡Œå·ç§¯æ“ä½œã€‚å›¾åƒåˆ†ç±»,åªé¢„æµ‹åˆ†ç±»æƒ…å†µ,æ‰€ä»¥æ¥å…¨è¿æ¥å±‚,è¿™é‡Œå•ä¸ªåƒç´ çš„é¢„æµ‹ç»“æœå¤ªå¤š,å°±ç”¨å¤šä¸ªé€šé“æ¥å­˜



#### **è¾¹ç•Œæ¡†é¢„æµ‹å±‚**

```python
def bbox_predictor(num_inputs, num_anchors):
    return nn.Conv2d(num_inputs,
                     num_anchors * 4,
                     kernel_size=3, 
                     padding=1)
```

é‡Œéœ€è¦ä¸ºæ¯ä¸ªé”šæ¡†é¢„æµ‹4ä¸ªåç§»é‡ï¼Œè€Œä¸æ˜¯q+1ä¸ªç±»åˆ«ã€‚



#### [**è¿ç»“å¤šå°ºåº¦çš„é¢„æµ‹**]

```python
def forward(x, block):
    return block(x)

Y1 = forward(torch.zeros((2, 8, 20, 20)), cls_predictor(8, 5, 10))
Y2 = forward(torch.zeros((2, 16, 10, 10)), cls_predictor(16, 3, 10))
Y1.shape, Y2.shape
```

forward(torch.zeros((2, 8, 20, 20))	feature mapçš„å‚æ•°	8å¯¹åº”channalæ•°(å‰é¢çš„8),5æ˜¯æ¯ä¸ªåƒç´ ç”Ÿæˆçš„é”šæ¡†æ•°,10æ˜¯ç±»åˆ«æ•°,ä¸åŒçš„feature mapåœ¨å·ç§¯å±‚ä¸­å¾—åˆ°

è¾“å‡º

```
(torch.Size([2, 55, 20, 20]), torch.Size([2, 33, 10, 10]))
```

55=5*(10+1),åé¢çš„é«˜å®½ä¸å˜,Y2åŒç†



```python
def flatten_pred(pred):
    return torch.flatten(pred.permute(0, 2, 3, 1), start_dim=1)

def concat_preds(preds):
    return torch.cat([flatten_pred(p) for p in preds], dim=1)

concat_preds([Y1, Y2]).shape
```

flatten_pred()å‡½æ•°:è°ƒæ•´é€šé“æ•°,è¿™é‡ŒæŠŠé€šé“æ•°æŒªåˆ°äº†æœ€å,

start_dim=1,ä»ç¬¬äºŒç»´åº¦å¼€å§‹å±•å¼€,ä»è€Œå˜ä¸º2dçŸ©é˜µ,ç¬¬ä¸€ç»´æ˜¯batchå¤§å°,åé¢åˆ™æ˜¯h *w *channal,channalæ”¾æœ€åä½¿å¾—hå’Œwåœ¨listä¸Šè¿ç»­



è¾“å‡º:

```python
torch.Size([2, 25300])
```

å°†æ‰€æœ‰çš„é¢„æµ‹ç»“æœéƒ½æ”¾åœ¨åŒä¸€ä¸ªç»´åº¦



#### [**é«˜å’Œå®½å‡åŠå—**]

```python
def down_sample_blk(in_channels, out_channels):
    blk = []
    for _ in range(2):
        blk.append(nn.Conv2d(in_channels, out_channels,
                             kernel_size=3, padding=1))
        blk.append(nn.BatchNorm2d(out_channels))
        blk.append(nn.ReLU())
        in_channels = out_channels
    blk.append(nn.MaxPool2d(2))
    return nn.Sequential(*blk)
```

å®šä¹‰ä¸€ä¸ªCNNç½‘ç»œ,æ¯æ¬¡hå’Œwå‡åŠ(æ± åŒ–å±‚),å‚æ•°ä¸ºè¾“å…¥channalå’Œè¾“å‡ºchannal(å·ç§¯å±‚)

```python
forward(torch.zeros((2, 3, 20, 20))
down_sample_blk(3, 10)).shape
```

è¾“å…¥channal3,è¾“å‡ºchannal10



```python
def base_net():
    blk = []
    num_filters = [3, 16, 32, 64]
    for i in range(len(num_filters) - 1):
        blk.append(down_sample_blk(num_filters[i], num_filters[i+1]))
    return nn.Sequential(*blk)

forward(torch.zeros((2, 3, 256, 256)), base_net()).shape
```

é€šé“æ•°ä»3->16->32->64	,æ¯æ¬¡é«˜å®½å‡å°‘ä¸€åŠ(å³1/8),å…±è®¡ä¸‰ä¸ªdown_sample_blk



```python
def get_blk(i):
    if i == 0:
        blk = base_net()
    elif i == 1:
        blk = down_sample_blk(64, 128)
    elif i == 4:
        blk = nn.AdaptiveMaxPool2d((1,1))
    else:
        blk = down_sample_blk(128, 128)
    return blk
```

åˆ°æœ€åå°†ç½‘ç»œç”¨MaxPool2då‹æˆ1*1çš„

æ•°æ®é›†ä¸å¤§å¤æ‚,æ‰€ä»¥ä»…ä»…æ˜¯å·ç§¯åˆ°128ä¸ªchannalå°±ç®—äº†

 ç¬¬ä¸€ä¸ªæ˜¯åŸºæœ¬ç½‘ç»œå—ï¼Œç¬¬äºŒä¸ªåˆ°ç¬¬å››ä¸ªæ˜¯é«˜å’Œå®½å‡åŠå—ï¼Œæœ€åä¸€ä¸ªæ¨¡å—ä½¿ç”¨å…¨å±€æœ€å¤§æ± å°†é«˜åº¦å’Œå®½åº¦éƒ½é™åˆ°1ã€‚ä»æŠ€æœ¯ä¸Šè®²ï¼Œç¬¬äºŒåˆ°ç¬¬äº”ä¸ªåŒºå—éƒ½æ˜¯ :numref:`fig_ssd`ä¸­çš„å¤šå°ºåº¦ç‰¹å¾å—ã€‚



```python
def blk_forward(X, blk, size, ratio, cls_predictor, bbox_predictor):
    Y = blk(X)
    anchors = d2l.multibox_prior(Y, sizes=size, ratios=ratio)
    cls_preds = cls_predictor(Y)
    bbox_preds = bbox_predictor(Y)
    return (Y, anchors, cls_preds, bbox_preds)
```

Xè¾“å…¥	blkå—	size ratioé”šæ¡†çš„å¤§å°å’Œé«˜å®½æ¯”

d2l.multibox_prior()ç”Ÿæˆé”šæ¡†çš„ç›¸å…³æ•°æ®

cls_preds = cls_predictor(Y),è¿™é‡Œä¼ å…¥äº†feature map,é”šæ¡†åœ¨å‰å‘ä¼ æ’­æ—¶ä¸éœ€è¦ä¼ å…¥,cls_preds ä»…ä»…åªæ˜¯å¯¹æ¯ä¸ªé”šæ¡†çš„ç±»å‹çš„é¢„æµ‹

bbox_preds:é”šæ¡†åˆ°çœŸå®è¾¹ç¼˜æ¡†çš„offsetåç§» çš„é¢„æµ‹



##### è¶…å‚æ•°: 

```python
sizes = [[0.2, 0.272], [0.37, 0.447], [0.54, 0.619], [0.71, 0.79],
         [0.88, 0.961]]
ratios = [[1, 2, 0.5]] * 5
num_anchors = len(sizes[0]) + len(ratios[0]) - 1
```

è¶…å‚æ•°:sizeçš„[] [1]æ˜¯æŒ‡æ ‡å‡†æ¡†(é«˜å®½æ¯”ä¾‹å’Œå›¾ç‰‡ç›¸åŒ)å å›¾ç‰‡çš„è¾¹é•¿çš„æ¯”

[0.2, 0.272],ä¸€ä¸ªæ¡†å å›¾ç‰‡é¢ç§¯çš„4%,åé¢åŒç†

0.2å’Œ1.05ä¹‹é—´çš„åŒºé—´è¢«å‡åŒ€åˆ†æˆäº”ä¸ªéƒ¨åˆ†ï¼Œä»¥ç¡®å®šäº”ä¸ªæ¨¡å—çš„åœ¨ä¸åŒå°ºåº¦ä¸‹çš„è¾ƒå°å€¼ï¼š0.2ã€0.37ã€0.54ã€0.71å’Œ0.88ã€‚ ä¹‹åï¼Œä»–ä»¬è¾ƒå¤§çš„å€¼ç”±âˆš(0.2Ã—0.37)=0.272,

âˆš(0.37Ã—0.54)=0.447ç­‰ç»™å‡º

ratios = [[1, 2, 0.5]] * 5 :å› ä¸ºè¿™ä¸ªæ¨¡å‹å®šä¹‰5å±‚ï¼Œæ¯å±‚çš„ratioséƒ½æ˜¯[1, 2, 0.5]



```python
class TinySSD(nn.Module):
    def __init__(self, num_classes, **kwargs):
        super(TinySSD, self).__init__(**kwargs)
        self.num_classes = num_classes
        idx_to_in_channels = [64, 128, 128, 128, 128]
        for i in range(5):
            # å³èµ‹å€¼è¯­å¥self.blk_i=get_blk(i)
            setattr(self, f'blk_{i}', get_blk(i))
            setattr(self, f'cls_{i}', cls_predictor(idx_to_in_channels[i],
                                                    num_anchors, num_classes))
            setattr(self, f'bbox_{i}', bbox_predictor(idx_to_in_channels[i],
                                                      num_anchors))

    def forward(self, X):
        anchors, cls_preds, bbox_preds = [None] * 5, [None] * 5, [None] * 5
        for i in range(5):
            # getattr(self,'blk_%d'%i)å³è®¿é—®self.blk_i
            X, anchors[i], cls_preds[i], bbox_preds[i] = blk_forward(
                X, getattr(self, f'blk_{i}'), sizes[i], ratios[i],
                getattr(self, f'cls_{i}'), getattr(self, f'bbox_{i}'))
        anchors = torch.cat(anchors, dim=1)
        cls_preds = concat_preds(cls_preds)
        cls_preds = cls_preds.reshape(
            cls_preds.shape[0], -1, self.num_classes + 1)
        bbox_preds = concat_preds(bbox_preds)
        return anchors, cls_preds, bbox_preds
```

è¿·ä½ ç‰ˆçš„SSD(ç®€å•æ•°æ®é›†ç”¨ä¸äº†è¿™ä¹ˆå¤æ‚ )



idx_to_in_channels = [64, 128, 128, 128, 128]	çœ‹ä¸Šé¢å±‚çš„å®šä¹‰,128åé¢å°±ä¸å†å˜äº†,æ‰€ä»¥é™¤äº†åŸºç¡€ç½‘ç»œå±‚ä»¥å¤–,

ä¸€å…±æ˜¯5å±‚ (for i in range(5):	ä¹‹å‰æ˜¯å’‹å®šä¹‰çš„:å¯¹äºæ¯ä¸ªchannaléƒ½æœ‰å¯¹åº”çš„bbox

setattrå®šä¹‰å±æ€§å€¼ï¼Œsetattr(object, â€˜nameâ€™, value)

**getattr()** å‡½æ•°ç”¨äºè¿”å›ä¸€ä¸ªå¯¹è±¡å±æ€§å€¼,getattr(object, name)

å³é€šè¿‡setattr()å®šä¹‰ä¸€ä¸ªblock,å†åœ¨forwardé‡Œé¢é€šè¿‡getattr()å–å‡º

torch.cat:å°†anchorsåœ¨ç¬¬ä¸€ç»´è¿›è¡Œæ‹¼æ¥(æ‰€æœ‰anchorå˜æˆä¸€ä¸ªåˆ—è¡¨)

cls_predsçš„reshapeä½¿å¾—æœ€åçš„softmaxæ¯”è¾ƒæ–¹ä¾¿(é¢„æµ‹num_classes + 1ä¸ªç±»)

bbox_predså¯¹anchorsçš„é¢„æµ‹,è¿™æ‰æ˜¯æˆ‘ä»¬è¦çš„



**åˆ›å»ºä¸€ä¸ªæ¨¡å‹å®ä¾‹ï¼Œç„¶åä½¿ç”¨å®ƒ**å¯¹ä¸€ä¸ª256Ã—256åƒç´ çš„å°æ‰¹é‡å›¾åƒ`X`(**æ‰§è¡Œå‰å‘ä¼ æ’­**)ã€‚

```python
net = TinySSD(num_classes=1)
X = torch.zeros((32, 3, 256, 256))
anchors, cls_preds, bbox_preds = net(X)

print('output anchors:', anchors.shape)
print('output class preds:', cls_preds.shape)
print('output bbox preds:', bbox_preds.shape)
```



è¾“å‡º

```
output anchors: torch.Size([1, 5444, 4])
output class preds: torch.Size([32, 5444, 2])
output bbox preds: torch.Size([32, 21776])
```

anchors	ç¬¬ä¸€ä¸ªä¸€å®šæ˜¯1,ç¬¬äºŒä¸ªæ˜¯anchoræ•°	,ç¬¬ä¸‰ä¸ªæ˜¯anchorçš„å±æ€§

class preds	batch=32	5444ä¸ªé”šæ¡†	2ä¸ªåˆ†ç±»(num_classes=1)

bbox preds		21776=5444*4	å¯¹æ¯ä¸ªé”šæ¡†å’ŒçœŸå®å€¼åš4ä¸ªåç§»



```python
batch_size = 32
train_iter, _ = d2l.load_data_bananas(batch_size)
device, net = d2l.try_gpu(), TinySSD(num_classes=1)
trainer = torch.optim.SGD(net.parameters(), lr=0.2, weight_decay=5e-4)

```

è¯»å–é¦™è•‰æ•°æ®é›†,**åˆå§‹åŒ–å…¶å‚æ•°å¹¶å®šä¹‰ä¼˜åŒ–ç®—æ³•**

```python
cls_loss = nn.CrossEntropyLoss(reduction='none')
bbox_loss = nn.L1Loss(reduction='none')

def calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks):
    batch_size, num_classes = cls_preds.shape[0], cls_preds.shape[2]
    cls = cls_loss(cls_preds.reshape(-1, num_classes),
                   cls_labels.reshape(-1)).reshape(batch_size, -1).mean(dim=1)
    bbox = bbox_loss(bbox_preds * bbox_masks,
                     bbox_labels * bbox_masks).mean(dim=1)
    return cls + bbox
```

é¢„æµ‹åç§»é‡æ˜¯ä¸€ä¸ªå›å½’é—®é¢˜,è¿™é‡Œä½¿ç”¨ğ¿1èŒƒæ•°æŸå¤±ï¼Œå³é¢„æµ‹å€¼å’ŒçœŸå®å€¼ä¹‹å·®çš„ç»å¯¹å€¼ã€‚ æ©ç å˜é‡`bbox_masks`ä»¤è´Ÿç±»é”šæ¡†å’Œå¡«å……é”šæ¡†ä¸å‚ä¸æŸå¤±çš„è®¡ç®—ã€‚ æœ€åï¼Œæˆ‘ä»¬å°†é”šæ¡†ç±»åˆ«å’Œåç§»é‡çš„æŸå¤±ç›¸åŠ ï¼Œä»¥è·å¾—æ¨¡å‹çš„æœ€ç»ˆæŸå¤±å‡½æ•°ã€‚

ä½¿ç”¨L1loss,ä½¿å¾—åœ¨åå·®è¿‡å¤§æ—¶,ä¸è‡³äºæœ‰è¿‡å¤§çš„lossä½¿å¾—éš¾ä»¥æ”¶æ•›

bbox_preds * bbox_masks	è¿™éƒ¨åˆ†*mask,åœ¨æ ‡æ³¨ä¸ºèƒŒæ™¯æ—¶ç›´æ¥=0,ä»…ä¿®æ­£éèƒŒæ™¯é”šæ¡†çš„é”™è¯¯

```python
def cls_eval(cls_preds, cls_labels):
    # ç”±äºç±»åˆ«é¢„æµ‹ç»“æœæ”¾åœ¨æœ€åä¸€ç»´ï¼Œargmaxéœ€è¦æŒ‡å®šæœ€åä¸€ç»´ã€‚
    return float((cls_preds.argmax(dim=-1).type(
        cls_labels.dtype) == cls_labels).sum())

def bbox_eval(bbox_preds, bbox_labels, bbox_masks):
    return float((torch.abs((bbox_labels - bbox_preds) * bbox_masks)).sum())
```

æˆ‘ä»¬å¯ä»¥æ²¿ç”¨å‡†ç¡®ç‡è¯„ä»·åˆ†ç±»ç»“æœã€‚ ç”±äºåç§»é‡ä½¿ç”¨äº†ğ¿1L1èŒƒæ•°æŸå¤±ï¼Œæˆ‘ä»¬ä½¿ç”¨*å¹³å‡ç»å¯¹è¯¯å·®*æ¥è¯„ä»·è¾¹ç•Œæ¡†çš„é¢„æµ‹ç»“æœã€‚è¿™äº›é¢„æµ‹ç»“æœæ˜¯ä»ç”Ÿæˆçš„é”šæ¡†åŠå…¶é¢„æµ‹åç§»é‡ä¸­è·å¾—çš„ã€‚

å³åšäº†ä¸€ä¸ªåˆ†ç±»é—®é¢˜(é”šæ¡†åˆ†ç±»)å’Œä¸€ä¸ªå›å½’é—®é¢˜(éèƒŒæ™¯é”šæ¡†ä¸ç‰©ä½“æ¡†é—´è·ç¦»çš„å›å½’)

  return cls + bbox	è¿”å›å€¼ç›´æ¥å°†ä¸¤ä¸ªlossç›¸åŠ 



```python
num_epochs, timer = 20, d2l.Timer()
animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],
                        legend=['class error', 'bbox mae'])
net = net.to(device)
for epoch in range(num_epochs):
    # è®­ç»ƒç²¾ç¡®åº¦çš„å’Œï¼Œè®­ç»ƒç²¾ç¡®åº¦çš„å’Œä¸­çš„ç¤ºä¾‹æ•°
    # ç»å¯¹è¯¯å·®çš„å’Œï¼Œç»å¯¹è¯¯å·®çš„å’Œä¸­çš„ç¤ºä¾‹æ•°
    metric = d2l.Accumulator(4)
    net.train()
    for features, target in train_iter:
        timer.start()
        trainer.zero_grad()
        X, Y = features.to(device), target.to(device)
        # ç”Ÿæˆå¤šå°ºåº¦çš„é”šæ¡†ï¼Œä¸ºæ¯ä¸ªé”šæ¡†é¢„æµ‹ç±»åˆ«å’Œåç§»é‡
        anchors, cls_preds, bbox_preds = net(X)
        # ä¸ºæ¯ä¸ªé”šæ¡†æ ‡æ³¨ç±»åˆ«å’Œåç§»é‡
        bbox_labels, bbox_masks, cls_labels = d2l.multibox_target(anchors, Y)
        # æ ¹æ®ç±»åˆ«å’Œåç§»é‡çš„é¢„æµ‹å’Œæ ‡æ³¨å€¼è®¡ç®—æŸå¤±å‡½æ•°
        l = calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels,
                      bbox_masks)
        l.mean().backward()
        trainer.step()
        #è‡³æ­¤è®­ç»ƒç»“æŸ,åé¢éƒ½æ˜¯printå‡½æ•°
        metric.add(cls_eval(cls_preds, cls_labels), cls_labels.numel(),
                   bbox_eval(bbox_preds, bbox_labels, bbox_masks),
                   bbox_labels.numel())
    cls_err, bbox_mae = 1 - metric[0] / metric[1], metric[2] / metric[3]
    animator.add(epoch + 1, (cls_err, bbox_mae))
print(f'class err {cls_err:.2e}, bbox mae {bbox_mae:.2e}')
print(f'{len(train_iter.dataset) / timer.stop():.1f} examples/sec on '
      f'{str(device)}')
```



##### [**é¢„æµ‹ç›®æ ‡**]

åœ¨é¢„æµ‹é˜¶æ®µï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½æŠŠå›¾åƒé‡Œé¢æ‰€æœ‰æˆ‘ä»¬æ„Ÿå…´è¶£çš„ç›®æ ‡æ£€æµ‹å‡ºæ¥ã€‚åœ¨ä¸‹é¢ï¼Œæˆ‘ä»¬è¯»å–å¹¶è°ƒæ•´æµ‹è¯•å›¾åƒçš„å¤§å°ï¼Œç„¶åå°†å…¶è½¬æˆå·ç§¯å±‚éœ€è¦çš„å››ç»´æ ¼å¼ã€‚

```
X = torchvision.io.read_image('../img/banana.jpg').unsqueeze(0).float()
img = X.squeeze(0).permute(1, 2, 0).long()
```

è¯»å›¾

```python
def predict(X):
    net.eval()	#ä½¿ç”¨éªŒè¯æ¨¡å¼
    anchors, cls_preds, bbox_preds = net(X.to(device))
    cls_probs = F.softmax(cls_preds, dim=2).permute(0, 2, 1)
    output = d2l.multibox_detection(cls_probs, bbox_preds, anchors)
    idx = [i for i, row in enumerate(output[0]) if row[0] != -1]
    return output[0, idx]

output = predict(X)
```

F.softmax:æŠŠcls_predså˜æˆé¢„æµ‹çš„æ¦‚ç‡

 d2l.multibox_detection	:æ ¹æ®é”šæ¡†åŠå…¶é¢„æµ‹åç§»é‡å¾—åˆ°é¢„æµ‹è¾¹ç•Œæ¡†ã€‚ç„¶åï¼Œé€šè¿‡éæå¤§å€¼æŠ‘åˆ¶æ¥ç§»é™¤ç›¸ä¼¼çš„é¢„æµ‹è¾¹ç•Œæ¡†ã€‚

è®­ç»ƒçš„æ—¶å€™ç”¨çŒ«æ¡†å’ŒæŸå¤±è®­ç»ƒæ•´ä¸ªå›¾ï¼Œä¸è¿‡æ˜¯æŒ‰ç…§æ¡†å†…çš„åšä¼˜åŒ–æŸå¤±ã€‚

ä»¥ä¸Šå®ç°äº†ä¸€ä¸ªç®€å•çš„SSDç®—æ³•,ä½†æ˜¯é€Ÿåº¦å’Œå‡†ç¡®åº¦éƒ½ä¸å¤§å°½äººæ„,ä½¿ç”¨ä¸€äº›ç›®æ ‡è¯†åˆ«çš„å°æŠ€å·§èƒ½éå¸¸å¤§åœ°æå‡å…¶æ•ˆç‡å’Œå‡†ç¡®åº¦



## YOLO

. SSDä¸­é”šæ¡†å¤§é‡é‡å ï¼Œå› æ­¤æµªè´¹äº†å¾ˆå¤šè®¡ç®—
Â·YOLOå°†å›¾ç‰‡å‡åŒ€åˆ†æˆSÃ—Sä¸ªé”šæ¡†Â·æ¯ä¸ªé”šæ¡†é¢„æµ‹Bä¸ªè¾¹ç¼˜æ¡†
Â·åç»­ç‰ˆæœ¬(V2,V3,V4...)æœ‰æŒç»­æ”¹è¿›

ä½¿ç”¨ä¸€äº›trick,æ€§èƒ½æå‡å¾ˆé«˜è€Œä¸”é€Ÿåº¦ä¹Ÿå¾ˆå¿«







##### QA

æ•°æ®å¢å¼ºçš„å¹³å‡:ä¸€èˆ¬åœ¨æ¦‚ç‡ä¸Šåšå¹³å‡,åœ¨softmaxå±‚ä¸Šåšå¹³å‡

å¤šæ¨¡å‹èåˆå¯¹ç²¾åº¦è¦æ±‚é«˜çš„æƒ…å†µä¸‹æ¯”è¾ƒå¥½,ä½†æ˜¯è¿™ä¸ªå·¥ä½œæ²¡å•¥åˆ›æ–°å‹

ROIä¼šä½¿å›¾ç‰‡å‘ç”Ÿå˜å½¢(é«˜å®½æ¯”å˜äº†),ä½†æ˜¯è¿™ä¸ªå˜å½¢æ˜¯å¯ä»¥æ¥å—çš„

å¯¹äºYOLOå’ŒSSD,è®­ç»ƒçš„æ˜¯é¢„é€‰æ¡†å’Œå®é™…æ¡†é—´çš„åç§»å€¼

CNNæ›´å…³æ³¨å±€éƒ¨ç»†èŠ‚ï¼Œè€Œtransformeræ›´å…³æ³¨å…¨å±€ä¿¡æ¯



#### å¤šå°ºåº¦ç›®æ ‡æ£€æµ‹

```python
%matplotlib inline
import torch
from d2l import torch as d2l

img = d2l.plt.imread('../img/catdog.jpg')
h, w = img.shape[:2]
h, w
```

è¯»å›¾,ä¸è§£é‡Šäº†

```python
def display_anchors(fmap_w, fmap_h, s):
    d2l.set_figsize()
    # å‰ä¸¤ä¸ªç»´åº¦ä¸Šçš„å€¼ä¸å½±å“è¾“å‡º
    fmap = torch.zeros((1, 10, fmap_h, fmap_w))
    anchors = d2l.multibox_prior(fmap, sizes=s, ratios=[1, 2, 0.5])
    bbox_scale = torch.tensor((w, h, w, h))
    d2l.show_bboxes(d2l.plt.imshow(img).axes,
                    anchors[0] * bbox_scale)
```

fmap_w, fmap_h	ä¸ºæ¨ªå‘ä»¥åŠçºµå‘çš„ä¸­å¿ƒç‚¹æ•°	sä¸ºé”šæ¡†é¢ç§¯	ratiosä¸ºé«˜å®½æ¯”



```python
display_anchors(fmap_w=4, fmap_h=4, s=[0.15])
display_anchors(fmap_w=2, fmap_h=2, s=[0.4])
display_anchors(fmap_w=1, fmap_h=1, s=[0.8])
```

ç¬¬ä¸€è¡Œä¾¦æµ‹å°ç‰¹å¾,æ‰€ä»¥ä½¿ç”¨å¤§w,hå°s 

ç¬¬äºŒè¡Œä¾¦æµ‹å¤§ç‰¹å¾,wå’Œhå‡åŠ,ä½¿ç”¨å°w,hå¤§s 



QA:

ä¸Šä¸€èŠ‚è¯¾ä¸¾äº†ä¾‹å­ï¼Œä¸ºäº†è¾ƒå°‘æ•°é‡ï¼Œæ‰€ä»¥å–æˆå¯¹çš„sizeå’Œratioçš„æ—¶å€™ï¼Œåªå–ç¬¬ä¸€ä¸ªsizeå’Œæ‰€æœ‰ratioã€ç¬¬ä¸€ä¸ªratioå’Œæ‰€æœ‰sizeçš„æ­é…ï¼Œä¹Ÿå°±æ˜¯æ€»å…±r+s-1ä¸ªæ­é…

å¯¹äºå¤§å°ºå¯¸çš„å›¾ç‰‡,SSDä¼šå¯¼è‡´è¿‡å¤šçš„anchor,æ­¤æ—¶ä¸å¤§é€‚åˆ;ä½¿ç”¨mask-fast-RCNNé™é”šæ¡†æ•°ä¼šæ¯”è¾ƒå¥½;å½“ç„¶YOLOä¹ŸæŒºå¥½

å¯¹äºæœ‰ç‰¹æ®Šå½¢çŠ¶çš„ç‰©ä½“(ç”µçº¿æ†:ç‰¹åˆ«ç»†é•¿ç­‰),è°ƒæ•´ratios(é«˜å®½æ¯”)å°±è¡Œ

æ¯ä¸€å±‚çš„é”šæ¡†ä¸å…±äº«å‚æ•°,ä½†å…±äº«ç‰¹å¾

lossç‰¹åˆ«å¤§çš„é”šæ¡†é€šå¸¸æ²¡ä»€ä¹ˆç”¨,æ¯•ç«Ÿæˆ‘ç›´æ¥é€‰ä¸ªlosså°çš„å°±å¥½äº†(æœ€åè¦ç”¨çš„anchorä¹Ÿå°±å‡ ä¸ª),ä½¿ç”¨L1å¯¹é”šæ¡†åšlosså°±ç­‰äºå¯¹losså¤§çš„é”šæ¡†å¼ƒç–—äº† 

 CrossEntropy losså’ŒL1 lossçš„å–å€¼èŒƒå›´ä¸€æ ·å—ï¼Ÿæ›´å¹¿æ³›çš„ä¸€ä¸ªé—® é¢˜ï¼Œå¤šä¸ªlossç›´æ¥ç›¸åŠ ï¼Œä¼šä¸ä¼šå¯¼è‡´ä¸€ä¸ªLoss dominateæ•´ä¸ªæŸå¤±å‡½æ•°ï¼Œå…¶ ä»–çš„lossæ ¹æœ¬æ²¡ä»€ä¹ˆç”¨ï¼Ÿ

ä¼š,æ‰€ä»¥ä¸€èˆ¬è€Œè¨€ä¼šå¯¹å„ä¸ªlossè¿›è¡Œä¸€ä¸ªåŠ æƒå¤„ç†,ä½¿å¾—ä¸¤ä¸ªlosså·®ä¸å¤šå¤§

å„ç§ç®—æ³•æ€ä¹ˆåœ¨GPUä¸Šè·‘å¾—å¿«,å¯ä»¥å»æœä¸€ä¸‹ç›¸å…³è®ºæ–‡

 é”šæ¡†çš„å·ç§¯éƒ½æ˜¯3*3ï¼Œä¸åŒé€šé“ä¸‹é•¿å®½å’Œå¤§å°ä¸åŒï¼Œconnectå±‚å’Œå·ç§¯å±‚æ¥ä½“ç°

ç›®æ ‡æ£€æµ‹çš„fine-tuneï¼šcls_predictorå’Œbbox_predictoré‡æ–°è®­ç»ƒ,å›¾ç‰‡åˆ†ç±»éƒ¨åˆ†åšfine-tune,predictorç­‰éƒ½è¦éšæœºåˆå§‹åŒ–

ä»‹ç»äº†ä¸€äº›å¼€æºçš„ç›®æ ‡æ£€æµ‹ç®—æ³•https://zhuanlan.zhihu.com/p/96931265

mmdetectionå‚æ•°å°‘ä¸€ç‚¹

Detectron2å‚æ•°å¤ªå¤š,å¯¹researcheræ¥è¯´å¥½ç”¨

å¯¹äºåŒä¸€ä¸ªæ¨¡å‹,ä¿å­˜é‡æ–°åŠ è½½åaccä¸ä¸€æ ·åŸå› :

1. éšæœºæ•°çš„seedå˜äº†
2. .evl(),æµ‹è¯•æ¨¡å¼æœ‰å¼€å—

æ¯ä¸ªåƒç´ åšanchor,å®é™…ä¸Šæ˜¯å¯¹feature mapçš„åƒç´ åšé”šæ¡†

å¯¹äºç½®ä¿¡åº¦è®¡ç®—,åŒæ ·ä¼šä½¿ç”¨nmsè¿›è¡Œè®¡ç®—

loss=é¢„æµ‹loss+é”šæ¡†åç§»é‡	å¹¶åŠ æƒ	,å› ä¸ºå›ä¼ åªèƒ½æœ‰ä¸€ä¸ªå€¼ç”¨ä»¥å›ä¼ ,æ‰€ä»¥ä¸¤ä¸ªåŠ èµ·æ¥

ä¸¥é‡æ•°æ®ä¸å¹³è¡¡:åŠ å¤§å°‘é‡æ•°æ®çš„æƒé‡,

